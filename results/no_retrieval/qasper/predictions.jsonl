{"question_id": "753990d0b621d390ed58f20c4d9e4f065f0dc672", "predicted_answer": "1. a vocabulary of positive and negative predicates that helps determine the polarity score of an event", "predicted_evidence": []}
{"question_id": "9d578ddccc27dd849244d632dd0f6bf27348ad81", "predicted_answer": "the results are:\n\n1. using all data to train: \n   - acp -- bert achieved 0.933 accuracy\n2. using a subset to train:\n   - bert achieved 0.886 accuracy using acp (6k) + al", "predicted_evidence": []}
{"question_id": "02e4bf719b1a504e385c35c6186742e720bcb281", "predicted_answer": "2", "predicted_evidence": []}
{"question_id": "44c4bd6decc86f1091b5fc0728873d9324cdde4e", "predicted_answer": "1. 7000000 pairs of events were extracted from the japanese web corpus, 529850 pairs of events were extracted from the acp corpus", "predicted_evidence": []}
{"question_id": "86abeff85f3db79cf87a8c993e5e5aa61226dc98", "predicted_answer": "negative, positive", "predicted_evidence": []}
{"question_id": "c029deb7f99756d2669abad0a349d917428e9c12", "predicted_answer": "unfortunately, i don't have enough information to provide a specific answer. the options only show one possible answer (3%), but there is no context about what \"the proposed approach\" and \"the basic approach\" are.\n\nhowever, based on typical results in machine learning research papers, here's my best guess:\n\n* 10% to 30%\n\nplease note that this is a very rough estimate and should be taken as a wild guess.", "predicted_evidence": []}
{"question_id": "39f8db10d949c6b477fa4b51e7c184016505884f", "predicted_answer": "1. by exploiting discourse relations to propagate polarity from seed predicates to final sentiment polarity", "predicted_evidence": []}
{"question_id": "d0bc782961567dc1dd7e074b621a6d6be44bb5b4", "predicted_answer": "i'm happy to help! however, i don't see an option list provided for this question. could you please provide more options or clarify if there's only one option available?", "predicted_evidence": []}
{"question_id": "a592498ba2fac994cd6fad7372836f0adb37e22a", "predicted_answer": "1. 100 million sentences", "predicted_evidence": []}
{"question_id": "3a9d391d25cde8af3334ac62d478b36b30079d74", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "8d8300d88283c73424c8f301ad9fdd733845eb47", "predicted_answer": "1. confusion matrices of labels between annotators", "predicted_evidence": []}
{"question_id": "48b12eb53e2d507343f19b8a667696a39b719807", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "003f884d3893532f8c302431c9f70be6f64d9be8", "predicted_answer": "1. no", "predicted_evidence": []}
{"question_id": "bb97537a0a7c8f12a3f65eba73cefa6abcd2f2b2", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "eea089baedc0ce80731c8fdcb064b82f584f483a", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "edb2d24d6d10af13931b3a47a6543bd469752f0c", "predicted_answer": "2", "predicted_evidence": []}
{"question_id": "938cf30c4f1d14fa182e82919e16072fdbcf2a82", "predicted_answer": "1. the average volatility of all utterances", "predicted_evidence": []}
{"question_id": "93f4ad6568207c9bd10d712a52f8de25b3ebadd4", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "71a7153e12879defa186bfb6dbafe79c74265e10", "predicted_answer": "2", "predicted_evidence": []}
{"question_id": "85d1831c28d3c19c84472589a252e28e9884500f", "predicted_answer": "1. bert-base, qanet", "predicted_evidence": []}
{"question_id": "1959e0ebc21fafdf1dd20c6ea054161ba7446f61", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "77cf4379106463b6ebcb5eb8fa5bb25450fa5fb8", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "06095a4dee77e9a570837b35fc38e77228664f91", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "19c9cfbc4f29104200393e848b7b9be41913a7ac", "predicted_answer": "1. 2,714", "predicted_evidence": []}
{"question_id": "6743c1dd7764fc652cfe2ea29097ea09b5544bc3", "predicted_answer": "1. unanswerable", "predicted_evidence": []}
{"question_id": "14323046220b2aea8f15fba86819cbccc389ed8b", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "08a5f8d36298b57f6a4fcb4b6ae5796dc5d944a4", "predicted_answer": "1. integrate clinical named entity information into pre-trained language model", "predicted_evidence": []}
{"question_id": "975a4ac9773a4af551142c324b64a0858670d06e", "predicted_answer": "1. 17,833 sentences, 826,987 characters and 2,714 question-answer pairs", "predicted_evidence": []}
{"question_id": "326e08a0f5753b90622902bd4a9c94849a24b773", "predicted_answer": "1. 17,833 sentences, 826,987 characters and 2,714 question-answer pairs", "predicted_evidence": []}
{"question_id": "bd78483a746fda4805a7678286f82d9621bc45cf", "predicted_answer": "1. state-of-the-art question answering models (i.e. qanet) and bert-base", "predicted_evidence": []}
{"question_id": "dd155f01f6f4a14f9d25afc97504aefdc6d29c13", "predicted_answer": "1.", "predicted_evidence": []}
{"question_id": "a9d530d68fb45b52d9bad9da2cd139db5a4b2f7c", "predicted_answer": "kneser\u2013ney smoothing", "predicted_evidence": []}
{"question_id": "e07df8f613dbd567a35318cd6f6f4cb959f5c82d", "predicted_answer": "1. perplexity", "predicted_evidence": []}
{"question_id": "1a43df221a567869964ad3b275de30af2ac35598", "predicted_answer": "1. the yelp challenge dataset", "predicted_evidence": []}
{"question_id": "98b11f70239ef0e22511a3ecf6e413ecb726f954", "predicted_answer": "unfortunately, i don't have enough information to determine if they use a pretrained nmt model to help generate reviews. however, based on my understanding of common practices in natural language processing and machine translation, i'll take a guess.\n\nmy best guess is: 1. no", "predicted_evidence": []}
{"question_id": "d4d771bcb59bab4f3eb9026cda7d182eb582027d", "predicted_answer": "unfortunately, i don't have enough information to provide a specific answer. however, based on my knowledge of nmt (neural machine translation), i can try to make an educated guess.\n\nsince there is only one option available (\"unanswerable\"), i will choose that as the best answer.", "predicted_evidence": []}
{"question_id": "12f1919a3e8ca460b931c6cacc268a926399dff4", "predicted_answer": "1. adaboost-based classifier", "predicted_evidence": []}
{"question_id": "cd1034c183edf630018f47ff70b48d74d2bb1649", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "bd9930a613dd36646e2fc016b6eb21ab34c77621", "predicted_answer": "2,000", "predicted_evidence": []}
{"question_id": "6e2ad9ad88cceabb6977222f5e090ece36aa84ea", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "aacb0b97aed6fc6a8b471b8c2e5c4ddb60988bf5", "predicted_answer": "one", "predicted_evidence": []}
{"question_id": "710c1f8d4c137c8dad9972f5ceacdbf8004db208", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "47726be8641e1b864f17f85db9644ce676861576", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "8958465d1eaf81c8b781ba4d764a4f5329f026aa", "predicted_answer": "ripa, neighborhood metric, weat", "predicted_evidence": []}
{"question_id": "31b6544346e9a31d656e197ad01756813ee89422", "predicted_answer": "i'm happy to help! however, i don't see a list of options provided for this question. the only option listed is \"1. unanswerable\". \n\nif that's correct, my response would be:\n\n1. unanswerable", "predicted_evidence": []}
{"question_id": "347e86893e8002024c2d10f618ca98e14689675f", "predicted_answer": "2. high-quality", "predicted_evidence": []}
{"question_id": "10091275f777e0c2890c3ac0fd0a7d8e266b57cf", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "cbf1137912a47262314c94d36ced3232d5fa1926", "predicted_answer": "fasttext, cwe-lp", "predicted_evidence": []}
{"question_id": "519db0922376ce1e87fcdedaa626d665d9f3e8ce", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "99a10823623f78dbff9ccecb210f187105a196e9", "predicted_answer": "1. large portuguese corpus", "predicted_evidence": []}
{"question_id": "09f0dce416a1e40cc6a24a8b42a802747d2c9363", "predicted_answer": "1. continuous bag-of-words (cbow)", "predicted_evidence": []}
{"question_id": "ac706631f2b3fa39bf173cd62480072601e44f66", "predicted_answer": "2. yes", "predicted_evidence": []}
{"question_id": "8b71ede8170162883f785040e8628a97fc6b5bcb", "predicted_answer": "the provided option does not directly answer the question about how the quality of citation is measured. however, based on the context given in the option, it seems that the performance (and possibly the quality) is evaluated using metrics such as f1 measure. therefore, my best guess for how the quality of citation is measured would be:\n\nf1 measure", "predicted_evidence": []}
{"question_id": "fa2a384a23f5d0fe114ef6a39dced139bddac20e", "predicted_answer": "1. 903019 references", "predicted_evidence": []}
{"question_id": "53712f0ce764633dbb034e550bb6604f15c0cacd", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "0bffc3d82d02910d4816c16b390125e5df55fd01", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "bdd8368debcb1bdad14c454aaf96695ac5186b09", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "3334f50fe1796ce0df9dd58540e9c08be5856c23", "predicted_answer": "1. for each user, we calculate the proportion of tweets scored positively by each liwc category.", "predicted_evidence": []}
{"question_id": "7081b6909cb87b58a7b85017a2278275be58bf60", "predicted_answer": "1. 210", "predicted_evidence": []}
{"question_id": "1870f871a5bcea418c44f81f352897a2f53d0971", "predicted_answer": "1. dospert, bsss and vias", "predicted_evidence": []}
{"question_id": "ce6201435cc1196ad72b742db92abd709e0f9e8d", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "928828544e38fe26c53d81d1b9c70a9fb1cc3feb", "predicted_answer": "1. 29,500 documents", "predicted_evidence": []}
{"question_id": "4f243056e63a74d1349488983dc1238228ca76a7", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "8f87215f4709ee1eb9ddcc7900c6c054c970160b", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "b04098f7507efdffcbabd600391ef32318da28b3", "predicted_answer": "unfortunately, i don't have enough information to provide a specific number of languages that the sentiment lexica is available for. therefore, my response would be:\n\n1. unanswerable", "predicted_evidence": []}
{"question_id": "8fc14714eb83817341ada708b9a0b6b4c6ab5023", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "d94ac550dfdb9e4bbe04392156065c072b9d75e1", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "eeb6e0caa4cf5fdd887e1930e22c816b99306473", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "3c0eaa2e24c1442d988814318de5f25729696ef5", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "dc1fe3359faa2d7daa891c1df33df85558bc461b", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "922f1b740f8b13fdc8371e2a275269a44c86195e", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "b39f2249a1489a2cef74155496511cc5d1b2a73d", "predicted_answer": "resnet50 89%, svm-hmm 70%.", "predicted_evidence": []}
{"question_id": "591231d75ff492160958f8aa1e6bfcbbcd85a776", "predicted_answer": "1. cnn-mean, cnn-avgmax", "predicted_evidence": []}
{"question_id": "9e805020132d950b54531b1a2620f61552f06114", "predicted_answer": "1. cnn-mean", "predicted_evidence": []}
{"question_id": "95abda842c4df95b4c5e84ac7d04942f1250b571", "predicted_answer": "2", "predicted_evidence": []}
{"question_id": "2419b38624201d678c530eba877c0c016cccd49f", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "b99d100d17e2a121c3c8ff789971ce66d1d40a4d", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "578d0b23cb983b445b1a256a34f969b34d332075", "predicted_answer": "2", "predicted_evidence": []}
{"question_id": "6548db45fc28e8a8b51f114635bad14a13eaec5b", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "4c4f76837d1329835df88b0921f4fe8bda26606f", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "819d2e97f54afcc7cdb3d894a072bcadfba9b747", "predicted_answer": "1. cnn, time, 20 newsgroups, and reuters-21578", "predicted_evidence": []}
{"question_id": "637aa32a34b20b4b0f1b5dfa08ef4e0e5ed33d52", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "4b8257cdd9a60087fa901da1f4250e7d910896df", "predicted_answer": "1.", "predicted_evidence": []}
{"question_id": "7e161d9facd100544fa339b06f656eb2fc64ed28", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "abc5836c54fc2ac8465aee5a83b9c0f86c6fd6f5", "predicted_answer": "2", "predicted_evidence": []}
{"question_id": "4debd7926941f1a02266b1a7be2df8ba6e79311a", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "3b745f086fb5849e7ce7ce2c02ccbde7cfdedda5", "predicted_answer": "1. in the sentiment classification task by 6% to 8% and in the intent classification task by 0.94% on average", "predicted_evidence": []}
{"question_id": "44c7c1fbac80eaea736622913d65fe6453d72828", "predicted_answer": "1. 34,432 user conversations", "predicted_evidence": []}
{"question_id": "3e0c9469821cb01a75e1818f2acb668d071fcf40", "predicted_answer": "neither of the options provided is a comprehensive list of metrics to measure user engagement. however, here are some common metrics used to measure user engagement:\n\n1. time on site/app\n2. bounce rate\n3. pages per session\n4. average session duration\n5. overall rating\n6. mean number of turns (for conversational interfaces)\n7. click-through rate (ctr)\n8. conversion rate\n9. scroll depth\n10. social shares and engagement metrics (e.g., likes, comments, shares)\n\nplease note that the specific metrics used may vary depending on the context and goals of the product or service being measured.", "predicted_evidence": []}
{"question_id": "a725246bac4625e6fe99ea236a96ccb21b5f30c6", "predicted_answer": "1. amazon conversational bot toolkit, natural language understanding (nlu) (nlu) module, dialog manager, knowledge bases, natural language generation (nlg) (nlg) module, text to speech (tts) (tts)", "predicted_evidence": []}
{"question_id": "516626825e51ca1e8a3e0ac896c538c9d8a747c8", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "77af93200138f46bb178c02f710944a01ed86481", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "71538776757a32eee930d297f6667cd0ec2e9231", "predicted_answer": "1. modeled the relationship between word count and the two metrics of user engagement (overall rating, mean number of turns) in separate linear regressions", "predicted_evidence": []}
{"question_id": "830de0bd007c4135302138ffa8f4843e4915e440", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "680dc3e56d1dc4af46512284b9996a1056f89ded", "predicted_answer": "2", "predicted_evidence": []}
{"question_id": "bd5379047c2cf090bea838c67b6ed44773bcd56f", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "7aa8375cdf4690fc3b9b1799b0f5a9ec1c1736ed", "predicted_answer": "2", "predicted_evidence": []}
{"question_id": "3ac30bd7476d759ea5d9a5abf696d4dfc480175b", "predicted_answer": "1. lstm lms", "predicted_evidence": []}
{"question_id": "0e57a0983b4731eba9470ba964d131045c8c7ea7", "predicted_answer": "none of the above options seem relevant to the question asked. however, i can try to provide a helpful response.\n\nin the context of evaluating human judges, some common questions that might be asked include:\n\n* what is your judicial philosophy?\n* how do you approach decision-making in complex cases?\n* can you describe a particularly challenging case you've presided over and how you handled it?\n* how do you ensure impartiality and avoid bias in your rulings?\n* how do you stay current with changes in the law and developments in your area of expertise?\n\nplease note that these questions are speculative, and i'm not aware of any specific context or criteria for evaluating human judges.", "predicted_evidence": []}
{"question_id": "f0317e48dafe117829e88e54ed2edab24b86edb1", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "ec91b87c3f45df050e4e16018d2bf5b62e4ca298", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "f129c97a81d81d32633c94111018880a7ffe16d1", "predicted_answer": "soft attention, hard stochastic attention, local attention", "predicted_evidence": []}
{"question_id": "100cf8b72d46da39fedfe77ec939fb44f25de77f", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "8cc56fc44136498471754186cfa04056017b4e54", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "5fa431b14732b3c47ab6eec373f51f2bca04f614", "predicted_answer": "1. tf-idf, nvdm", "predicted_evidence": []}
{"question_id": "33ccbc401b224a48fba4b167e86019ffad1787fb", "predicted_answer": "from 50k to 4.8m", "predicted_evidence": []}
{"question_id": "cca74448ab0c518edd5fc53454affd67ac1a201c", "predicted_answer": "198,112", "predicted_evidence": []}
{"question_id": "b69ffec1c607bfe5aa4d39254e0770a3433a191b", "predicted_answer": "1. chinese dataset bibref0", "predicted_evidence": []}
{"question_id": "f5cf8738e8d211095bb89350ed05ee7f9997eb19", "predicted_answer": "up to four percentage points in accuracy", "predicted_evidence": []}
{"question_id": "bed527bcb0dd5424e69563fba4ae7e6ea1fca26a", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "aeab5797b541850e692f11e79167928db80de1ea", "predicted_answer": "1. all three representations are concatenated and passed into a mlp", "predicted_evidence": []}
{"question_id": "bfa3776c30cb30e0088e185a5908e5172df79236", "predicted_answer": "1. random forest ensemble classifiers", "predicted_evidence": []}
{"question_id": "a2a66726a5dca53af58aafd8494c4de833a06f14", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "ee87608419e4807b9b566681631a8cd72197a71a", "predicted_answer": "2. the digital library in the textgrid repository", "predicted_evidence": []}
{"question_id": "cda4612b4bda3538d19f4b43dde7bc30c1eda4e5", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "e12674f0466f8c0da109b6076d9939b30952c7da", "predicted_answer": "fasttext", "predicted_evidence": []}
{"question_id": "9fe6339c7027a1a0caffa613adabe8b5bb6a7d4a", "predicted_answer": "i don't have enough information to determine what user-generated text data i use.", "predicted_evidence": []}
{"question_id": "b5c3787ab3784214fc35f230ac4926fe184d86ba", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "9174aded45bc36915f2e2adb6f352f3c7d9ada8b", "predicted_answer": "1. sst-2 (stanford sentiment treebank, version 2), snips", "predicted_evidence": []}
{"question_id": "a8f1029f6766bffee38a627477f61457b2d6ed5c", "predicted_answer": "unfortunately, i don't have enough context about \"they\" and what specific topic is being referred to. however, based on the option provided:\n\n1. unanswerable", "predicted_evidence": []}
{"question_id": "a2103e7fe613549a9db5e65008f33cf2ee0403bd", "predicted_answer": "wealth, democracy, population, levels of oda, conflict", "predicted_evidence": []}
{"question_id": "13b36644357870008d70e5601f394ec3c6c07048", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "e4a19b91b57c006a9086ae07f2d6d6471a8cf0ce", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "fd0ef5a7b6f62d07776bf672579a99c67e61a568", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "071bcb4b054215054f17db64bfd21f17fd9e1a80", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "f399d5a8dbeec777a858f81dc4dd33a83ba341a2", "predicted_answer": "1. qnamaker portal, qnamaker management apis, azure search index, qnamaker webapp, bot", "predicted_evidence": []}
{"question_id": "d28260b5565d9246831e8dbe594d4f6211b60237", "predicted_answer": "none of the above options seem directly related to measuring robustness in experiments. however, i'll choose one as per your request:\n\n2. boost the training bleu very greatly, the over-fitting problem of the plackett-luce models pl($k$) is alleviated with moderately large $k$", "predicted_evidence": []}
{"question_id": "8670989ca39214eda6c1d1d272457a3f3a92818b", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "923b12c0a50b0ee22237929559fad0903a098b7b", "predicted_answer": "1. plackett-luce model for smt reranking", "predicted_evidence": []}
{"question_id": "67131c15aceeb51ae1d3b2b8241c8750a19cca8e", "predicted_answer": "1. oracle", "predicted_evidence": []}
{"question_id": "579a0603ec56fc2b4aa8566810041dbb0cd7b5e7", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "c9c85eee41556c6993f40e428fa607af4abe80a9", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "f8281eb49be3e8ea0af735ad3bec955a5dedf5b3", "predicted_answer": "2. yes", "predicted_evidence": []}
{"question_id": "a5ee9b40a90a6deb154803bef0c71c2628acb571", "predicted_answer": "three commonly used ts datasets from two different domains", "predicted_evidence": []}
{"question_id": "e286860c41a4f704a3a08e45183cb8b14fa2ad2f", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "982979cb3c71770d8d7d2d1be8f92b66223dec85", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "5ba6f7f235d0f5d1d01fd97dd5e4d5b0544fd212", "predicted_answer": "2", "predicted_evidence": []}
{"question_id": "7ce7edd06925a943e32b59f3e7b5159ccb7acaf6", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "a883bb41449794e0a63b716d9766faea034eb359", "predicted_answer": "2", "predicted_evidence": []}
{"question_id": "5d83b073635f5fd8cd1bdb1895d3f13406583fbd", "predicted_answer": "the previously reported models are: hasty student, impatient reader, bidaf, bidaf w/ static memory", "predicted_evidence": []}
{"question_id": "171ebfdc9b3a98e4cdee8f8715003285caeb2f39", "predicted_answer": "single-task training: 2.51 \nmulti-task training: -0.42", "predicted_evidence": []}
{"question_id": "3c3cb51093b5fd163e87a773a857496a4ae71f03", "predicted_answer": "2", "predicted_evidence": []}
{"question_id": "53a0763eff99a8148585ac642705637874be69d4", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "0bfed6f9cfe93617c5195c848583e3945f2002ff", "predicted_answer": "1. gated recurrent unit (gru) and long short-term memory (lstm) are types of gated neural networks.", "predicted_evidence": []}
{"question_id": "352c081c93800df9654315e13a880d6387b91919", "predicted_answer": "unfortunately, i don't have enough information to provide a specific answer from the options given, as there is only one option and it's \"unanswerable\". however, i can try to provide some general information on script knowledge.\n\nscript knowledge typically involves understanding the structure and organization of events or actions in a particular context. some key points that can be studied in script knowledge include:\n\n* event sequences: the order in which events occur\n* causal relationships: how one event leads to another\n* goal-oriented behavior: understanding how scripts are used to achieve specific goals\n* script variations: recognizing different versions or adaptations of a script\n\nplease note that these points may not be directly related to the options provided, but rather a general answer based on my understanding of script knowledge.", "predicted_evidence": []}
{"question_id": "18fbf9c08075e3b696237d22473c463237d153f5", "predicted_answer": "2", "predicted_evidence": []}
{"question_id": "a37ef83ab6bcc6faff3c70a481f26174ccd40489", "predicted_answer": "four", "predicted_evidence": []}
{"question_id": "bc9c31b3ce8126d1d148b1025c66f270581fde10", "predicted_answer": "1.  kinship and nations knowledge graphs, yago3-10 and wn18kgs knowledge graphs", "predicted_evidence": []}
{"question_id": "185841e979373808d99dccdade5272af02b98774", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "d427e3d41c4c9391192e249493be23926fc5d2e9", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "330f2cdeab689670b68583fc4125f5c0b26615a8", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "c87b2dd5c439d5e68841a705dd81323ec0d64c97", "predicted_answer": "slda (mv)", "predicted_evidence": []}
{"question_id": "f7789313a804e41fcbca906a4e5cf69039eeef9f", "predicted_answer": "1. reuters-21578 bibref30,  labelme bibref31, 20-newsgroups benchmark corpus bibref29", "predicted_evidence": []}
{"question_id": "2376c170c343e2305dac08ba5f5bda47c370357f", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "0137ecebd84a03b224eb5ca51d189283abb5f6d9", "predicted_answer": "1. bertnlu from convlab-2, a rule-based model (ruledst) , trade (transferable dialogue state generator) , a vanilla policy trained in a supervised fashion from convlab-2 (sl policy)", "predicted_evidence": []}
{"question_id": "5f6fbd57cce47f20a0fda27d954543c00c4344c2", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "d6e2b276390bdc957dfa7e878de80cee1f41fbca", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "32537fdf0d4f76f641086944b413b2f756097e5e", "predicted_answer": "1. improving the score for wnlampro-medium by 50% compared to bert$_\\text{base}$ and 31% compared to attentive mimicking", "predicted_evidence": []}
{"question_id": "ef081d78be17ef2af792e7e919d15a235b8d7275", "predicted_answer": "2. mnli, ag's news, dbpedia", "predicted_evidence": []}
{"question_id": "537b2d7799124d633892a1ef1a485b3b071b303d", "predicted_answer": "wnlampro dataset", "predicted_evidence": []}
{"question_id": "9aca4b89e18ce659c905eccc78eda76af9f0072a", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "b0376a7f67f1568a7926eff8ff557a93f434a253", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "dad8cc543a87534751f9f9e308787e1af06f0627", "predicted_answer": "2. aida-conll, ace2004, msnbc, aquaint, wned-cweb, wned-wiki, ourself-wiki", "predicted_evidence": []}
{"question_id": "0481a8edf795768d062c156875d20b8fb656432c", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "b6a4ab009e6f213f011320155a7ce96e713c11cf", "predicted_answer": "1. unanswerable", "predicted_evidence": []}
{"question_id": "cfffc94518d64cb3c8789395707e4336676e0345", "predicted_answer": "2", "predicted_evidence": []}
{"question_id": "f60629c01f99de3f68365833ee115b95a3388699", "predicted_answer": "nnc su4 f1, nnc top 5, support vector classification (svc)", "predicted_evidence": []}
{"question_id": "a7cb4f8e29fd2f3d1787df64cd981a6318b65896", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "642c4704a71fd01b922a0ef003f234dcc7b223cd", "predicted_answer": "1. irremediable annotation discrepancies, differences in choice of attributes to annotate, the resources themselves would need updating to encode the relevant morphosyntactic information. some languages had a very low number of overlapping forms, and no tag matches or near-matches between them, the two annotations encode distinct information, incorrectly applied unimorph annotation, cross-lingual inconsistency in both resources", "predicted_evidence": []}
{"question_id": "e477e494fe15a978ff9c0a5f1c88712cdaec0c5c", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "04495845251b387335bf2e77e2c423130f43c7d9", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "564dcaf8d0bcc274ab64c784e4c0f50d7a2c17ee", "predicted_answer": "1. ar, bg, ca, cs, da, de, en, es, eu, fa, fi, fr, ga, he, hi, hu, it, la, lt, lv, nb, nl, nn, pl, pt, ro, ru, sl, sv, tr, uk, ur", "predicted_evidence": []}
{"question_id": "f3d0e6452b8d24b7f9db1fd898d1fbe6cd23f166", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "9b1d789398f1f1a603e4741a5eee63ccaf0d4a4f", "predicted_answer": "1. confusion matrices, $\\text{f}_1$ score", "predicted_evidence": []}
{"question_id": "00bcdffff7e055f99aaf1b05cf41c98e2748e948", "predicted_answer": "1. for the emotion recognition from text they use described neural network as baseline.\nfor audio and face there is no baseline.", "predicted_evidence": []}
{"question_id": "f92ee3c5fce819db540bded3cfcc191e21799cb1", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "4547818a3bbb727c4bb4a76554b5a5a7b5c5fedb", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "07d7652ad4a0ec92e6b44847a17c378b0d9f57f5", "predicted_answer": "1. 10.37 bleu", "predicted_evidence": []}
{"question_id": "9f3444c9fb2e144465d63abf58520cddd4165a01", "predicted_answer": "gu-etal:2018:emnlp1", "predicted_evidence": []}
{"question_id": "2348d68e065443f701d8052018c18daa4ecc120e", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "5679fabeadf680e35a4f7b092d39e8638dca6b4d", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "a939a53cabb4893b2fd82996f3dbe8688fdb7bbb", "predicted_answer": "unfortunately, i don't have enough information to provide a specific answer. however, based on general knowledge, i'll take a guess:\n\n none of the above (since there's only one option)\n\nplease provide more context or options so i can give a better answer!", "predicted_evidence": []}
{"question_id": "8b99767620fd4efe51428b68841cc3ec06699280", "predicted_answer": "natural language processing (nlp)", "predicted_evidence": []}
{"question_id": "312417675b3dc431eb7e7b16a917b7fed98d4376", "predicted_answer": "axelrod's causal mapping method", "predicted_evidence": []}
{"question_id": "792d7b579cbf7bfad8fe125b0d66c2059a174cf9", "predicted_answer": "ternary trans-cnn", "predicted_evidence": []}
{"question_id": "44a2a8e187f8adbd7d63a51cd2f9d2d324d0c98d", "predicted_answer": "1. heot , a labelled dataset for a corresponding english tweets", "predicted_evidence": []}
{"question_id": "5908d7fb6c48f975c5dfc5b19bb0765581df2b25", "predicted_answer": "2.", "predicted_evidence": []}
{"question_id": "cca3301f20db16f82b5d65a102436bebc88a2026", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "cfd67b9eeb10e5ad028097d192475d21d0b6845b", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "e1c681280b5667671c7f78b1579d0069cba72b0e", "predicted_answer": "ternary trans-cnn , hybrid multi-channel cnn and lstm", "predicted_evidence": []}
{"question_id": "58d50567df71fa6c3792a0964160af390556757d", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "07c79edd4c29635dbc1c2c32b8df68193b7701c6", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "66125cfdf11d3bf8e59728428e02021177142c3a", "predicted_answer": "1. table tabref15 shows that word-alignment based on mbert representations surpasses the outputs of the standard fastalign tool even if it was provided large parallel corpus. this suggests that word-level semantics are well captured by mbert contextual embeddings. for this task, learning an explicit projection had a negligible effect on the performance.", "predicted_evidence": []}
{"question_id": "222b2469eede9a0448e0226c6c742e8c91522af3", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "6f8386ad64dce3a20bc75165c5c7591df8f419cf", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "81dc39ee6cdacf90d5f0f62134bf390a29146c65", "predicted_answer": "1. contextual embeddings do not represent similar semantic phenomena similarly and therefore they are not directly usable for zero-shot cross-lingual tasks", "predicted_evidence": []}
{"question_id": "b1ced2d6dcd1d7549be2594396cbda34da6c3bca", "predicted_answer": "1. unanswerable", "predicted_evidence": []}
{"question_id": "f3be1a27df2e6ad12eed886a8cd2dfe09b9e2b30", "predicted_answer": "i don't have enough information to determine which evaluation metrics are used. the correct answer is:\n\n1. unanswerable", "predicted_evidence": []}
{"question_id": "a45a86b6a02a98d3ab11f1d04acd3446e95f5a16", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "1f1a9f2dd8c4c10b671cb8affe56e181948e229e", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "eeaceee98ef1f6c971dac7b0b8930ee8060d71c2", "predicted_answer": "2", "predicted_evidence": []}
{"question_id": "3371d586a3a81de1552d90459709c57c0b1a2594", "predicted_answer": "2. across input space: the degree of faithfulness at the level of subspaces of the input space, such as neighborhoods of similar inputs, or singular inputs themselves.", "predicted_evidence": []}
{"question_id": "d4b9cdb4b2dfda1e0d96ab6c3b5e2157fd52685e", "predicted_answer": "1. two models will make the same predictions if and only if they use the same reasoning process., on similar inputs, the model makes similar decisions if and only if its reasoning is similar., certain parts of the input are more important to the model reasoning than others. moreover, the contributions of different parts of the input are independent from each other.", "predicted_evidence": []}
{"question_id": "2a859e80d8647923181cb2d8f9a2c67b1c3f4608", "predicted_answer": "1, 2, 3, 4, 5", "predicted_evidence": []}
{"question_id": "aceac4ad16ffe1af0f01b465919b1d4422941a6b", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "f7070b2e258beac9b09514be2bfcc5a528cc3a0e", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "2efdcebebeb970021233553104553205ce5d6567", "predicted_answer": "1. two lstm layers", "predicted_evidence": []}
{"question_id": "4fa851d91388f0803e33f6cfae519548598cd37c", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "a891039441e008f1fd0a227dbed003f76c140737", "predicted_answer": "machine comprehension", "predicted_evidence": []}
{"question_id": "73738e42d488b32c9db89ac8adefc75403fa2653", "predicted_answer": "1.  69.10%/78.38%", "predicted_evidence": []}
{"question_id": "6c8bd7fa1cfb1b2bbeb011cc9c712dceac0c8f06", "predicted_answer": "2", "predicted_evidence": []}
{"question_id": "fa218b297d9cdcae238cef71096752ce27ca8f4a", "predicted_answer": "1. our model achieves a 68.73% em score and 77.39% f1 score", "predicted_evidence": []}
{"question_id": "ff28d34d1aaa57e7ad553dba09fc924dc21dd728", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "ae8354e67978b7c333094c36bf9d561ca0c2d286", "predicted_answer": "1. datasets from the nist duc-05, duc-06 and duc-07 shared tasks", "predicted_evidence": []}
{"question_id": "02348ab62957cb82067c589769c14d798b1ceec7", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "3748787379b3a7d222c3a6254def3f5bfb93a60e", "predicted_answer": "1. grammaticality, non-redundancy, referential clarity, focus, structure & coherence", "predicted_evidence": []}
{"question_id": "6852217163ea678f2009d4726cb6bd03cf6a8f78", "predicted_answer": "1. wn18rr, fb15k-237, yago3-10", "predicted_evidence": []}
{"question_id": "cd1ad7e18d8eef8f67224ce47f3feec02718ea1a", "predicted_answer": "1. transe, distmult, complex, conve, rotate", "predicted_evidence": []}
{"question_id": "9c9e90ceaba33242342a5ae7568e89fe660270d5", "predicted_answer": "2", "predicted_evidence": []}
{"question_id": "2a058f8f6bd6f8e80e8452e1dba9f8db5e3c7de8", "predicted_answer": "1. radial coordinate and the angular coordinates correspond to the modulus part and the phase part, respectively", "predicted_evidence": []}
{"question_id": "db9021ddd4593f6fadf172710468e2fdcea99674", "predicted_answer": "2. incorporating coding syntax tree model", "predicted_evidence": []}
{"question_id": "8ea4bd4c1d8a466da386d16e4844ea932c44a412", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "92240eeab107a4f636705b88f00cefc4f0782846", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "4196d329061f5a9d147e1e77aeed6a6bd9b35d18", "predicted_answer": "1. seq2seq translation", "predicted_evidence": []}
{"question_id": "a37e4a21ba98b0259c36deca0d298194fa611d2f", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "321429282557e79061fe2fe02a9467f3d0118cdd", "predicted_answer": "both options could be useful for improving accuracy.\n\nhowever, i will choose option 1: phrase-based word embedding", "predicted_evidence": []}
{"question_id": "891cab2e41d6ba962778bda297592c916b432226", "predicted_answer": "1. python", "predicted_evidence": []}
{"question_id": "1eeabfde99594b8d9c6a007f50b97f7f527b0a17", "predicted_answer": "1. validation data", "predicted_evidence": []}
{"question_id": "e96adf8466e67bd19f345578d5a6dc68fd0279a1", "predicted_answer": "1. unsupervised", "predicted_evidence": []}
{"question_id": "c1477a6c86bd1670dd17407590948000c9a6b7c6", "predicted_answer": "1. give more independence to the several learning methods (e.g. less human intervention) involved in the studies, increasing the size of the output images", "predicted_evidence": []}
{"question_id": "e020677261d739c35c6f075cde6937d0098ace7f", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "6389d5a152151fb05aae00b53b521c117d7b5e54", "predicted_answer": "3. diversity enhancement gans: ac-gan, tac-gan etc.", "predicted_evidence": []}
{"question_id": "7fe48939ce341212c1d801095517dc552b98e7b3", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "65ad17f614b7345f0077424c04c94971c831585b", "predicted_answer": "1. bilstm with max pooling", "predicted_evidence": []}
{"question_id": "323e100a6c92d3fe503f7a93b96d821408f92109", "predicted_answer": "bibref13", "predicted_evidence": []}
{"question_id": "9f89bff89cea722debc991363f0826de945bc582", "predicted_answer": "1. men, mturk287, mturk771, rg, rw, simlex999, simverb3500, ws353, ws353r, ws353s", "predicted_evidence": []}
{"question_id": "735f58e28d84ee92024a36bc348cfac2ee114409", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "710fa8b3e74ee63d2acc20af19f95f7702b7ce5e", "predicted_answer": "i don't have enough information to determine which approach performed better in experiments. can you please provide more context or details about the two proposed approaches?", "predicted_evidence": []}
{"question_id": "56123dd42cf5c77fc9a88fc311ed2e1eb672126e", "predicted_answer": "1. sptree, tagging, copyr, hrl, graphr, n-gram attention", "predicted_evidence": []}
{"question_id": "1898f999626f9a6da637bd8b4857e5eddf2fc729", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "d32b6ac003cfe6277f8c2eebc7540605a60a3904", "predicted_answer": "2", "predicted_evidence": []}
{"question_id": "c10f38ee97ed80484c1a70b8ebba9b1fb149bc91", "predicted_answer": "svmrank", "predicted_evidence": []}
{"question_id": "340501f23ddc0abe344a239193abbaaab938cc3a", "predicted_answer": "90 annotated documents with 5 citations each ranked 1 to 5, where 1 is least relevant and 5 is most relevant for a total of 450 annotated citations", "predicted_evidence": []}
{"question_id": "fbb85cbd41de6d2818e77e8f8d4b91e431931faa", "predicted_answer": "none of the above options mention a crowdsourcing platform.", "predicted_evidence": []}
{"question_id": "1951cde612751410355610074c3c69cec94824c2", "predicted_answer": "i'm happy to help! however, i don't see a specific question about which deep learning model performed better in a particular task or dataset. could you please provide more context or clarify the question?\n\nif not, i'll do my best guess based on general knowledge. in that case, my answer would be:\n\n2. cnn", "predicted_evidence": []}
{"question_id": "4140d8b5a78aea985546aa1e323de12f63d24add", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "61272b1d0338ed7708cf9ed9c63060a6a53e97a2", "predicted_answer": "1. accuracy of 82.6%", "predicted_evidence": []}
{"question_id": "53b02095ba7625d85721692fce578654f66bbdf0", "predicted_answer": "1. unanswerable", "predicted_evidence": []}
{"question_id": "0cd0755ac458c3bafbc70e4268c1e37b87b9721b", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "c1ce652085ef9a7f02cb5c363ce2b8757adbe213", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "96be67b1729c3a91ddf0ec7d6a80f2aa75e30a30", "predicted_answer": "1. english", "predicted_evidence": []}
{"question_id": "b85ab5f862221fac819cf2fef239bcb08b9cafc6", "predicted_answer": "1. localization accuracy", "predicted_evidence": []}
{"question_id": "7e34501255b89d64b9598b409d73f96489aafe45", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "e854edcc5e9111922e6e120ae17d062427c27ec1", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "bd6cec2ab620e67b3e0e7946fc045230e6906020", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "4b0ba460ae3ba7a813f204abd16cf631b871baca", "predicted_answer": "1. text clustering on the embeddings of texts", "predicted_evidence": []}
{"question_id": "63b0c93f0452d0e1e6355de1d0f3ff0fd67939fb", "predicted_answer": "1. quora duplicate question dataset bibref22", "predicted_evidence": []}
{"question_id": "d27f23bcd80b12f6df8e03e65f9b150444925ecf", "predicted_answer": "unfortunately, i don't have enough information about a specific fact-checking algorithm to provide its components. however, based on general knowledge of fact-checking algorithms, here are some common components:\n\n1. natural language processing (nlp)\n2. information retrieval\n3. knowledge graphs\n4. machine learning models\n5. claim detection and extraction\n\nplease note that these components may not be specific to a particular algorithm, but rather a general outline of what fact-checking algorithms might include.\n\nif you're looking for information on a specific algorithm, please provide more context or details about the algorithm you're interested in.", "predicted_evidence": []}
{"question_id": "b11ee27f3de7dd4a76a1f158dc13c2331af37d9f", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "7aba5e4483293f5847caad144ee0791c77164917", "predicted_answer": "1. wikihop", "predicted_evidence": []}
{"question_id": "565d668947ffa6d52dad019af79289420505889b", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "d83304c70fe66ae72e78aa1d183e9f18b7484cd6", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "e90ac9ee085dc2a9b6fe132245302bbce5f3f5ab", "predicted_answer": "1. unanswerable", "predicted_evidence": []}
{"question_id": "5b029ad0d20b516ec11967baaf7d2006e8d7199f", "predicted_answer": "more than two labels", "predicted_evidence": []}
{"question_id": "79bd2ad4cb5c630ce69d5a859ed118132cae62d7", "predicted_answer": "1. unanswerable", "predicted_evidence": []}
{"question_id": "d3a1a53521f252f869fdae944db986931d9ffe48", "predicted_answer": "2. the experts in the field", "predicted_evidence": []}
{"question_id": "38e11663b03ac585863742044fd15a0e875ae9ab", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "14421b7ae4459b647033b3ccba635d4ba7bb114b", "predicted_answer": "1. experts in washington post", "predicted_evidence": []}
{"question_id": "52f7e42fe8f27d800d1189251dfec7446f0e1d3b", "predicted_answer": "the proposed method is approximately 3-4% better than state-of-the-art methods in experiments.", "predicted_evidence": []}
{"question_id": "00e6324ecd454f5d4b2a4b27fcf4104855ff8ee2", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "aa0d67c2a1bc222d1f2d9e5d51824352da5bb6dc", "predicted_answer": "1. transe, transr and transh, ptranse, and all-paths, r-gcn bibref24 and kr-ear bibref26", "predicted_evidence": []}
{"question_id": "cf0085c1d7bd9bc9932424e4aba4e6812d27f727", "predicted_answer": "2", "predicted_evidence": []}
{"question_id": "586b7470be91efe246c3507b05e30651ea6b9832", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "31b20a4bab09450267dfa42884227103743e3426", "predicted_answer": "1. entity types or concepts bibref13, relations paths bibref17,  textual descriptions bibref11, bibref12, logical rules bibref23, deep neural network models bibref24", "predicted_evidence": []}
{"question_id": "45306b26447ea4b120655d6bb2e3636079d3d6e0", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "0c08af6e4feaf801185f2ec97c4da04c8b767ad6", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "6412e97373e8e9ae3aa20aa17abef8326dc05450", "predicted_answer": "1. human evaluators", "predicted_evidence": []}
{"question_id": "957bda6b421ef7d2839c3cec083404ac77721f14", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "368317b4fd049511e00b441c2e9550ded6607c37", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "b3ec918827cd22b16212265fcdd5b3eadee654ae", "predicted_answer": "#distantsupervision #weaksupervision #noisylabels", "predicted_evidence": []}
{"question_id": "387970ebc7ef99f302f318d047f708274c0e8f21", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "2fffff59e57b8dbcaefb437a6b3434fc137f813b", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "eb95af36347ed0e0808e19963fe4d058e2ce3c9f", "predicted_answer": "1. 51.7 and 51.6 on 4th and 8th grade question sets with no curated knowledge. 47.5 and 48.0 on 4th and 8th grade question sets when both solvers are given the same knowledge", "predicted_evidence": []}
{"question_id": "cd1792929b9fa5dd5b1df0ae06fc6aece4c97424", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "65d34041ffa4564385361979a08706b10b92ebc7", "predicted_answer": "1. no", "predicted_evidence": []}
{"question_id": "e215fa142102f7f9eeda9c9eb8d2aeff7f2a33ed", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "a8545f145d5ea2202cb321c8f93e75ad26fcf4aa", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "417dabd43d6266044d38ed88dbcb5fdd7a426b22", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "fed230cef7c130f6040fb04304a33bbc17ca3a36", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "7917d44e952b58ea066dc0b485d605c9a1fe3dda", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "7d5ba230522df1890619dedcfb310160958223c1", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "a48cc6d3d322a7b159ff40ec162a541bf74321eb", "predicted_answer": "word sense induction & disambiguation", "predicted_evidence": []}
{"question_id": "2bc0bb7d3688fdd2267c582ca593e2ce72718a91", "predicted_answer": "1. wordnet", "predicted_evidence": []}
{"question_id": "8c073b7ea8cb5cc54d7fecb8f4bf88c1fb621b19", "predicted_answer": "1. cosine similarity", "predicted_evidence": []}
{"question_id": "dcb18516369c3cf9838e83168357aed6643ae1b8", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "f46a907360d75ad566620e7f6bf7746497b6e4a9", "predicted_answer": "kyubyong park, edouard grave et al", "predicted_evidence": []}
{"question_id": "79d999bdf8a343ce5b2739db3833661a1deab742", "predicted_answer": "5. wrong range and tag", "predicted_evidence": []}
{"question_id": "71d59c36225b5ee80af11d3568bdad7425f17b0c", "predicted_answer": "0.18", "predicted_evidence": []}
{"question_id": "efc65e5032588da4a134d121fe50d49fe8fe5e8c", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "a30958c7123d1ad4723dcfd19d8346ccedb136d5", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "08333e4dd1da7d6b5e9b645d40ec9d502823f5d7", "predicted_answer": "1. 0.007 map on task a, 0.032 map on task b, 0.055 map on task c", "predicted_evidence": []}
{"question_id": "bc1bc92920a757d5ec38007a27d0f49cb2dde0d1", "predicted_answer": "i'm happy to help! however, i don't see a list of options provided for the question \"what is a strong feature-based method?\". the only option listed is \"1. unanswerable\", which doesn't seem relevant.\n\ncould you please provide more context or clarify what you mean by \"strong feature-based method\"? or perhaps provide additional options for me to choose from?", "predicted_evidence": []}
{"question_id": "942eb1f7b243cdcfd47f176bcc71de2ef48a17c4", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "9bffc9a9c527e938b2a95ba60c483a916dbd1f6b", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "8434974090491a3c00eed4f22a878f0b70970713", "predicted_answer": "1. proposed model has 1.16 million parameters and 11.04 mb.", "predicted_evidence": []}
{"question_id": "b67420da975689e47d3ea1c12b601851018c4071", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "01d91d356568fca79e47873bd0541bd22ba66ec0", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "37e45a3439b048a80c762418099a183b05772e6a", "predicted_answer": "they performed second on subtask a and well on subtask b.", "predicted_evidence": []}
{"question_id": "a4e66e842be1438e5cd8d7cb2a2c589f494aee27", "predicted_answer": "i'm happy to help! however, i don't see multiple options listed. you've only provided one option:\n\n1. depeche + svm\n\nif this is indeed the worst performer among the tested techniques, my response would be:\n\n1. depeche + svm", "predicted_evidence": []}
{"question_id": "cb78e280e3340b786e81636431834b75824568c3", "predicted_answer": "1. 6", "predicted_evidence": []}
{"question_id": "2941874356e98eb2832ba22eae9cb08ec8ce0308", "predicted_answer": "1. tf-idf + svm, depeche + svm, nrc + svm, tf-nrc + svm, doc2vec + svm,  hierarchical rnn, birnn + self-attention, elmo + birnn", "predicted_evidence": []}
{"question_id": "4e50e9965059899d15d3c3a0c0a2d73e0c5802a0", "predicted_answer": "1. 9710 passages, with an average of 6.24 sentences per passage, 16.16 words per sentence, and an average length of 86 words", "predicted_evidence": []}
{"question_id": "67d8e50ddcc870db71c94ad0ad7f8a59a6c67ca6", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "aecb485ea7d501094e50ad022ade4f0c93088d80", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "2fea3c955ff78220b2c31a8ad1322bc77f6706f8", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "faa4f28a2f2968cecb770d9379ab2cfcaaf5cfab", "predicted_answer": "none of the above options seem directly related to syntactic analysis. however, i'll take a guess:\n\n none of the above (but if i had to choose) 1. speaker's gender effects, interlocutors' gender and number effects", "predicted_evidence": []}
{"question_id": "da068b20988883bc324e55c073fb9c1a5c39be33", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "0d6d5b6c00551dd0d2519f117ea81d1e9e8785ec", "predicted_answer": "1. google neural machine translation (gnmt)", "predicted_evidence": []}
{"question_id": "edcde2b675cf8a362a63940b2bbdf02c150fe01f", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "d20d6c8ecd7cb0126479305d27deb0c8b642b09f", "predicted_answer": "fbanks with cepstral mean normalization (cmn), variance with mean normalization (cmvn)", "predicted_evidence": []}
{"question_id": "11e6b79f1f48ddc6c580c4d0a3cb9bcb42decb17", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "2677b88c2def3ed94e25a776599555a788d197f2", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "8ca31caa34cc5b65dc1d01d0d1f36bf8c4928805", "predicted_answer": "i think there may be a misunderstanding! you provided only one option, which is \"unanswerable\". however, i'll do my best to provide an alternative answer.\n\nin that case, my response would be: none of the above (since there's only one option). a more suitable answer could be: extemporaneous speech.", "predicted_evidence": []}
{"question_id": "9ab43f941c11a4b09a0e4aea61b4a5b4612e7933", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "5a02a3dd26485a4e4a77411b50b902d2bda3731b", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "579941de2838502027716bae88e33e79e69997a6", "predicted_answer": "for single-span questions: large-squad improves over mtmsnlarge baseline by 2.1 em and 1.55 f1.\n\nfor number type questions: mtmsnlarge baseline improves over large-squad by 3.11 em and 2.98 f1.\n\nfor date questions: large-squad improves over mtmsnlarge by 2.02 em, but mtmsnlarge improves over large-squad by 4.39 f1.", "predicted_evidence": []}
{"question_id": "9a65cfff4d99e4f9546c72dece2520cae6231810", "predicted_answer": "the proposed model achieves em 77.63 and f1 80.73 on the test and em 76.95 and f1 80.25 on the dev", "predicted_evidence": []}
{"question_id": "a9def7958eac7b9a780403d4f136927f756bab83", "predicted_answer": "mtmsn bibref4", "predicted_evidence": []}
{"question_id": "547be35cff38028648d199ad39fb48236cfb99ee", "predicted_answer": "1. unanswerable", "predicted_evidence": []}
{"question_id": "47a30eb4d0d6f5f2ff4cdf6487265a25c1b18fd8", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "e42fbf6c183abf1c6c2321957359c7683122b48e", "predicted_answer": "bilstm-xr accuracy is 83.31 for semeval-15 and 88.12 for semeval-16.", "predicted_evidence": []}
{"question_id": "e574f0f733fb98ecef3c64044004aa7a320439be", "predicted_answer": "displayform0", "predicted_evidence": []}
{"question_id": "b65b1c366c8bcf544f1be5710ae1efc6d2b1e2f1", "predicted_answer": "the lemming model in bibref17", "predicted_evidence": []}
{"question_id": "bd3ccb63fd8ce5575338d7332e96def7a3fabad6", "predicted_answer": "nlu-benchmark dataset", "predicted_evidence": []}
{"question_id": "7c794fa0b2818d354ca666969107818a2ffdda0c", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "1ef5fc4473105f1c72b4d35cf93d312736833d3d", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "5f9bd99a598a4bbeb9d2ac46082bd3302e961a0f", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "b2fab9ffbcf1d6ec6d18a05aeb6e3ab9a4dbf2ae", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "e9cf1b91f06baec79eb6ddfd91fc5d434889f652", "predicted_answer": "1. previous, next, ctrl+f <query>, stop", "predicted_evidence": []}
{"question_id": "6976296126e4a5c518e6b57de70f8dc8d8fde292", "predicted_answer": "1. feature concatenation model (fcm), spatial concatenation model (scm), textual kernels model (tkm)", "predicted_evidence": []}
{"question_id": "53640834d68cf3b86cf735ca31f1c70aa0006b72", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "b2b0321b0aaf58c3aa9050906ade6ef35874c5c1", "predicted_answer": "1. $150,000$ tweets", "predicted_evidence": []}
{"question_id": "4e9684fd68a242cb354fa6961b0e3b5c35aae4b6", "predicted_answer": "the multimodal model (fcm) has slightly better results than the unimodal lstm model in terms of f score (0.704 vs 0.703), auc (0.734 vs 0.732), and mean accuracy (68.4 vs 68.3).", "predicted_evidence": []}
{"question_id": "2e632eb5ad611bbd16174824de0ae5efe4892daf", "predicted_answer": "all of the above (1, 2, and 3)", "predicted_evidence": []}
{"question_id": "d1ff6cba8c37e25ac6b261a25ea804d8e58e09c0", "predicted_answer": "1. f-score, area under the roc curve (auc), mean accuracy (acc), precision vs recall plot, roc curve (which plots the true positive rate vs the false positive rate)", "predicted_evidence": []}
{"question_id": "24c0f3d6170623385283dfda7f2b6ca2c7169238", "predicted_answer": "1. twitter api", "predicted_evidence": []}
{"question_id": "21a9f1cddd7cb65d5d48ec4f33fe2221b2a8f62e", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "a0ef0633d8b4040bf7cdc5e254d8adf82c8eed5e", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "b0799e26152197aeb3aa3b11687a6cc9f6c31011", "predicted_answer": "1. feature concatenation model (fcm), spatial concatenation model (scm), textual kernels model (tkm)", "predicted_evidence": []}
{"question_id": "4ce4db7f277a06595014db181342f8cb5cb94626", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "62a6382157d5f9c1dce6e6c24ac5994442053002", "predicted_answer": "1. accuracy, normalized mutual information", "predicted_evidence": []}
{"question_id": "9e04730907ad728d62049f49ac828acb4e0a1a2a", "predicted_answer": "1. on searchsnippets dataset acc 77.01%, nmi 62.94%, on stackoverflow dataset acc 51.14%, nmi 49.08%, on biomedical dataset acc 43.00%, nmi 38.18%", "predicted_evidence": []}
{"question_id": "5a0841cc0628e872fe473874694f4ab9411a1d10", "predicted_answer": "1. on searchsnippets dataset by 6.72% in acc, by 6.94% in nmi; on biomedical dataset by 5.77% in acc, 3.91% in nmi", "predicted_evidence": []}
{"question_id": "a5dd569e6d641efa86d2c2b2e970ce5871e0963f", "predicted_answer": "1. k-means, skip-thought vectors, recursive neural network and paragraph vector based clustering methods", "predicted_evidence": []}
{"question_id": "785c054f6ea04701f4ab260d064af7d124260ccc", "predicted_answer": "1. searchsnippets, stackoverflow, biomedical", "predicted_evidence": []}
{"question_id": "3f6610d1d68c62eddc2150c460bf1b48a064e5e6", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "4c854d33a832f3f729ce73b206ff90677e131e48", "predicted_answer": "transformer type 1, transformer type 2, transformer type 3", "predicted_evidence": []}
{"question_id": "163c15da1aa0ba370a00c5a09294cd2ccdb4b96d", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "90dd5c0f5084a045fd6346469bc853c33622908f", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "095888f6e10080a958d9cd3f779a339498f3a109", "predicted_answer": "1. ai2 bibref2, cc bibref19, il bibref4, mawps bibref20", "predicted_evidence": []}
{"question_id": "57e783f00f594e08e43a31939aedb235c9d5a102", "predicted_answer": "auc-roc", "predicted_evidence": []}
{"question_id": "9646fa1abbe3102a0364f84e0a55d107d45c97f0", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "29983f4bc8a5513a198755e474361deee93d4ab6", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "6c0f97807cd83a94a4d26040286c6f89c4a0f8e0", "predicted_answer": "1. finite sequence of terms", "predicted_evidence": []}
{"question_id": "13ca4bf76565564c8ec3238c0cbfacb0b41e14d2", "predicted_answer": "1. 14 tds, bibref15", "predicted_evidence": []}
{"question_id": "70797f66d96aa163a3bee2be30a328ba61c40a18", "predicted_answer": "srcc (spearman rank correlation coefficient)", "predicted_evidence": []}
{"question_id": "71f2b368228a748fd348f1abf540236568a61b07", "predicted_answer": "1. unshuffled version of the french oscar corpus", "predicted_evidence": []}
{"question_id": "d3d4eef047aa01391e3e5d613a0f1f786ae7cfc7", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "63723c6b398100bba5dc21754451f503cb91c9b8", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "5471766ca7c995dd7f0f449407902b32ac9db269", "predicted_answer": "2.36 point increase in the f1 score", "predicted_evidence": []}
{"question_id": "dc49746fc98647445599da9d17bc004bafdc4579", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "8720c096c8b990c7b19f956ee4930d5f2c019e2b", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "b573b36936ffdf1d70e66f9b5567511c989b46b2", "predicted_answer": "1. unshuffled version of the french oscar corpus", "predicted_evidence": []}
{"question_id": "bf25a202ac713a34e09bf599b3601058d9cace46", "predicted_answer": "louvain clustering", "predicted_evidence": []}
{"question_id": "abebf9c8c9cf70ae222ecb1d3cabf8115b9fc8ac", "predicted_answer": "1. political events such as elections, corruption cases or justice decisions", "predicted_evidence": []}
{"question_id": "2df910c9806f0c379d7bb1bc2be2610438e487dc", "predicted_answer": "1. bibref32, bibref23, bibref33, discussions in four different languages: english, portuguese, spanish and french, occurring in five regions over the world: south and north america, western europe, central and southern asia.", "predicted_evidence": []}
{"question_id": "a2a3af59f3f18a28eb2ca7055e1613948f395052", "predicted_answer": "twitter", "predicted_evidence": []}
{"question_id": "d92f1c15537b33b32bfc436e6d017ae7d9d6c29a", "predicted_answer": "1. four different languages: english, portuguese, spanish and french", "predicted_evidence": []}
{"question_id": "fa3663567c48c27703e09c42930e51bacfa54905", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "7997b9971f864a504014110a708f215c84815941", "predicted_answer": "1. tweets noisy nature, use of creative spelling and punctuation, misspellings, slang, new words, urls, and genre-specific terminology and abbreviations, short (length limited) text", "predicted_evidence": []}
{"question_id": "0d1408744651c3847469c4a005e4a9dccbd89cf1", "predicted_answer": "accuracy, precision, recall, f1-score, and cohen's kappa are commonly used metrics to evaluate sentiment analysis on twitter.", "predicted_evidence": []}
{"question_id": "a3d83c2a1b98060d609e7ff63e00112d36ce2607", "predicted_answer": "1. 27.41 transformation on average of single seed sentence is available in dataset.", "predicted_evidence": []}
{"question_id": "aeda22ae760de7f5c0212dad048e4984cd613162", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "d5fa26a2b7506733f3fa0973e2fe3fc1bbd1a12d", "predicted_answer": "1.", "predicted_evidence": []}
{"question_id": "2d536961c6e1aec9f8491e41e383dc0aac700e0a", "predicted_answer": "1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15", "predicted_evidence": []}
{"question_id": "18482658e0756d69e39a77f8fcb5912545a72b9b", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "9d336c4c725e390b6eba8bb8fe148997135ee981", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "016b59daa84269a93ce821070f4f5c1a71752a8a", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "771b373d09e6eb50a74fffbf72d059ad44e73ab0", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "efb52bda7366d2b96545cf927f38de27de3b5b77", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "1a7d28c25bb7e7202230e1b70a885a46dac8a384", "predicted_answer": "unfortunately, i don't have enough information to provide a specific answer. therefore, my response is:\n\n1. unanswerable", "predicted_evidence": []}
{"question_id": "6bc45d4f908672945192390642da5a2760971c40", "predicted_answer": "unfortunately, i couldn't find a specific answer to this question. therefore, my response is:\n\n1. unanswerable", "predicted_evidence": []}
{"question_id": "48cc41c372d44b69a477998be449f8b81384786b", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "efb3a87845460655c53bd7365bcb8393c99358ec", "predicted_answer": "1. accuracy of 86.63 on sts, 85.14 on sanders and 80.9 on hcr", "predicted_evidence": []}
{"question_id": "0619fc797730a3e59ac146a5a4575c81517cc618", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "846a1992d66d955fa1747bca9a139141c19908e8", "predicted_answer": "1. stanford - twitter sentiment corpus (sts corpus), sanders - twitter sentiment corpus, health care reform (hcr)", "predicted_evidence": []}
{"question_id": "1ef8d1cb1199e1504b6b0daea52f2e4bd2ef7023", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "12d77ac09c659d2e04b5e3955a283101c3ad1058", "predicted_answer": "1. stanford - twitter sentiment corpus (sts corpus), sanders - twitter sentiment corpus, health care reform (hcr)", "predicted_evidence": []}
{"question_id": "d60a3887a0d434abc0861637bbcd9ad0c596caf4", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "69a7a6675c59a4c5fb70006523b9fe0f01ca415c", "predicted_answer": "1. link prediction , triplet classification", "predicted_evidence": []}
{"question_id": "60cb756d382b3594d9e1f4a5e2366db407e378ae", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "352a1bf734b2d7f0618e9e2b0dbed4a3f1787160", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "045dbdbda5d96a672e5c69442e30dbf21917a1ee", "predicted_answer": "unfortunately, i don't have enough information about \"the model\" being referred to in the question. can you please provide more context or clarify what specific model is being asked about? that way, i can try to provide a more accurate answer.\n\nif not, my best guess would be:\n\n1. unanswerable", "predicted_evidence": []}
{"question_id": "c20b012ad31da46642c553ce462bc0aad56912db", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "13e87f6d68f7217fd14f4f9a008a65dd2a0ba91c", "predicted_answer": "2", "predicted_evidence": []}
{"question_id": "89b9a2389166b992c42ca19939d750d88c5fa79b", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "dccc3b182861fd19ccce5bd00ce9c3f40451ed6e", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "98ba7a7aae388b1a77dd6cab890977251d906359", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "3da9a861dfa25ed486cff0ef657d398fdebf8a93", "predicted_answer": "1. noun wordnet semantic text exchange model (nwn-stem), general wordnet semantic text exchange model (gwn-stem), word2vec semantic text exchange model (w2v-stem)", "predicted_evidence": []}
{"question_id": "8c0a0747a970f6ea607ff9b18cfeb738502d9a95", "predicted_answer": "1. err of 19.05 with i-vectors and 15.52 with x-vectors", "predicted_evidence": []}
{"question_id": "529dabe7b4a8a01b20ee099701834b60fb0c43b0", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "a2be2bd84e5ae85de2ab9968147b3d49c84dfb7f", "predicted_answer": "1. genre, entertainment, interview, singing, play, movie, vlog, live broadcast, speech, drama, recitation and advertisement", "predicted_evidence": []}
{"question_id": "5699996a7a2bb62c68c1e62e730cabf1e3186eef", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "944d5dbe0cfc64bf41ea36c11b1d378c408d40b8", "predicted_answer": "unfortunately, i don't have enough information to provide a definitive answer. the options only list one model, \"x-vector\", but the question asks for a comparison between two models.\n\nhowever, based on my training data, i can try to make an educated guess. since there's only one option provided, i'll assume that x-vector is being compared to another model, possibly i-vector (a common competitor to x-vector in speaker recognition tasks).\n\nwith that assumption, my best guess would be:\n\n1. x-vector", "predicted_evidence": []}
{"question_id": "327e6c6609fbd4c6ae76284ca639951f03eb4a4c", "predicted_answer": "1. for i-vector system, performances are 11.75% inferior to voxceleb. for x-vector system, performances are 10.74% inferior to voxceleb", "predicted_evidence": []}
{"question_id": "df8cc1f395486a12db98df805248eb37c087458b", "predicted_answer": "1. sst (stanford sentiment treebank), subj (subjectivity dataset), mpqa opinion corpus, rt is another movie review sentiment dataset, trec is a dataset for classification of the six question types", "predicted_evidence": []}
{"question_id": "6e97c06f998f09256be752fa75c24ba853b0db24", "predicted_answer": "1. accuracy across six datasets", "predicted_evidence": []}
{"question_id": "de2d33760dc05f9d28e9dabc13bab2b3264cadb7", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "63bb39fd098786a510147f8ebc02408de350cb7c", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "6333845facb22f862ffc684293eccc03002a4830", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "a12a08099e8193ff2833f79ecf70acf132eda646", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "999b20dc14cb3d389d9e3ba5466bc3869d2d6190", "predicted_answer": "kim et al. (2019)", "predicted_evidence": []}
{"question_id": "ca4b66ffa4581f9491442dcec78ca556253c8146", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "b3ff166bd480048e099d09ba4a96e2e32b42422b", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "3703433d434f1913307ceb6a8cfb9a07842667dd", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "f7c34b128f8919e658ba4d5f1f3fc604fb7ff793", "predicted_answer": "1. textual inputs, knowledge bases, and images.", "predicted_evidence": []}
{"question_id": "d42031893fd4ba5721c7d37e1acb1c8d229ffc21", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "a999761aa976458bbc7b4f330764796446d030ff", "predicted_answer": "1. cross-lingual ne recognition", "predicted_evidence": []}
{"question_id": "f229069bcb05c2e811e4786c89b0208af90d9a25", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "6b55b558ed581759425ede5d3a6fcdf44b8082ac", "predicted_answer": "1. naive bayes, svm, maximum entropy classifiers", "predicted_evidence": []}
{"question_id": "3e3f5254b729beb657310a5561950085fa690e83", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "5bb96b255dab3e47a8a68b1ffd7142d0e21ebe2a", "predicted_answer": "tweet subjectivity can be measured using natural language processing (nlp) techniques such as sentiment analysis and machine learning algorithms that analyze the language and tone used in the tweet to determine its emotional tone and polarity.\n\nhowever, since there is only one option available which is \"unanswerable\", i will choose that.", "predicted_evidence": []}
{"question_id": "129c03acb0963ede3915415953317556a55f34ee", "predicted_answer": "1.", "predicted_evidence": []}
{"question_id": "58b3b630a31fcb9bffb510390e1ec30efe87bfbf", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "141dab98d19a070f1ce7e7dc384001d49125d545", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "afdad4c9bdebf88630262f1a9a86ac494f06c4c1", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "bfd4fc82ffdc5b2b32c37f4222e878106421ce2a", "predicted_answer": "1.", "predicted_evidence": []}
{"question_id": "1ce26783f0ff38925bfc07bbbb65d206e52c2d21", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "9213159f874b3bdd9b4de956a88c703aac988411", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "5f4e6ce4a811c4b3ab07335d89db2fd2a8d8d8b2", "predicted_answer": "1. accuracy", "predicted_evidence": []}
{"question_id": "a234bcbf2e41429422adda37d9e926b49ef66150", "predicted_answer": "1. classification accuracy, bleu scores, model perplexities of the reconstruction", "predicted_evidence": []}
{"question_id": "c383fa9170ae00a4a24a8e39358c38395c5f034b", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "83251fd4a641cea8b180b49027e74920bca2699a", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "5d70c32137e82943526911ebdf78694899b3c28a", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "97dac7092cf8082a6238aaa35f4b185343b914af", "predicted_answer": "1. either likely depressed-user population is younger, or depressed youngsters are more likely to disclose their age, more women than men were given a diagnosis of depression", "predicted_evidence": []}
{"question_id": "195611926760d1ceec00bd043dfdc8eba2df5ad1", "predicted_answer": "i'm not aware of a specific model that is widely recognized for achieving a 5% improvement on f1 score for identifying depressed individuals on twitter. however, i can try to provide an educated guess.\n\nbased on my knowledge, random forest classifier is often used in text classification tasks and has been shown to perform well in various studies. therefore, i'll take a chance and respond with:\n\n1. random forest classifier", "predicted_evidence": []}
{"question_id": "445e792ce7e699e960e2cb4fe217aeacdd88d392", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "a3b1520e3da29d64af2b6e22ff15d330026d0b36", "predicted_answer": "based on the options provided, here is the answer:\n\n* image data: facial presence, facial expression, general image features\n* textual data: textual content, analytical thinking, clout, authenticity, emotional tone, sixltr, informal language markers, 1st person singular pronouns", "predicted_evidence": []}
{"question_id": "2cf8825639164a842c3172af039ff079a8448592", "predicted_answer": "1. the data are self-reported by twitter users and then verified by two human experts.", "predicted_evidence": []}
{"question_id": "36b25021464a9574bf449e52ae50810c4ac7b642", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "98515bd97e4fae6bfce2d164659cd75e87a9fc89", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "53bf6238baa29a10f4ff91656c470609c16320e1", "predicted_answer": "1. users' tweets", "predicted_evidence": []}
{"question_id": "b27f7993b1fe7804c5660d1a33655e424cea8d10", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "e21a8581cc858483a31c6133e53dd0cfda76ae4c", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "9f6e877e3bde771595e8aee10c2656a0e7b9aeb2", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "a3783e42c2bf616c8a07bd3b3d503886660e4344", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "0d0959dba3f7c15ee4f5cdee51682656c4abbd8f", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "589be705a5cc73a23f30decba23ce58ec39d313b", "predicted_answer": "1. the dutch section of the oscar corpus", "predicted_evidence": []}
{"question_id": "6e962f1f23061f738f651177346b38fd440ff480", "predicted_answer": "1. bertje bibref8, an ulmfit model (universal language model fine-tuning for text classification model) bibref19., mbert", "predicted_evidence": []}
{"question_id": "594a6bf37eab64a16c6a05c365acc100e38fcff1", "predicted_answer": "1. sentiment analysis, the disambiguation of demonstrative pronouns", "predicted_evidence": []}
{"question_id": "d79d897f94e666d5a6fcda3b0c7e807c8fad109e", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "599d9ca21bbe2dbe95b08cf44dfc7537bde06f98", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "827464c79f33e69959de619958ade2df6f65fdee", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "8e857e44e4233193c7b2d538e520d37be3ae1552", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "084fb7c80a24b341093d4bf968120e3aff56f693", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "babe72f0491e65beff0e5889380e8e32d7a81f78", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "31ee92e521be110b6a5a8d08cc9e6f90a3a97aae", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "737397f66751624bcf4ef891a10b29cfc46b0520", "predicted_answer": "2. coha", "predicted_evidence": []}
{"question_id": "87cb19e453cf7e248f24b5f7d1ff9f02d87fc261", "predicted_answer": "a centroid model summarizes each set of seed words by its expected vector in embedding space, and classifies concepts into the class of closest expected embedding in euclidean distance following a softmax rule;", "predicted_evidence": []}
{"question_id": "5fb6a21d10adf4e81482bb5c1ec1787dc9de260d", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "542a87f856cb2c934072bacaa495f3c2645f93be", "predicted_answer": "1. care / harm, fairness / cheating, loyalty / betrayal, authority / subversion, and sanctity / degradation", "predicted_evidence": []}
{"question_id": "4fcc668eb3a042f60c4ce2e7d008e7923b25b4fc", "predicted_answer": "unfortunately, i couldn't find a specific dataset source that is widely recognized as demonstrating moral sentiment through history.\n\nso, my response would be:\n\n1. unanswerable", "predicted_evidence": []}
{"question_id": "c180f44667505ec03214d44f4970c0db487a8bae", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "76d62e414a345fe955dc2d99562ef5772130bc7e", "predicted_answer": "1. neural question-answering technique to extract relations from a story text, openie5, a commonly used rule-based information extraction technique", "predicted_evidence": []}
{"question_id": "6b9310b577c6232e3614a1612cbbbb17067b3886", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "d484a71e23d128f146182dccc30001df35cdf93f", "predicted_answer": "1. perplexity of the best model is 65.58 compared to best baseline 105.79.\nbleu of the best model is 6.57 compared to best baseline 5.50.", "predicted_evidence": []}
{"question_id": "5787ac3e80840fe4cf7bfae7e8983fa6644d6220", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "ee31c8a94e07b3207ca28caef3fbaf9a38d94964", "predicted_answer": "1. bleu, micro entity f1, quality of the responses according to correctness, fluency, and humanlikeness on a scale from 1 to 5", "predicted_evidence": []}
{"question_id": "66d743b735ba75589486e6af073e955b6bb9d2a4", "predicted_answer": "attn seq2seq, ptr-unk, kv net, mem2seq, dsr", "predicted_evidence": []}
{"question_id": "b9f852256113ef468d60e95912800fab604966f6", "predicted_answer": "camrest, incar assistant", "predicted_evidence": []}
{"question_id": "88f8ab2a417eae497338514142ac12c3cec20876", "predicted_answer": "1. unanswerable", "predicted_evidence": []}
{"question_id": "05e3b831e4c02bbd64a6e35f6c52f0922a41539a", "predicted_answer": "unfortunately, i don't have enough information to determine a specific interval for extracting video and audio frames. therefore, my response is:\n\n1. unanswerable", "predicted_evidence": []}
{"question_id": "bd74452f8ea0d1d82bbd6911fbacea1bf6e08cab", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "6472f9d0a385be81e0970be91795b1b97aa5a9cf", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "2173809eb117570d289cefada6971e946b902bd6", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "293e9a0b30670f4f0a380e574a416665a8c55bc2", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "17de58c17580350c9da9c2f3612784b432154d11", "predicted_answer": "1. multi-class naive bayes", "predicted_evidence": []}
{"question_id": "ff27d6e6eb77e55b4d39d343870118d1a6debd5e", "predicted_answer": "svm", "predicted_evidence": []}
{"question_id": "29772ba04886bee2d26b7320e1c6d9b156078891", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "94dc437463f7a7d68b8f6b57f1e3606eacc4490a", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "9d9d84822a9c42eb0257feb7c18086d390dae3be", "predicted_answer": "1. unanswerable", "predicted_evidence": []}
{"question_id": "d27e3a099954e917b6491e81b2e907478d7f1233", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "c0a11ba0f6bbb4c69b5a0d4ae9d18e86a4a8f354", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "dfc393ba10ec4af5a17e5957fcbafdffdb1a6443", "predicted_answer": "1. bimpm, esim, decomposable attention model, kim, bert", "predicted_evidence": []}
{"question_id": "311a7fa62721e82265f4e0689b4adc05f6b74215", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "82bcacad668351c0f81bd841becb2dbf115f000e", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "5937ebbf04f62d41b48cbc6b5c38fc309e5c2328", "predicted_answer": "1. quotation (\u2303q) dialogue acts, on the other hand, are mostly used with `anger' and `frustration', action directive (ad) dialogue act utterances, which are usually orders, frequently occur with `anger' or `frustration' although many with `happy' emotion in case of the meld dataset, acknowledgements (b) are mostly with positive or neutral, appreciation (ba) and rhetorical (bh) backchannels often occur with a greater number in `surprise', `joy' and/or with `excited' (in case of iemocap), questions (qh, qw, qy and qy\u2303d) are mostly asked with emotions `surprise', `excited', `frustration' or `disgust' (in case of meld) and many are neutral, no-answers (nn) are mostly `sad' or `frustrated' as compared to yes-answers (ny).", "predicted_evidence": []}
{"question_id": "dcd6f18922ac5c00c22cef33c53ff5ae08b42298", "predicted_answer": "1. first preference is given to the labels that are perfectly matching in all the neural annotators., in case two out of three context models are correct, then it is being checked if that label is also produced by at least one of the non-context models., when we see that none of the context models is producing the same results, then we rank the labels with their respective confidence values produced as a probability distribution using the $softmax$ function. the labels are sorted in descending order according to confidence values. then we check if the first three (case when one context model and both non-context models produce the same label) or at least two labels are matching, then we allow to pick that one. , finally, when none the above conditions are fulfilled, we leave out the label with an unknown category.", "predicted_evidence": []}
{"question_id": "2965c86467d12b79abc16e1457d848cb6ca88973", "predicted_answer": "1. damsl", "predicted_evidence": []}
{"question_id": "b99948ac4810a7fe3477f6591b8cf211d6398e67", "predicted_answer": "five", "predicted_evidence": []}
{"question_id": "73d657d6faed0c11c65b1ab60e553db57f4971ca", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "9ef182b61461d0d8b6feb1d6174796ccde290a15", "predicted_answer": "1. use an existing one", "predicted_evidence": []}
{"question_id": "f6f8054f327a2c084a73faca16cf24a180c094ae", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "b8f711179a468fec9a0d8a961fb0f51894af4b31", "predicted_answer": "1. cnn", "predicted_evidence": []}
{"question_id": "3bf429633ecbbfec3d7ffbcfa61fa90440cc918b", "predicted_answer": "1. apply an ensemble of deep learning and linguistic techniques", "predicted_evidence": []}
{"question_id": "94e0cf44345800ef46a8c7d52902f074a1139e1a", "predicted_answer": "ritter", "predicted_evidence": []}
{"question_id": "ad67ca844c63bf8ac9fdd0fa5f58c5a438f16211", "predicted_answer": "1. 1000 hours of wsj audio data", "predicted_evidence": []}
{"question_id": "12eaaf3b6ebc51846448c6e1ad210dbef7d25a96", "predicted_answer": "wav2vec has 12 convolutional layers", "predicted_evidence": []}
{"question_id": "828615a874512844ede9d7f7d92bdc48bb48b18d", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "a43c400ae37a8705ff2effb4828f4b0b177a74c4", "predicted_answer": "1.", "predicted_evidence": []}
{"question_id": "4056ee2fd7a0a0f444275e627bb881134a1c2a10", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "f6496b8d09911cdf3a9b72aec0b0be6232a6dba1", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "5c90e1ed208911dbcae7e760a553e912f8c237a5", "predicted_answer": "1. in-house dataset: 3716 documents, ace05 dataset: 1635 documents", "predicted_evidence": []}
{"question_id": "3c3b4797e2b21e2c31cf117ad9e52f327721790f", "predicted_answer": "english, german, spanish, italian, japanese and portuguese", "predicted_evidence": []}
{"question_id": "a7d72f308444616a0befc8db7ad388b3216e2143", "predicted_answer": "ace05 dataset", "predicted_evidence": []}
{"question_id": "dfb0351e8fa62ceb51ce77b0f607885523d1b8e8", "predicted_answer": "unfortunately, i don't have a specific numerical value to provide as an answer. however, based on general knowledge, i can suggest that using both language and vision for auto-completion is likely to perform better than only using language.\n\nif i had to choose from the options provided, i would say:\n\n1. unanswerable", "predicted_evidence": []}
{"question_id": "a130aa735de3b65c71f27018f20d3c068bafb826", "predicted_answer": "1. 16k images and 740k corresponding region descriptions", "predicted_evidence": []}
{"question_id": "0c1663a7f7750b399f40ef7b4bf19d5c598890ff", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "aa800b424db77e634e82680f804894bfa37f2a34", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "fbd47705262bfa0a2ba1440a2589152def64cbbd", "predicted_answer": "35%", "predicted_evidence": []}
{"question_id": "51aaec4c511d96ef5f5c8bae3d5d856d8bc288d3", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "3aee5c856e0ee608a7664289ffdd11455d153234", "predicted_answer": "1. for test-repeated set, em score of 61.17, f1 of 93.54, ed of 0.75 and gm of 61.36. for test-new set, em score of 41.71, f1 of 91.02, ed of 1.22 and gm of 41.81", "predicted_evidence": []}
{"question_id": "f42d470384ca63a8e106c7caf1cb59c7b92dbc27", "predicted_answer": "1. exact match, f1 score, edit distance and goal match", "predicted_evidence": []}
{"question_id": "29bdd1fb20d013b23b3962a065de3a564b14f0fb", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "25b2ae2d86b74ea69b09c140a41593c00c47a82b", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "fd7f13b63f6ba674f5d5447b6114a201fe3137cb", "predicted_answer": "1. english language", "predicted_evidence": []}
{"question_id": "c82e945b43b2e61c8ea567727e239662309e9508", "predicted_answer": "1. distinguishing between clinically positive and negative phenomena within each risk factor domain and accounting for structured data collected on the target cohort", "predicted_evidence": []}
{"question_id": "fbee81a9d90ff23603ee4f5986f9e8c0eb035b52", "predicted_answer": "1. achieved the highest per-domain scores on substance (f1 \u2248 0.8) and the lowest scores on interpersonal and mood (f1 \u2248 0.5), and show consistency in per-domain performance rankings between mlp and rbf models.", "predicted_evidence": []}
{"question_id": "39cf0b3974e8a19f3745ad0bcd1e916bf20eeab8", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "1f6180bba0bc657c773bd3e4269f87540a520ead", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "57388bf2693d71eb966d42fa58ab66d7f595e55f", "predicted_answer": "1.", "predicted_evidence": []}
{"question_id": "47796c7f0a7de76ccb97ccbd43dc851bb8a613d5", "predicted_answer": "1. morpheme segmentation and byte pair encoding (bpe)", "predicted_evidence": []}
{"question_id": "9d5153a7553b7113716420a6ddceb59f877eb617", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "55c840a2f1f663ab2bff984ae71501b17429d0c0", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "fa5357c56ea80a21a7ca88a80f21711c5431042c", "predicted_answer": "1. 36", "predicted_evidence": []}
{"question_id": "35915166ab2fd3d39c0297c427d4ac00e8083066", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "e6c872fea474ea96ca2553f7e9d5875df4ef55cd", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "fc29bb14f251f18862c100e0d3cd1396e8f2c3a1", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "f3e96c5487d87557a661a65395b0162033dc05b3", "predicted_answer": "1. zulu", "predicted_evidence": []}
{"question_id": "74db8301d42c7e7936eb09b2171cd857744c52eb", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "587885bc86543b8f8b134c20e2c62f6251195571", "predicted_answer": "1. english, spanish and zulu", "predicted_evidence": []}
{"question_id": "b72264a73eea36c828e7de778a8b4599a5d02b39", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "24cc1586e5411a7f8574796d3c576b7c677d6e21", "predicted_answer": "1. no", "predicted_evidence": []}
{"question_id": "db291d734524fa51fb314628b64ebe1bac7f7e1e", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "85abd60094c92eb16f39f861c6de8c2064807d02", "predicted_answer": "1. neural machine translation (nmt) models are trained between language pairs, using as source language the translation (word-level) and as target", "predicted_evidence": []}
{"question_id": "50f09a044f0c0795cc636c3e25a4f7c3231fb08d", "predicted_answer": "1. results show that similar languages rank better in terms of segmentation performance, and that by combining the information learned by different models, segmentation is further improved.", "predicted_evidence": []}
{"question_id": "26b5c090f72f6d51e5d9af2e470d06b2d7fc4a98", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "8c0621016e96d86a7063cb0c9ec20c76a2dba678", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "f1214a05cc0e6d870c789aed24a8d4c768e1db2f", "predicted_answer": "german-english, turkish-english, english-german", "predicted_evidence": []}
{"question_id": "41d3ab045ef8e52e4bbe5418096551a22c5e9c43", "predicted_answer": "1. iwslt14 german-english, iwslt14 turkish-english, wmt14 english-german", "predicted_evidence": []}
{"question_id": "62736ad71c76a20aee8e003c462869bab4ab4b1e", "predicted_answer": "1. draw our data from news publications, wine reviews, and reddit, develop new metrics for the agreement of binomial orderings across communities and the movement of binomial orderings over time,  develop a null model to determine how much variation in binomial orderings we might expect across communities and across time", "predicted_evidence": []}
{"question_id": "aaf50a6a9f449389ef212d25d0fae59c10b0df92", "predicted_answer": "1. news publications, wine reviews, and reddit", "predicted_evidence": []}
{"question_id": "a1917232441890a89b9a268ad8f987184fa50f7a", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "574f17134e4dd041c357ebb75a7ef590da294d22", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "41fd359b8c1402b31b6f5efd660143d1414783a0", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "d216d715ec27ee2d4949f9e908895a18fb3238e2", "predicted_answer": "1. word length, number of phonemes, number of syllables, alphabetical order, and frequency", "predicted_evidence": []}
{"question_id": "ba973b13f26cd5eb1da54663c0a72842681d5bf5", "predicted_answer": "1. news publications, wine reviews, and reddit", "predicted_evidence": []}
{"question_id": "508580af51483b5fb0df2630e8ea726ff08d537b", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "89d1687270654979c53d0d0e6a845cdc89414c67", "predicted_answer": "1. using crowdsourcing", "predicted_evidence": []}
{"question_id": "fc6cfac99636adda28654e1e19931c7394d76c7c", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "ed7a3e7fc1672f85a768613e7d1b419475950ab4", "predicted_answer": "1. single-domain setting", "predicted_evidence": []}
{"question_id": "72ceeb58e783e3981055c70a3483ea706511fac3", "predicted_answer": "1. joint goal accuracy", "predicted_evidence": []}
{"question_id": "9bfa46ad55136f2a365e090ce585fc012495393c", "predicted_answer": "multiwoz", "predicted_evidence": []}
{"question_id": "42812113ec720b560eb9463ff5e74df8764d1bff", "predicted_answer": "unfortunately, i don't have enough information to provide a specific answer. however, based on general knowledge of automatic theorem provers, i'll take a guess.\n\nsince there's only one option available, and it says \"unanswerable\", i'm going to assume that the question is indeed unanswerable without more context or information about the specific automatic theorem prover being referred to.\n\nso, my response would be:\n\n1. unanswerable", "predicted_evidence": []}
{"question_id": "4f4892f753b1d9c5e5e74c7c94d8c9b6ef523e7b", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "f258ada8577bb71873581820a94695f4a2c223b3", "predicted_answer": "1. 70,000", "predicted_evidence": []}
{"question_id": "05bb75a1e1202850efa9191d6901de0a34744af0", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "770aeff30846cd3d0d5963f527691f3685e8af02", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "f7817b949605fb04b1e4fec9dd9ca8804fb92ae9", "predicted_answer": "none of the above options are provided as a correct answer choice, but i will still give an answer based on general knowledge.\n\nthe best answer is: none of the above (the reason is likely due to differences in linguistic structures and grammatical rules between languages).", "predicted_evidence": []}
{"question_id": "8255f74cae1352e5acb2144fb857758dda69be02", "predicted_answer": "1. by calculating log ratio of grammatical phrase over ungrammatical phrase", "predicted_evidence": []}
{"question_id": "db62d5d83ec187063b57425affe73fef8733dd28", "predicted_answer": "1. markov random field with an optional neural parameterization", "predicted_evidence": []}
{"question_id": "946676f1a836ea2d6fe98cb4cfc26b9f4f81984d", "predicted_answer": "1. unanswerable", "predicted_evidence": []}
{"question_id": "3b090b416c4ad7d9b5b05df10c5e7770a4590f6a", "predicted_answer": "1. unanswerable", "predicted_evidence": []}
{"question_id": "a1e07c7563ad038ee2a7de5093ea08efdd6077d4", "predicted_answer": "1. (about 4 million sentences, 138 million word tokens)", "predicted_evidence": []}
{"question_id": "a1c4f9e8661d4d488b8684f055e0ee0e2275f767", "predicted_answer": "1. recurrent neural network (rnn), actionlstm, generative recurrent neural network grammars (rnng)", "predicted_evidence": []}
{"question_id": "c5171daf82107fce0f285fa18f19e91fbd1215c5", "predicted_answer": "1. the evaluation metrics include bleu and rouge (1, 2, l) scores.", "predicted_evidence": []}
{"question_id": "baeb6785077931e842079e9d0c9c9040947ffa4e", "predicted_answer": "1. the e2e nlg challenge dataset bibref21", "predicted_evidence": []}
{"question_id": "bb570d4a1b814f508a07e74baac735bf6ca0f040", "predicted_answer": "1. better sentence pair representations", "predicted_evidence": []}
{"question_id": "1771a55236823ed44d3ee537de2e85465bf03eaf", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "1d74fd1d38a5532d20ffae4abbadaeda225b6932", "predicted_answer": "1. f1 score and recall are 68.66, 80.08 with traditional ners as reference and 59.56, 69.76 with wikipedia titles as reference.", "predicted_evidence": []}
{"question_id": "da8bda963f179f5517a864943dc0ee71249ee1ce", "predicted_answer": "1. 4 layers", "predicted_evidence": []}
{"question_id": "5c059a13d59947f30877bed7d0180cca20a83284", "predicted_answer": "1. unanswerable", "predicted_evidence": []}
{"question_id": "a1885f807753cff7a59f69b5cf6d0fdef8484057", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "c2553166463b7b5ae4d9786f0446eb06a90af458", "predicted_answer": "1.", "predicted_evidence": []}
{"question_id": "cc9f0ac8ead575a9b485a51ddc06b9ecb2e2a44d", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "69e678666d11731c9bfa99953e2cd5a5d11a4d4f", "predicted_answer": "sparc and cosql", "predicted_evidence": []}
{"question_id": "471d624498ab48549ce492ada9e6129da05debac", "predicted_answer": "all of them.", "predicted_evidence": []}
{"question_id": "f858031ebe57b6139af46ee0f25c10870bb00c3c", "predicted_answer": "sparc and cosql", "predicted_evidence": []}
{"question_id": "1763a029daca7cab10f18634aba02a6bd1b6faa7", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "f9de9ddea0c70630b360167354004ab8cbfff041", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "fc8bc6a3c837a9d1c869b7ee90cf4e3c39bcd102", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "58e65741184c81c9e7fe0ca15832df2d496beb6f", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "269b05b74d5215b09c16e95a91ae50caedd9e2aa", "predicted_answer": "1. agreement rates, kappa value", "predicted_evidence": []}
{"question_id": "0d7f514f04150468b2d1de9174c12c28e52c5511", "predicted_answer": "1. agreement of 0.85 and kappa value of 0.83", "predicted_evidence": []}
{"question_id": "4d223225dbf84a80e2235448a4d7ba67bfb12490", "predicted_answer": "1. removing altlexc and adding progression into our sense hierarchy", "predicted_evidence": []}
{"question_id": "ca26cfcc755f9d0641db0e4d88b4109b903dbb26", "predicted_answer": "the results are approximately 9-10% better compared to baseline models.", "predicted_evidence": []}
{"question_id": "6cdd61ebf84aa742155f4554456cc3233b6ae2bf", "predicted_answer": "svm with rbf kernel", "predicted_evidence": []}
{"question_id": "8e8097cada29d89ca07166641c725e0f8fed6676", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "951098f0b7169447695b47c142384f278f451a1e", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "07c59824f5e7c5399d15491da3543905cfa5f751", "predicted_answer": "1. 4,261  days for france and 4,748 for the uk", "predicted_evidence": []}
{"question_id": "77f04cd553df691e8f4ecbe19da89bc32c7ac734", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "728a55c0f628f2133306b6bd88af00eb54017b12", "predicted_answer": "1.", "predicted_evidence": []}
{"question_id": "d5498d16e8350c9785782b57b1e5a82212dbdaad", "predicted_answer": "i can't verify the accuracy of a model trained on text exclusively.", "predicted_evidence": []}
{"question_id": "3e839783d8a4f2fe50ece4a9b476546f0842b193", "predicted_answer": "1. f1 score of 66.66%", "predicted_evidence": []}
{"question_id": "2869d19e54fb554fcf1d6888e526135803bb7d75", "predicted_answer": "1. f1 score of 82.10%", "predicted_evidence": []}
{"question_id": "894c086a2cbfe64aa094c1edabbb1932a3d7c38a", "predicted_answer": "1. for sentiment analysis uwb, inf-ufrgs-opinion-mining, litismind, pkudblab and svm + n-grams + sentiment and for emotion analysis maxent, svm, lstm, bilstm and cnn", "predicted_evidence": []}
{"question_id": "722e9b6f55971b4c48a60f7a9fe37372f5bf3742", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "9c2f306044b3d1b3b7fdd05d1c046e887796dd7a", "predicted_answer": "1. semeval 2016 task 6 bibref7, stance sentiment emotion corpus (ssec) bibref15", "predicted_evidence": []}
{"question_id": "3d99bc8ab2f36d4742e408f211bec154bc6696f7", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "9219eef636ddb020b9d394868959325562410f83", "predicted_answer": "1. bibref7, bibref39, bibref37, litismind, maximum entropy, svm, lstm, bi-lstm, and cnn", "predicted_evidence": []}
{"question_id": "ff83eea2df9976c1a01482818340871b17ad4f8c", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "0ee20a3a343e1e251b74a804e9aa1393d17b46d6", "predicted_answer": "1. quality of the classifier predictions is too low to be integrated into the network analysis right away, the classifier drastically facilitates the annotation process for human annotators compared to annotating unfiltered tweets", "predicted_evidence": []}
{"question_id": "f0e8f045e2e33a2129e67fb32f356242db1dc280", "predicted_answer": "1.", "predicted_evidence": []}
{"question_id": "b6c235d5986914b380c084d9535a7b01310c0278", "predicted_answer": "3", "predicted_evidence": []}
{"question_id": "e9b1e8e575809f7b80b1125305cfa76ae4f5bdfb", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "1e4450e23ec81fdd59821055f998fd9db0398b16", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "02ce4c288df14a90a210cb39973c6ac0fb4cec59", "predicted_answer": "english", "predicted_evidence": []}
{"question_id": "60726d9792d301d5ff8e37fbb31d5104a520dea3", "predicted_answer": "1. mh17 twitter dataset", "predicted_evidence": []}
{"question_id": "e39d90b8d959697d9780eddce3a343e60543be65", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "c6e63e3b807474e29bfe32542321d015009e7148", "predicted_answer": "1. set/change destination, set/change route, go faster, go slower, stop, park, pull over, drop off, open door, other", "predicted_evidence": []}
{"question_id": "4ef2fd79d598accc54c084f0cca8ad7c1b3f892a", "predicted_answer": "1. 3347 unique utterances", "predicted_evidence": []}
{"question_id": "40e3639b79e2051bf6bce300d06548e7793daee0", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "8383e52b2adbbfb533fbe8179bc8dae11b3ed6da", "predicted_answer": "1. set/change destination, set/change route, go faster, go slower, stop, park, pull over, drop off, open door, other", "predicted_evidence": []}
{"question_id": "5f7850254b723adf891930c6faced1058b99bd57", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "4d05a264b2353cff310edb480a917d686353b007", "predicted_answer": "1. the hmm can identify punctuation or pick up on vowels.", "predicted_evidence": []}
{"question_id": "7cdce4222cea6955b656c1a3df1129bb8119e2d0", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "6ea63327ffbab2fc734dd5c2414e59d3acc56ea5", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "50690b72dc61748e0159739a9a0243814d37f360", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "8266642303fbc6a1138b4e23ee1d859a6f584fbb", "predicted_answer": "bibref3, bibref4, bibref9", "predicted_evidence": []}
{"question_id": "3685bf2409b23c47bfd681989fb4a763bcab6be2", "predicted_answer": "1. 300 dimensional glove", "predicted_evidence": []}
{"question_id": "19225e460fff2ac3aebc7fe31fcb4648eda813fb", "predicted_answer": "common crawl", "predicted_evidence": []}
{"question_id": "f37026f518ab56c859f6b80b646d7f19a7b684fa", "predicted_answer": "150k", "predicted_evidence": []}
{"question_id": "1231934db6adda87c1b15e571468b8e9d225d6fe", "predicted_answer": "100k", "predicted_evidence": []}
{"question_id": "81303f605da57ddd836b7c121490b0ebb47c60e7", "predicted_answer": "the sr and hate datasets.", "predicted_evidence": []}
{"question_id": "a3f108f60143d13fe38d911b1cc3b17bdffde3bd", "predicted_answer": "proposed model achieves 0.86, 0.924, 0.71 f1 score on sr, hate, har datasets respectively.", "predicted_evidence": []}
{"question_id": "118ff1d7000ea0d12289d46430154cc15601fd8e", "predicted_answer": "i don't have enough information to determine what \"the baseline\" refers to. can you please provide more context or clarify what you are asking about?", "predicted_evidence": []}
{"question_id": "102a0439739428aac80ac11795e73ce751b93ea1", "predicted_answer": "kftt bibref12 and btec bibref13", "predicted_evidence": []}
{"question_id": "d9c26c1bfb3830c9f3dbcccf4c8ecbcd3cb54404", "predicted_answer": "1. english-japanese", "predicted_evidence": []}
{"question_id": "04f72eddb1fc73dd11135a80ca1cf31e9db75578", "predicted_answer": "1. 278 more annotations", "predicted_evidence": []}
{"question_id": "f74eaee72cbd727a6dffa1600cdf1208672d713e", "predicted_answer": "1. qa pairs per predicate", "predicted_evidence": []}
{"question_id": "068dbcc117c93fa84c002d3424bafb071575f431", "predicted_answer": "1. inter-annotator agreement, comparison against expert annotation, agreement with propbank data annotations.", "predicted_evidence": []}
{"question_id": "96526a14820b7debfd6f7c5beeade0a854b93d1a", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "32ba4d2d15194e889cbc9aa1d21ff1aa6fa27679", "predicted_answer": "1. extensive personal feedback", "predicted_evidence": []}
{"question_id": "78c010db6413202b4063dc3fb6e3cc59ec16e7e3", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "a69af5937cab861977989efd72ad1677484b5c8c", "predicted_answer": "1. the annotation machinery of bibref5", "predicted_evidence": []}
{"question_id": "8847f2c676193189a0f9c0fe3b86b05b5657b76a", "predicted_answer": "1. 1593 annotations", "predicted_evidence": []}
{"question_id": "05196588320dfb0b9d9be7d64864c43968d329bc", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "e930f153c89dfe9cff75b7b15e45cd3d700f4c72", "predicted_answer": "unfortunately, i don't have enough information to provide a specific answer. therefore, my response is:\n\n1. unanswerable", "predicted_evidence": []}
{"question_id": "545ff2f76913866304bfacdb4cc10d31dbbd2f37", "predicted_answer": "1. wmt 2014 en-fr parallel corpus", "predicted_evidence": []}
{"question_id": "cf93a209c8001ffb4ef505d306b6ced5936c6b63", "predicted_answer": "1. late 2014", "predicted_evidence": []}
{"question_id": "fb5ce11bfd74e9d7c322444b006a27f2ff32a0cf", "predicted_answer": "1. 96-97.6% using the objects color or shape and 79% using shape alone", "predicted_evidence": []}
{"question_id": "1e2ffa065b640e912d6ed299ff713a12195e12c4", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "28b2a20779a78a34fb228333dc4b93fd572fda15", "predicted_answer": "1. supervised learning", "predicted_evidence": []}
{"question_id": "b367b823c5db4543ac421d0057b02f62ea16bf9f", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "84737d871bde8058d8033e496179f7daec31c2d3", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "7b3d207ed47ae58286029b62fd0c160a0145e73d", "predicted_answer": "unfortunately, i don't have enough information about the paper you're referring to, so my response is:\n\n1. unanswerable", "predicted_evidence": []}
{"question_id": "d58c264068d8ca04bb98038b4894560b571bab3e", "predicted_answer": "1. unanswerable", "predicted_evidence": []}
{"question_id": "f80d89fb905b3e7e17af1fe179b6f441405ad79b", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "5f6fac08c97c85d5f4f4d56d8b0691292696f8e6", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "6adec34d86095643e6b89cda5c7cd94f64381acc", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "62ba1fefc1eb826fe0cbac092d37a3e2098967e9", "predicted_answer": "none of the above options seem directly related to a clear definition of \"baseline\". however, i'll take a guess that in many contexts, especially in data science and machine learning, a baseline often refers to a simple or standard method used for comparison. given the options provided:\n\n1. random method \n\nthis option seems more plausible as a baseline because it represents a basic, non-optimized approach against which other methods (like lstm) can be compared.", "predicted_evidence": []}
{"question_id": "93ac147765ee2573923f68aa47741d4bcbf88fa8", "predicted_answer": "1. non-contextual properties of a word, word usage in an op or pc (two groups), how a word connects an op and pc., general op/pc properties", "predicted_evidence": []}
{"question_id": "14c0328e8ec6360a913b8ecb3e50cb27650ff768", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "6073fa9050da76eeecd8aa3ccc7ecb16a238d83f", "predicted_answer": "1. f1 score", "predicted_evidence": []}
{"question_id": "eacd7e540cc34cb45770fcba463f4bf968681d59", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "1124804c3702499b78cf0678bab5867e81284b6c", "predicted_answer": "1. non-contextual properties of a word, word usage in an op or pc (two groups), how a word connects an op and pc, general op/pc properties", "predicted_evidence": []}
{"question_id": "2b78052314cb730824836ea69bc968df7964b4e4", "predicted_answer": "1. squad", "predicted_evidence": []}
{"question_id": "11d2f0d913d6e5f5695f8febe2b03c6c125b667c", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "1c85a25ec9d0c4f6622539f48346e23ff666cd5f", "predicted_answer": "5 questions per image", "predicted_evidence": []}
{"question_id": "37d829cd42db9ae3d56ab30953a7cf9eda050841", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "4b41f399b193d259fd6e24f3c6e95dc5cae926dd", "predicted_answer": "1. for the question generation model 15,000 images with 75,000 questions. for the chatbot model, around 460k utterances over 230k dialogues.", "predicted_evidence": []}
{"question_id": "76377e5bb7d0a374b0aefc54697ac9cd89d2eba8", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "85aa125b3a15bbb6f99f91656ca2763e8fbdb0ff", "predicted_answer": "1. precision@1, mean average precision, mean reciprocal rank", "predicted_evidence": []}
{"question_id": "4b128f9e94d242a8e926bdcb240ece279d725729", "predicted_answer": "dbqa, kbre", "predicted_evidence": []}
{"question_id": "f8f13576115992b0abb897ced185a4f9d35c5de9", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "1fdcc650c65c11908f6bde67d5052087245f3dde", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "abad9beb7295d809d7e5e1407cbf673c9ffffd19", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "265c9b733e4dfffb76acfbade4c0c9b14d3ccde1", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "0f928732f226185c76ad5960402e9342c0619310", "predicted_answer": "1. feedforward neural networks (dnns), convolutional neural networks (cnns)", "predicted_evidence": []}
{"question_id": "11c5b12e675cfd8d1113724f019d8476275bd700", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "d24acc567ebaec1efee52826b7eaadddc0a89e8b", "predicted_answer": "1. 10700", "predicted_evidence": []}
{"question_id": "2d62a75af409835e4c123a615b06235a352a67fe", "predicted_answer": "convolutional neural networks", "predicted_evidence": []}
{"question_id": "fffbd6cafef96eeeee2f9fa5d8ab2b325ec528e6", "predicted_answer": "1. 58", "predicted_evidence": []}
{"question_id": "c034f38a570d40360c3551a6469486044585c63c", "predicted_answer": "1. perplexity of proposed meed model is 19.795 vs 19.913 of next best result on test set.", "predicted_evidence": []}
{"question_id": "9cbea686732b5b85f77868ca47d2f93cf34516ed", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "6aee16c4f319a190c2a451c1c099b66162299a28", "predicted_answer": "(1) grammatical correctness, (2) contextual coherence, (3) emotional appropriateness", "predicted_evidence": []}
{"question_id": "4d4b9ff2da51b9e0255e5fab0b41dfe49a0d9012", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "180047e1ccfc7c98f093b8d1e1d0479a4cca99cc", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "fb3687ea05d38b5e65fdbbbd1572eacd82f56c0b", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "b5d6357d3a9e3d5fdf9b344ae96cddd11a407875", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "f33a21c6a9c75f0479ffdbb006c40e0739134716", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "8a1d4ed00d31c1f1cb05bc9d5e4f05fe87b0e5a4", "predicted_answer": "1. authors", "predicted_evidence": []}
{"question_id": "17f5f4a5d943c91d46552fb75940b67a72144697", "predicted_answer": "1. the rank-correlation for mfh model increases by 36.4% when is evaluated in vqa-hat dataset and 7.7% when is evaluated in vqa-x", "predicted_evidence": []}
{"question_id": "83f22814aaed9b5f882168e22a3eac8f5fda3882", "predicted_answer": "1. rank-correlation bibref25", "predicted_evidence": []}
{"question_id": "ed11b4ff7ca72dd80a792a6028e16ba20fccff66", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "a48c6d968707bd79469527493a72bfb4ef217007", "predicted_answer": "1. multinli", "predicted_evidence": []}
{"question_id": "b69897deb5fb80bf2adb44f9cbf6280d747271b3", "predicted_answer": "1. bert", "predicted_evidence": []}
{"question_id": "ad1f230f10235413d1fe501e414358245b415476", "predicted_answer": "1. bilstm-max, hbmp, esim, kim, esim + elmo, and bert", "predicted_evidence": []}
{"question_id": "0a521541b9e2b5c6d64fb08eb318778eba8ac9f7", "predicted_answer": "snli, multinli and sick", "predicted_evidence": []}
{"question_id": "11e376f98df42f487298ec747c32d485c845b5cd", "predicted_answer": "1. unanswerable", "predicted_evidence": []}
{"question_id": "284ea817fd79bc10b7a82c88d353e8f8a9d7e93c", "predicted_answer": "i'm happy to help! however, i don't see a question provided. please go ahead and ask your question, and i'll do my best to assist you.\n\nif you meant to ask if the data is all in vietnamese, here's an answer based on no context:\n\n1. yes", "predicted_evidence": []}
{"question_id": "c0122190119027dc3eb51f0d4b4483d2dbedc696", "predicted_answer": "textcnn", "predicted_evidence": []}
{"question_id": "1ed6acb88954f31b78d2821bb230b722374792ed", "predicted_answer": "1. private dashboard is leaderboard where competitors can see results after competition is finished - on hidden part of test set (private test set).", "predicted_evidence": []}
{"question_id": "5a33ec23b4341584a8079db459d89a4e23420494", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "1b9119813ea637974d21862a8ace83bc1acbab8e", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "8abb96b2450ebccfcc5c98772cec3d86cd0f53e0", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "f52ec4d68de91dba66668f0affc198706949ff90", "predicted_answer": "1. men-video games", "predicted_evidence": []}
{"question_id": "225a567eeb2698a9d3f1024a8b270313a6d15f82", "predicted_answer": "rnn model, cnn model , rnn-cnn model, attn1511 model, deep averaging network model, avg mean of word embeddings in the sentence with projection matrix", "predicted_evidence": []}
{"question_id": "35b10e0dc2cb4a1a31d5692032dc3fbda933bf7d", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "f5eac66c08ebec507c582a2445e99317a83e9ebe", "predicted_answer": "1. unanswerable", "predicted_evidence": []}
{"question_id": "62613aca3d7c7d534c9f6d8cb91ff55626bb8695", "predicted_answer": "1. argus dataset, ai2-8grade/ck12 dataset, mctest dataset", "predicted_evidence": []}
{"question_id": "6e4505609a280acc45b0a821755afb1b3b518ffd", "predicted_answer": "the bleu metric", "predicted_evidence": []}
{"question_id": "9bd938859a8b063903314a79f09409af8801c973", "predicted_answer": "1. wmt14 en-fr and en-de datasets, iwslt de-en and en-vi datasets", "predicted_evidence": []}
{"question_id": "68ba5bf18f351e8c83fae7b444cc50bef7437f13", "predicted_answer": "i think there may be a misunderstanding here!\n\nsince i only have one option provided, and it's not clear if this is the correct answer or just an example, i'll do my best to provide three main machine translation tasks based on general knowledge.\n\nhere are three main machine translation tasks:\n\n1. de-en (german to english)\n2. en-fr (english to french)\n3. zh-en (chinese to english)\n\nplease let me know if this is what you were looking for!", "predicted_evidence": []}
{"question_id": "f6a1125c5621a2f32c9bcdd188dff14efa096083", "predicted_answer": "1. 2.2 bleu gains", "predicted_evidence": []}
{"question_id": "282aa4e160abfa7569de7d99b8d45cabee486ba4", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "ecfb2e75eb9a8eba8f640a039484874fa0d2fceb", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "a6950c22c7919f86b16384facc97f2cf66e5941d", "predicted_answer": "inlineform0 (semeval 2014), inlineform1 (semeval 2014), inlineform2 (semeval 2015) and inlineform3 (semeval 2016).", "predicted_evidence": []}
{"question_id": "54be3541cfff6574dba067f1e581444537a417db", "predicted_answer": "5.0%, 1.6%, 1.4%, 1.3%", "predicted_evidence": []}
{"question_id": "221e9189a9d2431902d8ea833f486a38a76cbd8e", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "a276d5931b989e0a33f2a0bc581456cca25658d9", "predicted_answer": "1. 3-gram and 4-gram conditional language model, convolution, lstm models bibref27 with and without attention bibref28, transformer, gpt-2", "predicted_evidence": []}
{"question_id": "c21d26130b521c9596a1edd7b9ef3fe80a499f1e", "predicted_answer": "1. ordering pizza, creating auto repair appointments, setting up ride service, ordering movie tickets, ordering coffee drinks and making restaurant reservations", "predicted_evidence": []}
{"question_id": "ec8043290356fcb871c2f5d752a9fe93a94c2f71", "predicted_answer": "1. general classification tasks, use of the methodology in other networked systems, a network could be enriched with embeddings obtained from graph embeddings techniques", "predicted_evidence": []}
{"question_id": "728c2fb445173fe117154a2a5482079caa42fe24", "predicted_answer": "1. long-range syntactical links, though less frequent than adjacent syntactical relationships, might be disregarded from a simple word adjacency approach", "predicted_evidence": []}
{"question_id": "23d32666dfc29ed124f3aa4109e2527efa225fbc", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "076928bebde4dffcb404be216846d9d680310622", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "f33236ebd6f5a9ccb9b9dbf05ac17c3724f93f91", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "66bf0d61ffc321f15e7347aaed191223f4ce4b4a", "predicted_answer": "2,060 workers", "predicted_evidence": []}
{"question_id": "5dfa59c116e0ceb428efd99bab19731aa3df4bbd", "predicted_answer": "6980", "predicted_evidence": []}
{"question_id": "0c557b408183630d1c6c325b5fb9ff1573661290", "predicted_answer": "1. 0.16%", "predicted_evidence": []}
{"question_id": "a08b5018943d4428f067c08077bfff1af3de9703", "predicted_answer": "neutral class", "predicted_evidence": []}
{"question_id": "9447ec36e397853c04dcb8f67492ca9f944dbd4b", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "12c6ca435f4fcd4ad5ea5c0d76d6ebb9d0be9177", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "32c149574edf07b1a96d7f6bc49b95081de1abd2", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "3de27c81af3030eb2d9de1df5ec9bfacdef281a9", "predicted_answer": "1. $421\\,829\\,960$ words divided into $17\\,305\\,401$ sentences", "predicted_evidence": []}
{"question_id": "cc680cb8f45aeece10823a3f8778cf215ccc8af0", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "fab4ec639a0ea1e07c547cdef1837c774ee1adb8", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "9190c56006ba84bf41246a32a3981d38adaf422c", "predicted_answer": "1. extracted from a dump of the italian wikipedia (dated 2019.04.01), from the main categories of italian google news (world, nation, business, technology, entertainment, sports, science, health) and from some anonymized chats between users and a customer care chatbot (laila)", "predicted_evidence": []}
{"question_id": "7aab78e90ba1336950a2b0534cc0cb214b96b4fd", "predicted_answer": "1. an additional morphology table including target-side affixes., we inject the decoder with morphological properties of the target language.", "predicted_evidence": []}
{"question_id": "b7fe91e71da8f4dc11e799b3bd408d253230e8c6", "predicted_answer": "1. target-side affixes", "predicted_evidence": []}
{"question_id": "16fa6896cf4597154363a6c9a98deb49fffef15f", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "0f60864503ecfd5b048258e21d548ab5e5e81772", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "fe578842021ccfc295209a28cf2275ca18f8d155", "predicted_answer": "1. rnns, cnns, naive bayes with laplace smoothing, k-clustering, svm with linear kernel", "predicted_evidence": []}
{"question_id": "00ef9cc1d1d60f875969094bb246be529373cb1d", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "279b633b90fa2fd69e84726090fadb42ebdf4c02", "predicted_answer": "1. the east coast bomb cyclone,  the mendocino, california wildfires, hurricane florence, hurricane michael, the california camp fires", "predicted_evidence": []}
{"question_id": "0106bd9d54e2f343cc5f30bb09a5dbdd171e964b", "predicted_answer": "1. twitter", "predicted_evidence": []}
{"question_id": "e015d033d4ee1c83fe6f192d3310fb820354a553", "predicted_answer": "bibref8", "predicted_evidence": []}
{"question_id": "8a871b136ccef78391922377f89491c923a77730", "predicted_answer": "1. stanford ner, bilstm+crf, lstm+cnn+crf, t-ner and bilstm+cnn+co-attention", "predicted_evidence": []}
{"question_id": "acd05f31e25856b9986daa1651843b8dc92c2d99", "predicted_answer": "1. 9,892 stories of sexual harassment incidents", "predicted_evidence": []}
{"question_id": "8c78b21ec966a5e8405e8b9d3d6e7099e95ea5fb", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "af60462881b2d723adeb4acb5fbc07ea27b6bde2", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "879bec20c0fdfda952444018e9435f91e34d8788", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "3c378074111a6cc7319c0db0aced5752c30bfffb", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "b464bc48f176a5945e54051e3ffaea9a6ad886d7", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "3b40799f25dbd98bba5b526e0a1d0d0bb51173e0", "predicted_answer": "1. unanswerable", "predicted_evidence": []}
{"question_id": "3c16d4cf5dc23223980d9c0f924cb9e4e6943f13", "predicted_answer": "1.", "predicted_evidence": []}
{"question_id": "4c822bbb06141433d04bbc472f08c48bc8378865", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "1baf87437b70cc0375b8b7dc2cfc2830279bc8b5", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "0b31eb5bb111770a3aaf8a3931d8613e578e07a8", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "7348e781b2c3755b33df33f4f0cab4b94fcbeb9b", "predicted_answer": "i'm happy to help! however, i don't see a specific context or corpora being referred to in the question. could you please provide more information or clarify which corpora you are asking about?\n\nif not, my best guess would be:\n\n1. only automatic methods", "predicted_evidence": []}
{"question_id": "f68bd65b5251f86e1ed89f0c858a8bb2a02b233a", "predicted_answer": "1. randomly from a twitter dump", "predicted_evidence": []}
{"question_id": "e111925a82bad50f8e83da274988b9bea8b90005", "predicted_answer": "1. randomly from twitter", "predicted_evidence": []}
{"question_id": "ba48c095c496d01c7717eaa271470c3406bf2d7c", "predicted_answer": "i'm happy to help! however, i don't see a specific context for the question \"what languages do they experiment with?\" could you please provide more information about who \"they\" are and what kind of experimentation is being referred to?\n\nif not, my best guess based on the limited options provided would be:\n\n1. chinese", "predicted_evidence": []}
{"question_id": "42a61773aa494f7b12838f71a949034c12084de1", "predicted_answer": "memn2n, bibref12, attentive and impatient readers bibref6", "predicted_evidence": []}
{"question_id": "48c3e61b2ed7b3f97706e2a522172bf9b51ec467", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "61fba3ab10f7b6906e27b028fb1d42ec601c3fb8", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "80de3baf97a55ea33e0fe0cafa6f6221ba347d0a", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "f5707610dc8ae2a3dc23aec63d4afa4b40b7ec1e", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "e76139c63da0f861c097466983fbe0c94d1d9810", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "b8b588ca1e876b3094ae561a875dd949c8965b2e", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "2ec640e6b4f1ebc158d13ee6589778b4c08a04c8", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "ab0bb4d0a9796416d3d7ceba0ba9ab50c964e9d6", "predicted_answer": "unfortunately, i don't have enough information to provide an accurate answer. the provided text doesn't mention any collection steps.\n\nhowever, based on your request, i will choose:\n\n1. unanswerable", "predicted_evidence": []}
{"question_id": "0460019eb2186aef835f7852fc445b037bd43bb7", "predicted_answer": "two", "predicted_evidence": []}
{"question_id": "96c09ece36a992762860cde4c110f1653c110d96", "predicted_answer": "for task 1: 0.9414 \nfor task 2: ratio 0.3175", "predicted_evidence": []}
{"question_id": "a9cc4b17063711c8606b8fc1c5eaf057b317a0c9", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "6ead576ee5813164684a8cdda36e6a8c180455d9", "predicted_answer": "rouge-l, bleu-1", "predicted_evidence": []}
{"question_id": "0117aa1266a37b0d2ef429f1b0653b9dde3677fe", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "5455b3cdcf426f4d5fc40bc11644a432fa7a5c8f", "predicted_answer": "1. well-formed sentences vs concise answers", "predicted_evidence": []}
{"question_id": "6c80bc3ed6df228c8ca6e02c0a8a1c2889498688", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "2d274c93901c193cf7ad227ab28b1436c5f410af", "predicted_answer": "1. bidaf, deep cascade qa, s-net+ces2s, bert+multi-pgnet, selector+ccg, vnet, decaprop, mhpgm+noic, conznet, rmr+a2d", "predicted_evidence": []}
{"question_id": "e63bde5c7b154fbe990c3185e2626d13a1bad171", "predicted_answer": "1. bleu-1: 54.11, bleu-4: 30.43, meteor: 26.13, rouge-l: 59.87", "predicted_evidence": []}
{"question_id": "cb8a6f5c29715619a137e21b54b29e9dd48dad7d", "predicted_answer": "1. well-formed sentences vs concise answers", "predicted_evidence": []}
{"question_id": "8a7bd9579d2783bfa81e055a7a6ebc3935da9d20", "predicted_answer": "1. was", "predicted_evidence": []}
{"question_id": "27b01883ed947b457d3bab0c66de26c0736e4f90", "predicted_answer": "1. syllables", "predicted_evidence": []}
{"question_id": "9714cb7203c18a0c53805f6c889f2e20b4cab5dd", "predicted_answer": "none of the above options directly answers the question about what visual information characterizes tones. however, based on the provided option:\n\n1", "predicted_evidence": []}
{"question_id": "a22b900fcd76c3d36b5679691982dc6e9a3d34bf", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "fb2593de1f5cc632724e39d92e4dd82477f06ea1", "predicted_answer": "none of the above options are provided as an answer choice, but since option 1 is given, i will choose that.\n\nthe best answer is 1.", "predicted_evidence": []}
{"question_id": "476d0b5579deb9199423bb843e584e606d606bc7", "predicted_answer": "bibref13, majority baseline", "predicted_evidence": []}
{"question_id": "eddabb24bc6de6451bcdaa7940f708e925010912", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "f0946fb9df9839977f4d16c43476e4c2724ff772", "predicted_answer": "i'm happy to help! however, i don't see a list of options provided for this question. could you please provide more context or clarify what you mean by \"elementary argumentative units\"? that way, i can give you a more accurate answer.\n\nif not, my best guess would be that elementary argumentative units are defined as the smallest units of argumentation that still convey a meaningful claim or assertion.", "predicted_evidence": []}
{"question_id": "e51d0c2c336f255e342b5f6c3cf2a13231789fed", "predicted_answer": "none of the above options are provided as an answer choice, but based on the given option:\n\n1", "predicted_evidence": []}
{"question_id": "5b6aec1b88c9832075cd343f59158078a91f3597", "predicted_answer": "1. proposed sg model vs sindhi fasttext:\naverage cosine similarity score: 0.650 vs 0.388\naverage semantic relatedness similarity score between countries and their capitals: 0.663 vs 0.391", "predicted_evidence": []}
{"question_id": "a6717e334c53ebbb87e5ef878a77ef46866e3aed", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "a1064307a19cd7add32163a70b6623278a557946", "predicted_answer": "1. 908456", "predicted_evidence": []}
{"question_id": "8cb9006bcbd2f390aadc6b70d54ee98c674e45cc", "predicted_answer": "1. daily kawish and awami awaz sindhi newspapers, wikipedia dumps, short stories and sports news from wichaar social blog, news from focus word press blog, historical writings, novels, stories, books from sindh salamat literary website, novels, history and religious books from sindhi adabi board,  tweets regarding news and sports are collected from twitter", "predicted_evidence": []}
{"question_id": "75043c17a2cddfce6578c3c0e18d4b7cf2f18933", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "95bb3ea4ebc3f2174846e8d422abc076e1407d6a", "predicted_answer": "1. between 1900s and 2010s", "predicted_evidence": []}
{"question_id": "3ebdc15480250f130cf8f5ab82b0595e4d870e2f", "predicted_answer": "1. 77 genres", "predicted_evidence": []}
{"question_id": "bbc58b193c08ccb2a1e8235a36273785a3b375fb", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "3c34187a248d179856b766e9534075da1aa5d1cf", "predicted_answer": "1. the results obtained on development and test set (f1 = 89.60, f1 = 87.82) and the results on the supplemental test set (f1 = 71.49)", "predicted_evidence": []}
{"question_id": "8bfbf78ea7fae0c0b8a510c9a8a49225bbdb5383", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "97757a69d9fc28b260e68284fd300726fbe358d0", "predicted_answer": "1. bias feature, token feature, uppercase feature (y/n), titlecase feature (y/n), character trigram feature, quotation feature (y/n), word suffix feature (last three characters), pos tag (provided by spacy utilities), word shape (provided by spacy utilities), word embedding (see table tabref26)", "predicted_evidence": []}
{"question_id": "41830ebb8369a24d490e504b7cdeeeaa9b09fd9c", "predicted_answer": "unfortunately, i don't have enough context about what \"state of the art method\" refers to in this case. could you please provide more information or clarify which field or domain you are asking about? \n\nhowever, since there is only one option available, i will respond with that.\n\n1. unanswerable", "predicted_evidence": []}
{"question_id": "4904ef32a8f84cf2f53b1532ccf7aa77273b3d19", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "45b28a6ce2b0f1a8b703a3529fd1501f465f3fdf", "predicted_answer": "1. special dedicated discriminator is added to the model to control that the latent representation does not contain stylistic information, shifted autoencoder or sae, combination of both approaches", "predicted_evidence": []}
{"question_id": "d6a27c41c81f12028529e97e255789ec2ba39eaa", "predicted_answer": "1. accuracy can change up to 5 percentage points, whereas bleu can vary up to 8 points", "predicted_evidence": []}
{"question_id": "2d3bf170c1647c5a95abae50ee3ef3b404230ce4", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "6e8c587b6562fafb43a7823637b84cd01487059a", "predicted_answer": "1. ranges from 44.22 to 100.00 depending on k and the sequence length.", "predicted_evidence": []}
{"question_id": "ab9453fa2b927c97b60b06aeda944ac5c1bfef1e", "predicted_answer": "1. sequence copy task and wmt'17", "predicted_evidence": []}
{"question_id": "3a8d65eb8e1dbb995981a0e02d86ebf3feab107a", "predicted_answer": "1. an adversarial loss ($\\ell _{adv}$) for each model as in the baseline, a cycle consistency loss ($\\ell _{cycle}$) on each side", "predicted_evidence": []}
{"question_id": "d0c79f4a5d5c45fe673d9fcb3cd0b7dd65df7636", "predicted_answer": "1. new best results of accuracy (p@1) on vecmap:\nours-geommsemi: en-it 50.00 it-en 42.67 en-de 51.60 de-en 47.22 fi-en 39.62 en-es 39.47 es-en 36.43", "predicted_evidence": []}
{"question_id": "54c7fc08598b8b91a8c0399f6ab018c45e259f79", "predicted_answer": "the proposed method is slightly better in some cases (en-de, de-en) and slightly worse in others (en-fi), but overall performance is comparable to the best baseline result on vecmap.", "predicted_evidence": []}
{"question_id": "5112bbf13c7cf644bf401daecb5e3265889a4bfc", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "03ce42ff53aa3f1775bc57e50012f6eb1998c480", "predicted_answer": "1, 2, 3, 4, 5, 6", "predicted_evidence": []}
{"question_id": "ebeedbb8eecdf118d543fdb5224ae610eef212c8", "predicted_answer": "1. procrustes, gpa, geomm, geomm$_{semi}$, adv-c-procrustes, unsup-sl, sinkhorn-bt", "predicted_evidence": []}
{"question_id": "9efd025cfa69c6ff2777528bd158f79ead9353d1", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "559c1307610a15427caeb8aff4d2c01ae5c9de20", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "4ecb6674bcb4162bf71aea8d8b82759255875df3", "predicted_answer": "bibref5", "predicted_evidence": []}
{"question_id": "eacc1eb65daad055df934e0e878f417b73b2ecc1", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "d353a6bbdc66be9298494d0c853e0d8d752dec4b", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "e2cfaa2ec89b944bbc46e5edf7753b3018dbdc8f", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "22c36082b00f677e054f0f0395ed685808965a02", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "85a7dbf6c2e21bfb7a3a938381890ac0ec2a19e0", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "90bc60320584ebba11af980ed92a309f0c1b5507", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "f52b2ca49d98a37a6949288ec5f281a3217e5ae8", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "228425783a4830e576fb98696f76f4c7c0a1b906", "predicted_answer": "1. english-italian (en-it) and english-german (en-de)", "predicted_evidence": []}
{"question_id": "9d1135303212356f3420ed010dcbe58203cc7db4", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "d8bf4a29c7af213a9a176eb1503ec97d01cc8f51", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "73abb173a3cc973ab229511cf53b426865a2738b", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "1d9b953a324fe0cfbe8e59dcff7a44a2f93c568d", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "093039f974805952636c19c12af3549aa422ec43", "predicted_answer": "1. it uses deep learning framework (pytorch)", "predicted_evidence": []}
{"question_id": "8df89988adff57279db10992846728ec4f500eaa", "predicted_answer": "none of the above options seem directly related to baselines used in experiments. however, i'll make an educated guess based on common practices.\n\ntypically, in experiments, a baseline can be a simple or standard implementation that serves as a comparison point for more complex models or algorithms. given the context of dynamic programming and parsing algorithms mentioned in the options, a possible answer could be:\n\n* a serial (non-parallelized) version of an algorithm.\n* a basic or naive implementation of an algorithm.\n\nhowever, without more specific information about the type of experiment or field of study, it's challenging to provide a precise answer.", "predicted_evidence": []}
{"question_id": "94edac71eea1e78add678fb5ed2d08526b51016b", "predicted_answer": "parallel scan inference, vectorized parsing, semiring matrix operations", "predicted_evidence": []}
{"question_id": "9c4ed8ca59ba6d240f031393b01f634a9dc3615d", "predicted_answer": "vecmap", "predicted_evidence": []}
{"question_id": "ca7e71131219252d1fab69865804b8f89a2c0a8f", "predicted_answer": "1.", "predicted_evidence": []}
{"question_id": "d77c9ede2727c28e0b5a240b2521fd49a19442e0", "predicted_answer": "1. word embeddings", "predicted_evidence": []}
{"question_id": "a9610cbcca813f4376fbfbf21cc14689c7fbd677", "predicted_answer": "1. in the overall available data there are 40,071 training, 4,988 validation, and 5,050 usable testing stories.", "predicted_evidence": []}
{"question_id": "64ab2b92e986e0b5058bf4f1758e849f6a41168b", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "bcd6befa65cab3ffa6334c8ecedd065a4161028b", "predicted_answer": "1. a form of wordplay jokes in which one sign (e.g. a word or a phrase) suggests two or more meanings by exploiting polysemy, homonymy, or phonological similarity to another sign, for an intended humorous or rhetorical effect", "predicted_evidence": []}
{"question_id": "479fc9e6d6d80e69f425d9e82e618e6b7cd12764", "predicted_answer": "intra-sequential and inter-sequential", "predicted_evidence": []}
{"question_id": "bc26eee4ef1c8eff2ab8114a319901695d044edb", "predicted_answer": "1.", "predicted_evidence": []}
{"question_id": "9c94ff8c99d3e51c256f2db78c34b2361f26b9c2", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "8e9de181fa7d96df9686d0eb2a5c43841e6400fa", "predicted_answer": "1. yes, crwiz has been used for data collection and its initial use resulted in 145 dialogues. the average time taken for the task was close to the estimate of 10 minutes, 14 dialogues (9.66%) resolved the emergency in the scenario, and these dialogues rated consistently higher in subjective and objective ratings than those which did not resolve the emergency. qualitative results showed that participants believed that they were interacting with an automated assistant.", "predicted_evidence": []}
{"question_id": "ff1595a388769c6429423a75b6e1734ef88d3e46", "predicted_answer": "1. the wizard can select one of several predefined messages to send, or type their own message if needed. free text messages do not change the dialogue state in the fsm, so it is important to minimise their use by providing enough dialogue options to the wizard. predefined messages can also trigger other associated events such as pop-ups or follow-up non-verbal actions.", "predicted_evidence": []}
{"question_id": "dd2046f5481f11b7639a230e8ca92904da75feed", "predicted_answer": "average score", "predicted_evidence": []}
{"question_id": "47e6c3e6fcc9be8ca2437f41a4fef58ef4c02579", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "569ad21441e99ae782d325d5f5e1ac19e08d5e76", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "90741b227b25c42e0b81a08c279b94598a25119d", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "1d739bb8e5d887fdfd1f4b6e39c57695c042fa25", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "5c70fdd3d6b67031768d3e28336942e49bf9a500", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "f27502c3ece9ade265389d5ace90ca9ca42b46f3", "predicted_answer": "1. separate set of turkers to rate the stories for overall quality and the three improvement areas", "predicted_evidence": []}
{"question_id": "ffb7a12dfe069ab7263bb7dd366817a9d22b8ef2", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "aa4b38f601cc87bf93849245d5f65124da3dc112", "predicted_answer": "i'm not familiar with \"baselines\" in a specific context that matches the provided option. however, i can try to give an educated guess.\n\nmy response is: none of the above (since there's only one option).", "predicted_evidence": []}
{"question_id": "08b87a90139968095433f27fc88f571d939cd433", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "ef872807cb0c9974d18bbb886a7836e793727c3d", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "4db3c2ca6ddc87209c31b20763b7a3c1c33387bc", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "63337fd803f6fdd060ebd0f53f9de79d451810cd", "predicted_answer": "unfortunately, i don't have enough information to provide a specific answer. however, based on my knowledge of ioc (indicators of compromise) detection systems, i can try to make an educated guess.\n\nsince there is only one option available, which is \"unanswerable\", i will choose that as the best answer.", "predicted_evidence": []}
{"question_id": "63496705fff20c55d4b3d8cdf4786f93e742dd3d", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "7b44bee49b7cb39cb7d5eec79af5773178c27d4d", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "6d54bad91b6ccd1108d1ddbff1d217c6806e0842", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "238ec3c1e1093ce2f5122ee60209b969f7669fae", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "f704d182c9e01a2002381b76bf21e4bb3c0d3efc", "predicted_answer": "unfortunately, i don't have enough information to provide a specific technique that yields the best performance among various transfer learning techniques.\n\nso, my response is:\n\n1. unanswerable", "predicted_evidence": []}
{"question_id": "da544015511e535503dee2eaf4912a5e36c806cd", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "7bc993b32484d6ae3c86d0b351a68e59fd2757a5", "predicted_answer": "i'm happy to help! however, i don't see a question in your prompt. could you please provide the actual question so i can give you an accurate answer?", "predicted_evidence": []}
{"question_id": "da495e2f99ee2d5db9cc17eca5517ddaa5ea8e42", "predicted_answer": "1. ldc corpus", "predicted_evidence": []}
{"question_id": "e44a5514d7464993997212341606c2c0f3a72eb4", "predicted_answer": "1. unanswerable", "predicted_evidence": []}
{"question_id": "310e61b9dd4d75bc1bebbcb1dae578f55807cd04", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "bdc6664cec2b94b0b3769bc70a60914795f39574", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "e40df8c685a28b98006c47808f506def68f30e26", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "9653c89a93ac5c717a0a26cf80e9aa98a5ccf910", "predicted_answer": "1. wdaqua bibref0 , qakis bibref7 , ganswer bibref6 and platypus bibref8", "predicted_evidence": []}
{"question_id": "b921a1771ed0ba9dbeff9da000336ecf2bb38322", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "412aff0b2113b7d61c914edf90b90f2994390088", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "010e3793eb1342225857d3f95e147d8f8467192a", "predicted_answer": "the dutch section: 2,333,816 sentences and 53,487,257 words; the sonar500 corpus: more than 500 million words.", "predicted_evidence": []}
{"question_id": "c20bb0847ced490a793657fbaf6afb5ef54dad81", "predicted_answer": "unfortunately, i don't have enough information to provide a specific answer. therefore, my response is:\n\n1. unanswerable", "predicted_evidence": []}
{"question_id": "ff8557d93704120b65d9b597a4fab40b49d24b6d", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "447eb98e602616c01187960c9c3011c62afd7c27", "predicted_answer": "table tabref10 displays the twenty resulting topics", "predicted_evidence": []}
{"question_id": "f398587b9a0008628278a5ea858e01d3f5559f65", "predicted_answer": "rouge-1: 0.29 \ncic: 0.2", "predicted_evidence": []}
{"question_id": "d5f8707ddc21741d52b3c2a9ab1af2871dc6c90b", "predicted_answer": "1. rouge and cic, relevance, conciseness and readability on a 1 to 5 scale, and rank the summary pair", "predicted_evidence": []}
{"question_id": "58f3bfbd01ba9768172be45a819faaa0de2ddfa4", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "73633afbefa191b36cca594977204c6511f9dad4", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "db39a71080e323ba2ddf958f93778e2b875dcd24", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "6da2cb3187d3f28b75ac0a61f6562a8adf716109", "predicted_answer": "pointer-generator", "predicted_evidence": []}
{"question_id": "c47e87efab11f661993a14cf2d7506be641375e4", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "14684ad200915ff1e3fc2a89cb614e472a1a2854", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "8d1f9d3aa2cc2e2e58d3da0f5edfc3047978f3ee", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "5065ff56d3c295b8165cb20d8bcfcf3babe9b1b8", "predicted_answer": "1. bleu-3/4, rouge-2/l, cider, spice, bertscore", "predicted_evidence": []}
{"question_id": "c34a15f1d113083da431e4157aceb11266e9a1b2", "predicted_answer": "1. no", "predicted_evidence": []}
{"question_id": "061682beb3dbd7c76cfa26f7ae650e548503d977", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "3518d8eb84f6228407cfabaf509fd63d60351203", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "617c77a600be5529b3391ab0c21504cd288cc7c7", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "53d6cbee3606dd106494e2e98aa93fdd95920375", "predicted_answer": "1. test accuracy of 88.9%, which exceeds the previous best by 16.9%", "predicted_evidence": []}
{"question_id": "9dc844f82f520daf986e83466de0c84d93953754", "predicted_answer": "1. multinli bibref15 and snli bibref16", "predicted_evidence": []}
{"question_id": "9fe4a2a5b9e5cf29310ab428922cc8e7b2fc1d11", "predicted_answer": "1. ftlm++, bert-large, xlnet", "predicted_evidence": []}
{"question_id": "36d892460eb863220cd0881d5823d73bbfda172c", "predicted_answer": "1. dream, mctest, toefl, and semeval-2018 task 11", "predicted_evidence": []}
{"question_id": "4cbc56d0d53c4c03e459ac43e3c374b75fd48efe", "predicted_answer": "lstm, scibert", "predicted_evidence": []}
{"question_id": "e5a965e7a109ae17a42dd22eddbf167be47fca75", "predicted_answer": "1.", "predicted_evidence": []}
{"question_id": "082c88e132b4f1bf68abdc3a21ac4af180de1113", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "74091e10f596428135b0ab06008608e09c051565", "predicted_answer": "1. entity memory and relational memory.", "predicted_evidence": []}
{"question_id": "43b4f7eade7a9bcfaf9cc0edba921a41d6036e9c", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "a75861e6dd72d69fdf77ebd81c78d26c6f7d0864", "predicted_answer": "1. extends memory-augmented neural networks with a relational memory to reason about relationships between multiple entities present within the text.", "predicted_evidence": []}
{"question_id": "60fd7ef7986a5752b31d3bd12bbc7da6843547a4", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "7d59374d9301a0c09ea5d023a22ceb6ce07fb490", "predicted_answer": "1. by number of distinct n-grams", "predicted_evidence": []}
{"question_id": "8e2b125426d1220691cceaeaf1875f76a6049cbd", "predicted_answer": "1. on event2mind, the accuracy of proposed method is improved by  absolute blue  2.9,  10.87, 1.79 for xintent, xreact and oreact respectively.\non atomic dataset, the accuracy of proposed method is improved by  absolute blue 3.95.   4.11, 4.49 for xintent, xreact and oreact.respectively.", "predicted_evidence": []}
{"question_id": "42bc4e0cd0f3e238a4891142f1b84ebcd6594bf1", "predicted_answer": "1. rnn-based seq2seq, variational seq2seq, vrnmt , cwvae-unpretrained", "predicted_evidence": []}
{"question_id": "fb76e994e2e3fa129f1e94f1b043b274af8fb84c", "predicted_answer": "1. cwvae is trained on an auxiliary dataset to learn the event background information by using the context-aware latent variable. then, in finetune stage, cwvae is trained on the task-specific dataset to adapt the event background information to each specific aspect of if-then inferential target.", "predicted_evidence": []}
{"question_id": "99ef97336c0112d9f60df108f58c8b04b519a854", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "95d8368b1055d97250df38d1e8c4a2b283d2b57e", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "a978a1ee73547ff3a80c66e6db3e6c3d3b6512f4", "predicted_answer": "1. 0.08 points on the 2011 test set, 0.44 points on the 2012 test set, 0.42 points on the 2013 test set for iwslt-ce.", "predicted_evidence": []}
{"question_id": "46ee1cbbfbf0067747b28bdf4c8c2f7dc8955650", "predicted_answer": "lstms", "predicted_evidence": []}
{"question_id": "4f12b41bd3bb2610abf7d7835291496aa69fb78c", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "65e6a1cc2590b139729e7e44dce6d9af5dd2c3b5", "predicted_answer": "1. do not follow a particular plan or pursue a particular fixed information need, integrating content found via search with content from structured data, at each system turn, there are a large number of conversational moves that are possible, most other domains do not have such high quality structured data available, live search may not be able to achieve the required speed and efficiency", "predicted_evidence": []}
{"question_id": "b54fc86dc2cc6994e10c1819b6405de08c496c7b", "predicted_answer": "none of the above options seem relevant to measuring speed. my best guess is:\n\n none of the above (typically, speed is measured in distance per unit time, such as miles per hour or kilometers per second)", "predicted_evidence": []}
{"question_id": "b43a8a0f4b8496b23c89730f0070172cd5dca06a", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "b161febf86cdd58bd247a934120410068b24b7d1", "predicted_answer": "the nine types are: agreement, answer, appreciation, disagreement, elaboration, humor, negative reaction, question, other", "predicted_evidence": []}
{"question_id": "d40662236eed26f17dd2a3a9052a4cee1482d7d6", "predicted_answer": "1. a vector of frame-level acoustic features", "predicted_evidence": []}
{"question_id": "1d791713d1aa77358f11501f05c108045f53c8aa", "predicted_answer": "1. 1061", "predicted_evidence": []}
{"question_id": "6b6360fab2edc836901195c0aba973eae4891975", "predicted_answer": "1. switchboard conversational english corpus", "predicted_evidence": []}
{"question_id": "b6b5f92a1d9fa623b25c70c1ac67d59d84d9eec8", "predicted_answer": "1. their best average precision tops previous best result by 0.202", "predicted_evidence": []}
{"question_id": "86a93a2d1c19cd0cd21ad1608f2a336240725700", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "6090d3187c41829613abe785f0f3665d9ecd90d9", "predicted_answer": "1. only in the context of a sentence does a word have a meaning.", "predicted_evidence": []}
{"question_id": "117aa7811ed60e84d40cd8f9cb3ca78781935a98", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "c359ab8ebef6f60c5a38f5244e8c18d85e92761d", "predicted_answer": "1. 10*n paraphrases, where n depends on the number of paraphrases that contain the entity mention spans", "predicted_evidence": []}
{"question_id": "ad362365656b0b218ba324ae60701eb25fe664c1", "predicted_answer": "1. syntactic information, semantic and topical information", "predicted_evidence": []}
{"question_id": "423bb905e404e88a168e7e807950e24ca166306c", "predicted_answer": "graphparser without paraphrases, monolingual machine translation based model for paraphrase generation", "predicted_evidence": []}
{"question_id": "e5ae8ac51946db7475bb20b96e0a22083b366a6d", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "18288c7b0f8bd7839ae92f9c293e7fb85c7e146a", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "b5e883b15e63029eb07d6ff42df703a64613a18a", "predicted_answer": "1. using topic modeling model latent dirichlet allocation (lda)", "predicted_evidence": []}
{"question_id": "c45a160d31ca8eddbfea79907ec8e59f543aab86", "predicted_answer": "swissmetro dataset", "predicted_evidence": []}
{"question_id": "7358a1ce2eae380af423d4feeaa67d2bd23ae9dd", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "1165fb0b400ec1c521c1aef7a4e590f76fee1279", "predicted_answer": "1. the data from collected travel surveys is used to model travel behavior.", "predicted_evidence": []}
{"question_id": "f2c5da398e601e53f9f545947f61de5f40ede1ee", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "2d4d0735c50749aa8087d1502ab7499faa2f0dd8", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "43761478c26ad65bec4f0fd511ec3181a100681c", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "01866fe392d9196dda1d0b472290edbd48a99f66", "predicted_answer": "1. re-train the skip-gram model and update the emoji map periodically on new escort ads, when traffickers switch to new emojis, the map can link the new emojis to the old ones", "predicted_evidence": []}
{"question_id": "394cf73c0aac8ccb45ce1b133f4e765e8e175403", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "2c4003f25e8d95a3768204f52a7a5f5e17cb2102", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "65e32f73357bb26a29a58596e1ac314f7e9c6c91", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "46f175e1322d648ab2c0258a9609fe6f43d3b44e", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "7cc22fd8c9d0e1ce5e86d0cbe90bf3a177f22a68", "predicted_answer": "1. 1000 conversations composed of 6833 sentences and 88047 tokens", "predicted_evidence": []}
{"question_id": "3fa638e6167e1c7a931c8ee5c0e2e397ec1b6cda", "predicted_answer": "r/explainlikeimfive, r/askscience, and r/eli5 are some popular communities on reddit where users look for answers to complex questions explained in simple terms.", "predicted_evidence": []}
{"question_id": "d2b3f2178a177183b1aeb88784e48ff7e3e5070c", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "d5ff8fc4d3996db2c96cb8af5a6d215484991e62", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "d9c6493e1c3d8d429d4ca608f5acf29e4e7c4c9b", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "0427ca83d6bf4ec113bc6fec484b2578714ae8ec", "predicted_answer": "lstm+attention, transformer, universal transformer", "predicted_evidence": []}
{"question_id": "f1c70baee0fd02b8ecb0af4b2daa5a56f3e9ccc3", "predicted_answer": "1. 239,357 english question-answer pairs", "predicted_evidence": []}
{"question_id": "8db45a8217f6be30c31f9b9a3146bf267de68389", "predicted_answer": "2. output length, input length, output pattern, input pattern", "predicted_evidence": []}
{"question_id": "4e379d6d5f87554fabf6f7f7b6ed92d2025e7280", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "518d0847b02b4f23a8f441faa38b935c9b892e1e", "predicted_answer": "honk, deepspeech-finetune", "predicted_evidence": []}
{"question_id": "8112d18681e266426cf7432ac4928b87f5ce8311", "predicted_answer": "english, hindi", "predicted_evidence": []}
{"question_id": "b14f13f2a3a316e5a5de9e707e1e6ed55e235f6f", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "ba6422e22297c7eb0baa381225a2f146b9621791", "predicted_answer": "1.", "predicted_evidence": []}
{"question_id": "65e72ad72a9cbfc379f126b10b0ce80cfe44579b", "predicted_answer": "nat w/ fertility, nat-ir, nat-reg, lv nar, ctc loss, cmlm", "predicted_evidence": []}
{"question_id": "cf8edc6e8c4d578e2bd9965579f0ee81f4bf35a9", "predicted_answer": "wmt2014, wmt2016 and iwslt-2014", "predicted_evidence": []}
{"question_id": "04aff4add28e6343634d342db92b3ac36aa8c255", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "a8e4522ce2ce7336e731286654d6ad0931927a4e", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "f6202100cfb83286dc51f57c68cffdbf5cf50a3f", "predicted_answer": "1. step-wise decoder fusion, multimodal attention modulation, visual-semantic (vs) regularizer", "predicted_evidence": []}
{"question_id": "bd7039f81a5417474efa36f703ebddcf51835254", "predicted_answer": "reasoner model and ranker model", "predicted_evidence": []}
{"question_id": "022e5c996a72aeab890401a7fdb925ecd0570529", "predicted_answer": "1. reasoner learns to extract the linking entity from chains selected by a well-trained ranker, and it benefits the ranker training by providing extra rewards", "predicted_evidence": []}
{"question_id": "2a950ede24b26a45613169348d5db9176fda4f82", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "34af2c512ec38483754e94e1ea814aa76552d60a", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "c1429f7fed5a4dda11ac7d9643f97af87a83508b", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "a93d4aa89ac3abbd08d725f3765c4f1bed35c889", "predicted_answer": "1. english, chinese", "predicted_evidence": []}
{"question_id": "bc473c5bd0e1a8be9b2037aa7006fd68217c3f47", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "cc5d8e12f6aecf6a5f305e2f8b3a0c67f49801a9", "predicted_answer": "1. 36%", "predicted_evidence": []}
{"question_id": "9299fe72f19c1974564ea60278e03a423eb335dc", "predicted_answer": "3", "predicted_evidence": []}
{"question_id": "2ed02be0c183fca7031ccb8be3fd7bc109f3694b", "predicted_answer": "1.08 points in rouge-l over our base pointer-generator model , 0.6 points in rouge-1", "predicted_evidence": []}
{"question_id": "be73a88d5b695200e2ead4c2c24e2a977692970e", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "0e45aae0e97a6895543e88705e153f084ce9c136", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "c515269b37cc186f6f82ab9ada5d9ca176335ded", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "43f86cd8aafe930ebb35ca919ada33b74b36c7dd", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "aa60b0a6c1601e09209626fd8c8bdc463624b0b3", "predicted_answer": "1. with both test sets performances decrease, varying between 94-97%", "predicted_evidence": []}
{"question_id": "3837ae1e91a4feb27f11ac3b14963e9a12f0c05e", "predicted_answer": "6,7,8,9,10,11,12,13,14", "predicted_evidence": []}
{"question_id": "ef4d6c9416e45301ea1a4d550b7c381f377cacd9", "predicted_answer": "1. standard linguistic features, such as part-of-speech (pos) and chunk tag, series of features representing tokens' left and right context", "predicted_evidence": []}
{"question_id": "689d1d0c4653a8fa87fd0e01fa7e12f75405cd38", "predicted_answer": "bilstm-networks", "predicted_evidence": []}
{"question_id": "7920f228de6ef4c685f478bac4c7776443f19f39", "predicted_answer": "1. english", "predicted_evidence": []}
{"question_id": "41844d1d1ee6d6d38f31b3a17a2398f87566ed92", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "ae17066634bd2731a07cd60e9ca79fc171692585", "predicted_answer": "unfortunately, i don't have enough information about the context of \"domain mismatch\" and how it is explored. therefore, my response would be:\n\n1. unanswerable", "predicted_evidence": []}
{"question_id": "4fa2faa08eeabc09d78d89aaf0ea86bb36328172", "predicted_answer": "unfortunately, i don't have enough information to provide a specific answer. however, based on general knowledge, here is my response:\n\n none of the above (since there's only one option and it says \"unanswerable\")\n\nif you could provide more context or clarify what you mean by \"they\" and \"dialect variability\", i'd be happy to try again!", "predicted_evidence": []}
{"question_id": "e87f47a293e0b49ab8b15fc6633d9ca6dc9de071", "predicted_answer": "1. egyptian (egy), levantine (lev), gulf (glf), north african (nor)", "predicted_evidence": []}
{"question_id": "7426a6e800d6c11795941616fc4a243e75716a10", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "da4535b75e360604e3ce4bb3631b0ba96f4dadd3", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "4d30c2223939b31216f2e90ef33fe0db97e962ac", "predicted_answer": "1. 11'248", "predicted_evidence": []}
{"question_id": "7b47aa6ba247874eaa8ab74d7cb6205251c01eb5", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "ce14b87dacfd5206d2a5af7c0ed1cfeb7b181922", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "709a4993927187514701fe3cc491ac3030da1215", "predicted_answer": "1. information retrieval system, word-association method", "predicted_evidence": []}
{"question_id": "a3c6acf900126bc9bd9c50ce99041ea00761da6a", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "31b631a8634f6180b20a72477040046d1e085494", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "ab78f066144936444ecd164dc695bec1cb356762", "predicted_answer": "1. jointly trained with slots", "predicted_evidence": []}
{"question_id": "e659ceb184777015c12db2da5ae396635192f0b0", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "b512ab8de26874ee240cffdb3c65d9ac8d6023d9", "predicted_answer": "the provided options do not include specific kernels used in support vector machines (svms). however, common kernels used in svms include:\n\n- linear kernel\n- polynomial kernel\n- radial basis function (rbf) kernel\n- sigmoid kernel\n\ngiven the constraint of choosing from the provided option and my inability to select a kernel directly, i must choose an answer that reflects the situation accurately.", "predicted_evidence": []}
{"question_id": "4e4d377b140c149338446ba69737ea191c4328d9", "predicted_answer": "1. acl anthology reference corpus", "predicted_evidence": []}
{"question_id": "828ce5faed7783297cf9ce202364f999b8d4a1f6", "predicted_answer": "1. f-score, micro-f, macro-f, weighted-f", "predicted_evidence": []}
{"question_id": "9d016eb3913b41f7a18c6fa865897c12b5fe0212", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "c1c611409b5659a1fd4a870b6cc41f042e2e9889", "predicted_answer": "1. bleu scores, exact matches of words in both translations and topic cache, and cosine similarities of adjacent sentences for coherence.", "predicted_evidence": []}
{"question_id": "79bb1a1b71a1149e33e8b51ffdb83124c18f3e9c", "predicted_answer": "1. combined per-pixel accuracy for character line segments is 74.79", "predicted_evidence": []}
{"question_id": "26faad6f42b6d628f341c8d4ce5a08a591eea8c2", "predicted_answer": "1. 508", "predicted_evidence": []}
{"question_id": "20be7a776dfda0d3c9dc10270699061cb9bc8297", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "3bfb8c12f151dada259fbd511358914c4b4e1b0e", "predicted_answer": "1. precision, recall, f-measure", "predicted_evidence": []}
{"question_id": "3f85cc5be84479ba668db6d9f614fedbff6d77f1", "predicted_answer": "the current size of the wikipedia revision dump dataset is around 60-70 gb (compressed) and over 200 gb (uncompressed), but this can vary depending on the specific dump and the time it was generated.\n\nhowever, since i have to choose from the given options:\n\n1. eight gb", "predicted_evidence": []}
{"question_id": "126e8112e26ebf8c19ca7ff3dd06691732118e90", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "be08ef81c3cfaaaf35c7414397a1871611f1a7fd", "predicted_answer": "pv-dtw, pv-ted", "predicted_evidence": []}
{"question_id": "dc57ae854d78aa5d5e8c979826d3e2524d4e9165", "predicted_answer": "unfortunately, i don't have enough information to provide a specific answer from the options given, as there is only one option and it's \"unanswerable\". however, i can try to provide an answer based on general knowledge.\n\nbeing feature-engineering free is not typically considered an advantage. feature engineering is often a crucial step in machine learning pipelines that involves selecting and transforming raw data into features that are more suitable for modeling. \n\nhowever, if we consider the context of automated machine learning or automl systems, being feature-engineering free could be seen as an advantage because it allows users to focus on higher-level tasks without worrying about the details of feature engineering.\n\ngiven this, i'll provide a response based on the available option:\n\n1", "predicted_evidence": []}
{"question_id": "18412237f7faafc6befe975d5bcd348e2b499b55", "predicted_answer": "$4th$", "predicted_evidence": []}
{"question_id": "02945c85d6cc4cdd1757b2f2bfa5e92ee4ed14a0", "predicted_answer": "1. dialectal tweet data", "predicted_evidence": []}
{"question_id": "6e51af9088c390829703c6fa966e98c3a53114c1", "predicted_answer": "1. modern standard arabic (msa), msa as well as dialects at various degrees of granularity such as egyptian, gulf, and levantine", "predicted_evidence": []}
{"question_id": "07ee4e0277ad1083270131d32a71c3fe062a916d", "predicted_answer": "1. author profiling and deception detection in arabic, lama+dina emotion detection, sentiment analysis in arabic tweets", "predicted_evidence": []}
{"question_id": "bfce2afe7a4b71f9127d4f9ef479a0bfb16eaf76", "predicted_answer": "1. rating questions on a scale of 1-5 based on fluency of language used and relevance of the question to the context", "predicted_evidence": []}
{"question_id": "dfbab3cd991f86d998223726617d61113caa6193", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "df510c85c277afc67799abcb503caa248c448ad2", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "d95180d72d329a27ddf2fd5cc6919f469632a895", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "e196e2ce72eb8b2d50732c26e9bf346df6643f69", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "46570c8faaeefecc8232cfc2faab0005faaba35f", "predicted_answer": "semeval 2018 task 3, bibref20, bibref4, sarc 2.0, sarc 2.0 pol, sarcasm corpus v1 (sc-v1), sarcasm corpus v2 (sc-v2)", "predicted_evidence": []}
{"question_id": "982d375378238d0adbc9a4c987d633ed16b7f98f", "predicted_answer": "that's not enough options for me to choose from. however, i can try to provide a more comprehensive answer.\n\nthe three different sources of data are:\n\n1. primary sources (e.g., surveys, experiments)\n2. secondary sources (e.g., books, articles, research papers)\n3. tertiary sources (e.g., social media, online forums, reddit)\n\nplease note that the options you provided seem to be a mix of tertiary sources.", "predicted_evidence": []}
{"question_id": "bbdb2942dc6de3d384e3a1b705af996a5341031b", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "4ec538e114356f72ef82f001549accefaf85e99c", "predicted_answer": "1. all caps, quotation marks, emoticons, emojis, hashtags", "predicted_evidence": []}
{"question_id": "40a45d59a2ef7a67c8ab0f2b2d5b43fc85b85498", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "b29b5c39575454da9566b3dd27707fced8c6f4a1", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "4040f5c9f365f9bc80b56dce944ada85bb8b4ab4", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "7dce1b64c0040500951c864fce93d1ad7a1809bc", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "e1b36927114969f3b759cba056cfb3756de474e4", "predicted_answer": "1. improved aecnn-t by 2.1 and aecnn-t-sm by 0.9", "predicted_evidence": []}
{"question_id": "186ccc18c6361904bee0d58196e341a719fb31c2", "predicted_answer": "1. sociodemographics: gender, age, marital status, etc., past medical history: number of previous admissions, history of suicidality, average length of stay (up until that admission), etc., information from the current admission: length of stay (los), suicidal risk, number and length of notes, time of discharge, evaluation scores, etc.", "predicted_evidence": []}
{"question_id": "fd5412e2784acefb50afc3bfae1e087580b90ab9", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "c7f087c78768d5c6f3ff26921858186d627fd4fd", "predicted_answer": "unfortunately, i don't see an option related to sentiment analysis in the provided options. however, based on my understanding of the context, i'll take a guess:\n\n none of the above (since there's only one option and it doesn't seem related to sentiment analysis)", "predicted_evidence": []}
{"question_id": "82596190560dc2e2ced2131779730f40a3f3eb8c", "predicted_answer": "1. ehrs of 183 psychosis patients from mclean psychiatric hospital in belmont, ma", "predicted_evidence": []}
{"question_id": "345f65eaff1610deecb02ff785198aa531648e75", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "51d03f0741b72ae242c380266acd2321baf43444", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "96c20af8bbef435d0d534d10c42ae15ff2f926f8", "predicted_answer": "1.", "predicted_evidence": []}
{"question_id": "9544cc0244db480217ce9174aa13f1bf09ba0d94", "predicted_answer": "english, german", "predicted_evidence": []}
{"question_id": "c97a4a1c0e3d00137a9ae8d6fbb809ba6492991d", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "3758669426e8fb55a4102564cf05f2864275041b", "predicted_answer": "1. allows the annotator to define each markable as a certain mention type (pronoun, np, vp or clause), the mentions referring to the same discourse item are linked between each other., chain members are annotated for their correctness", "predicted_evidence": []}
{"question_id": "1ebd6f703458eb6690421398c79abf3fc114148f", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "15a1df59ed20aa415a4daf0acb256747f6766f77", "predicted_answer": "1. shining through, explicitation", "predicted_evidence": []}
{"question_id": "b124137e62178a2bd3b5570d73b1652dfefa2457", "predicted_answer": "1.", "predicted_evidence": []}
{"question_id": "c6aa8a02597fea802890945f0b4be8d631e4d5cd", "predicted_answer": "1. semantic similarity structure, semantic direction structure", "predicted_evidence": []}
{"question_id": "bfad30f51ce3deea8a178944fa4c6e8acdd83a48", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "dd9883f4adf7be072d314d7ed13fe4518c5500e0", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "81669c550d32d756f516dab5d2b76ff5f21c0f36", "predicted_answer": "1. syn dep, openie, srl, bidaf, qanet, bert, naqanet, naqanet+", "predicted_evidence": []}
{"question_id": "b0b1ff2d6515fb40d74a4538614a0db537e020ea", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "4266aacb575b4be7dbcdb8616766324f8790763c", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "191107cd112f7ee6d19c1dc43177e6899452a2c7", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "b0dca7b74934f51ff3da0c074ad659c25d84174d", "predicted_answer": "i'm not aware of a specific model called \"caevo\" being a traditional linguistic feature-based model. however, i can try to provide some common examples of traditional linguistic feature-based models:\n\n* n-gram language models\n* hidden markov models (hmms)\n* decision trees\n* conditional random fields (crfs)\n\nplease note that these are just a few examples and there may be other models that fit the description.", "predicted_evidence": []}
{"question_id": "601e58a3d2c03a0b4cd627c81c6228a714e43903", "predicted_answer": "caevo", "predicted_evidence": []}
{"question_id": "a0fbf90ceb520626b80ff0f9160b3cd5029585a5", "predicted_answer": "bibref16", "predicted_evidence": []}
{"question_id": "e8ca81d5b36952259ef3e0dbeac7b3a622eabe8e", "predicted_answer": "iemocap", "predicted_evidence": []}
{"question_id": "e75685ef5f58027be44f42f30cb3988b509b2768", "predicted_answer": "1. set of related tasks are learned (e.g., emotional activation), primary task (e.g., emotional valence)", "predicted_evidence": []}
{"question_id": "1df24849e50fcf22f0855e0c0937c1288450ed5c", "predicted_answer": "i'm happy to help! however, i don't see a clear question in your prompt. the text \"<question>what are the subtle changes in voice which have been previously overshadowed?</question>\" appears to be a placeholder for a question.\n\ncould you please provide the actual question you'd like me to answer?", "predicted_evidence": []}
{"question_id": "859e0bed084f47796417656d7a68849eb9cb324f", "predicted_answer": "1. low-frequency words", "predicted_evidence": []}
{"question_id": "04e90c93d046cd89acef5a7c58952f54de689103", "predicted_answer": "1. cmrc-2017, people's daily (pd), children fairy tales (cft) , children's book test (cbt)", "predicted_evidence": []}
{"question_id": "f513e27db363c28d19a29e01f758437d7477eb24", "predicted_answer": "as reader, ga reader, cas reader", "predicted_evidence": []}
{"question_id": "eb5ed1dd26fd9adb587d29225c7951a476c6ec28", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "0828cfcf0e9e02834cc5f279a98e277d9138ffd9", "predicted_answer": "1. extracted text from sorani kurdish books of primary school and randomly created sentences", "predicted_evidence": []}
{"question_id": "7b2de0109b68f78afa9e6190c82ca9ffaf62f9bd", "predicted_answer": "1. 2000 sentences", "predicted_evidence": []}
{"question_id": "482ac96ff675975227b6d7058b9b87aeab6f81fe", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "3f3c09c1fd542c1d9acf197957c66b79ea1baf6e", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "0a82534ec6e294ab952103f11f56fd99137adc1f", "predicted_answer": "1. 2000", "predicted_evidence": []}
{"question_id": "938688871913862c9f8a28b42165237b7324e0de", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "4170ed011b02663f5b1b1a3c1f0415b7abfaa85d", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "fd08dc218effecbe5137a7e3b73d9e5e37ace9c1", "predicted_answer": "1. no", "predicted_evidence": []}
{"question_id": "a85c2510f25c7152940b5ac4333a80e0f91ade6e", "predicted_answer": "1. greens-efa, s&d, and epp exhibit the highest cohesion, non-aligned members ni have the lowest cohesion, followed by efdd and enl, two methods disagree is the level of cohesion of gue-ngl", "predicted_evidence": []}
{"question_id": "fa572f1f3f3ce6e1f9f4c9530456329ffc2677ca", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "5e057e115f8976bf9fe70ab5321af72eb4b4c0fc", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "d824f837d8bc17f399e9b8ce8b30795944df0d51", "predicted_answer": "1.", "predicted_evidence": []}
{"question_id": "2ff3898fbb5954aa82dd2f60b37dd303449c81ba", "predicted_answer": "1. penn treebank, text8, wsj10", "predicted_evidence": []}
{"question_id": "3070d6d6a52aa070f0c0a7b4de8abddd3da4f056", "predicted_answer": "bpc, perplexity", "predicted_evidence": []}
{"question_id": "ee9b95d773e060dced08705db8d79a0a6ef353da", "predicted_answer": "1. they are used as additional features in a supervised classification task", "predicted_evidence": []}
{"question_id": "dbdf13cb4faa1785bdee90734f6c16380459520b", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "73e715e485942859e1db75bfb5f35f1d5eb79d2e", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "12391aab31c899bac0ecd7238c111cb73723a6b7", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "8b43201e7e648c670c02e16ba189230820879228", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "5d5a571ff04a5fdd656ca87f6525a60e917d6558", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "3c362bfa11c60bad6c7ea83f8753d427cda77de0", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "e78a47aec37d9a3bec5a18706b0a462c148c118b", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "351510da69ab6879df5ff5c7c5f49a8a7aea4632", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "d43e868cae91b3dc393c05c55da0754b0fb3a46a", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "fd8b6723ad5f52770bec9009e45f860f4a8c4321", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "4ce3a6632e7d86d29a42bd1fcf325114b3c11d46", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "e7c0cdc05b48889905cc03215d1993ab94fb6eaa", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "99760276cfd699e55b827ceeb653b31b043b9ceb", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "247e1fe052230458ce11b98e3637acf0b86795cd", "predicted_answer": "unfortunately, i don't have enough information to determine the correct answer. however, since there is only one option available, my response would be:\n\n1. unanswerable", "predicted_evidence": []}
{"question_id": "79cfd1b82c72d18e2279792c66a042c0e9dfa6b7", "predicted_answer": "i'm happy to help! however, i don't see three tasks mentioned in your question. could you please provide more context or clarify which three tasks you are referring to? that way, i can give a more accurate answer.\n\nif not, my best guess based on the option provided is:\n\n1. dynet", "predicted_evidence": []}
{"question_id": "9e1bf306658ef2972159643fdaf149c569db524b", "predicted_answer": "1. the otomanguean language family", "predicted_evidence": []}
{"question_id": "25b24ab1248f14a621686a57555189acc1afd49c", "predicted_answer": "1. dynet", "predicted_evidence": []}
{"question_id": "8486e06c03f82ebd48c7cfbaffaa76e8b899eea5", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "27f575e90487ef68298cfb6452683bb977e39e43", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "157b9f6f8fb5d370fa23df31de24ae7efb75d6f3", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "9bcc1df7ad103c7a21d69761c452ad3cd2951bda", "predicted_answer": "i'm happy to help! however, i notice that there is only one option provided. could you please provide more options so i can give a more accurate answer?", "predicted_evidence": []}
{"question_id": "8427988488b5ecdbe4b57b3813b3f981b07f53a5", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "3604c4fba0a82d7139efd5ced47612c90bd10601", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "38e2f07ba965b676a99be06e8872dade7c04722a", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "931a2a13a1f6a8d9107d26811089bdccc39b0800", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "8c981f8b992cb583e598f71741c322f522c6d2ad", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "16f33de90b76975a99572e0684632d5aedbd957c", "predicted_answer": "1. a reference corpus of 21,093 tokens and their correct lemmas", "predicted_evidence": []}
{"question_id": "d0b005cb7ed6d4c307745096b2ed8762612480d2", "predicted_answer": "1. transformer generation model", "predicted_evidence": []}
{"question_id": "9d9b11f86a96c6d3dd862453bf240d6e018e75af", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "415f35adb0ef746883fb9c33aa53b79cc4e723c3", "predicted_answer": "i'm happy to help! however, i notice that there is only one option provided. could you please provide more options so i can give a more accurate answer?", "predicted_evidence": []}
{"question_id": "52f1a91f546b8a25a5d72325c503ec8f9c72de23", "predicted_answer": "rnnlm bibref11", "predicted_evidence": []}
{"question_id": "bb5697cf352dd608edf119ca9b82a6b7e51c8d21", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "98785bf06e60fcf0a6fe8921edab6190d0c2cec1", "predicted_answer": "1.", "predicted_evidence": []}
{"question_id": "9846f84747b89f5c692665c4ea7111671ad9839a", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "eecf62e18a790bcfdd8a56f0c4f498927ff2fb47", "predicted_answer": "1. softly augments a randomly chosen word in a sentence by its contextual mixture of multiple related words, replacing the one-hot representation of a word by a distribution provided by a language model over the vocabulary", "predicted_evidence": []}
{"question_id": "acda028a21a465c984036dcbb124b7f03c490b41", "predicted_answer": "madl extends the dual learning framework by introducing multiple primal and dual models.", "predicted_evidence": []}
{"question_id": "42af0472e6895eaf7b9392674b0d956e64e86b03", "predicted_answer": "1. german$\\leftrightarrow $english, german$\\leftrightarrow $french, chinese$\\leftrightarrow $english, english$\\rightarrow $lithuanian, english$\\rightarrow $finnish, and russian$\\rightarrow $english, lithuanian$\\rightarrow $english, finnish$\\rightarrow $english, and english$\\rightarrow $kazakh", "predicted_evidence": []}
{"question_id": "a85698f19a91ecd3cd3a90a93a453d2acebae1b7", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "af073d84b8a7c968e5822c79bef34a28655886de", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "e8fcfb1412c3b30da6cbc0766152b6e11e17196c", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "0cd90e5b79ea426ada0203177c28812a7fc86be5", "predicted_answer": "varied the number of experts between models", "predicted_evidence": []}
{"question_id": "f01a88e15ef518a68d8ca2bec992f27e7a3a6add", "predicted_answer": "displayform0, displayform0 displayform1", "predicted_evidence": []}
{"question_id": "44104668796a6ca10e2ea3ecf706541da1cec2cf", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "bbcd77aac74989f820e84488c52f3767d0405d51", "predicted_answer": "i'm happy to help! however, i don't see a list of options provided for the question. could you please provide the complete list of options so i can give you the best answer?", "predicted_evidence": []}
{"question_id": "6a31bd676054222faf46229fc1d283322478a020", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "e4d16050f0b457c93e590261732a20401def9cde", "predicted_answer": "1. levenshtein distance metric bibref8, diacritical swapping, levenshtein distance is used in a weighted sum to cosine distance between word vectors, elmo-augmented lstm", "predicted_evidence": []}
{"question_id": "b25e7137f49f77e7e67ee2f40ca585d3a377f8b5", "predicted_answer": "1. spellchecking mammography reports and tweets", "predicted_evidence": []}
{"question_id": "d803b782023553bbf9b36551fbc888ad189b1f29", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "fc5f9604c74c9bb804064f315676520937131e17", "predicted_answer": "1. bleu scores and the slot error rate (err)", "predicted_evidence": []}
{"question_id": "b37fd665dfa5fad43977069d5623f4490a979305", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "c1f4d632da78714308dc502fe4e7b16ea6f76f81", "predicted_answer": "i don't have enough information to determine which language-pair had better performance since only one option is provided.", "predicted_evidence": []}
{"question_id": "749a307c3736c5b06d7b605dc228d80de36cbabe", "predicted_answer": "1. wmt 2019 parallel dataset, a restricted dataset containing the full ted corpus from must-c bibref10, sampled sentences from wmt 2019 dataset", "predicted_evidence": []}
{"question_id": "102de97c123bb1e247efec0f1d958f8a3a86e2f6", "predicted_answer": "1. bleu and ter scores", "predicted_evidence": []}
{"question_id": "3460393d6888dd34113fa0813a1b3a1514c66aa6", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "d491ee69db39ec65f0f6da9ec03450520389699a", "predicted_answer": "1.", "predicted_evidence": []}
{"question_id": "d3839c7acee4f9c8db0a4a475214a8dcbd0bc26f", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "a6d00f44ff8f83b6c1787e39333e759b0c3daf15", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "0d4aa05eb00d9dee74000ea5b21b08f693ba1e62", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "382bef47d316d7c12ea190ae160bf0912a0f4ffe", "predicted_answer": "manual verification", "predicted_evidence": []}
{"question_id": "32a232310babb92991c4b1b75f7aa6b4670ec447", "predicted_answer": "1. no", "predicted_evidence": []}
{"question_id": "5845d1db7f819dbadb72e7df69d49c3f424b5730", "predicted_answer": "1. hindi", "predicted_evidence": []}
{"question_id": "e829f008d62312357e0354a9ed3b0827c91c9401", "predicted_answer": "1. part of speech, punctuation, sentiment analysis, empath, tf-idf emoticon features", "predicted_evidence": []}
{"question_id": "54fe8f05595f2d1d4a4fd77f4562eac519711fa6", "predicted_answer": "1.", "predicted_evidence": []}
{"question_id": "61404466cf86a21f0c1783ce535eb39a01528ce8", "predicted_answer": "2 is not an option, so i'll choose:\n\n none of the above (i will provide a brief answer instead)\n\nthe key differences in communication styles between twitter and facebook are:\n\n* character limit: twitter has a 280-character limit, while facebook does not have a character limit for posts.\n* tone: twitter is often used for real-time updates and news, with a more formal tone. facebook is often used for personal updates and has a more casual tone.\n* audience: twitter is often used by businesses and public figures to reach a wider audience, while facebook is often used by individuals to connect with friends and family.\n\nplease let me know if you'd like me to elaborate!", "predicted_evidence": []}
{"question_id": "fbe5e513745d723aad711ceb91ce0c3c2ceb669e", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "1571e16063b53409f2d1bd6ec143fccc5b29ebb9", "predicted_answer": "1. majority class baseline (mc)", "predicted_evidence": []}
{"question_id": "d71937fa5da853f7529f767730547ccfb70e5908", "predicted_answer": "1. news articles, twitter", "predicted_evidence": []}
{"question_id": "8d258899e36326183899ebc67aeb4188a86f682c", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "955ca31999309685c1daa5cb03867971ca99ec52", "predicted_answer": "wn18, fb15k", "predicted_evidence": []}
{"question_id": "9b2b063e8a9938da195c9c0d6caa3e37a4a615a8", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "ac3c88ace59bf75788370062db139f60499c2056", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "26012f57cba21ba44b9a9f7ed8b1ed9e8ee7625d", "predicted_answer": "pv-dm", "predicted_evidence": []}
{"question_id": "bd26a6d5d8b68d62e1b6eaf974796f3c34a839c4", "predicted_answer": "1. string length, words co-occurrences, stems co-occurrences, mesh similarity", "predicted_evidence": []}
{"question_id": "7d4fad6367f28c67ad22487094489680c45f5062", "predicted_answer": "window_size, alpha, sample, dm, hs, vector_size", "predicted_evidence": []}
{"question_id": "3aa7173612995223a904cc0f8eef4ff203cbb860", "predicted_answer": "1. slqa, rusalka, hma model (single), trian (single), jiangnan (ensemble), mitre (ensemble), trian (ensemble), hma model (ensemble)", "predicted_evidence": []}
{"question_id": "acc8d9918d19c212ec256181e51292f2957b37d7", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "6f2f304ef292d8bcd521936f93afeec917cbe28a", "predicted_answer": "1. it eliminates non-termination in some models fixing for some models up to 6% of non-termination ratio.", "predicted_evidence": []}
{"question_id": "82fa2b99daa981fc42a882bb6db8481bdbbb9675", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "61fb982b2c67541725d6db76b9c710dd169b533d", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "68edb6a483cdec669c9130c928994654f1c19839", "predicted_answer": "ndcg, mrr, recall@k, mean rank", "predicted_evidence": []}
{"question_id": "f64531e460e0ac09b58584047b7616fdb7dd5b3f", "predicted_answer": "unfortunately, i couldn't find information on the winner of the visual dialog challenge 2019. therefore, my response is:\n\n1. unanswerable", "predicted_evidence": []}
{"question_id": "cee29acec4da1b247795daa4e2e82ef8a7b25a64", "predicted_answer": "1. dl-61", "predicted_evidence": []}
{"question_id": "7e54c7751dbd50d9d14b9f8b13dc94947a46e42f", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "d3bcfcea00dec99fa26283cdd74ba565bc907632", "predicted_answer": "1. 133,287 images", "predicted_evidence": []}
{"question_id": "cdf65116a7c50edddcb115e9afd86b2b6accb8ad", "predicted_answer": "1. verb/preposition-based relation, nominal attribute, descriptive phrase and hyponymy relation.", "predicted_evidence": []}
{"question_id": "c8031c1629d270dedc3b0c16dcb7410524ff1bab", "predicted_answer": "1. restricted copy mechanism to ensure literally honestness, coverage mechanism to alleviate the under extraction and over extraction problem, and gated dependency attention mechanism to incorporate dependency information", "predicted_evidence": []}
{"question_id": "8c0e8a312b85c4ffdffabeef0d29df1ef8ff7fb2", "predicted_answer": "1. 3,200 sentences", "predicted_evidence": []}
{"question_id": "8816333fbed2bfb1838407df9d6c084ead89751c", "predicted_answer": "unfortunately, i couldn't find a clear answer on how data for rtfm (read the fine manual) is collected. since there's only one option available, i'll go with:\n\n1. unanswerable", "predicted_evidence": []}
{"question_id": "37e8f5851133a748c4e3e0beeef0d83883117a98", "predicted_answer": "the proposed model achieves a significantly better performance compared to baselines, with a win rate of 66\u00b122, outperforming baseline cnn (13\u00b11) and baseline film (32\u00b13).", "predicted_evidence": []}
{"question_id": "c9e9c5f443649593632656a5934026ad8ccc1712", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "4d844c9453203069363173243e409698782bac3f", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "5633d93ef356aca02592bae3dfc1b3ec8fce27dc", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "134598831939a3ae20d177cec7033d133625a88e", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "4bae74eb707ed71d5f438ddb3d9c2192ac490f66", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "c30c3e0f8450b1c914d29f41c17a22764fa078e0", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "21656039994cab07f79e89553cbecc31ba9853d4", "predicted_answer": "1. document-level variants of the squad dataset", "predicted_evidence": []}
{"question_id": "bee74e96f2445900e7220bc27795bfe23accd0a7", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "a56fbe90d5d349336f94ef034ba0d46450525d19", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "b1f2db88a6f89d0f048803e38a0a568f5ba38fc5", "predicted_answer": "1. cases of singular/plural, subject pronoun/object pronoun, etc.", "predicted_evidence": []}
{"question_id": "cf3af2b68648fa8695e7234b6928d014e3b141f1", "predicted_answer": "i don't have enough information about \"this approach\" to provide a specific answer. however, i can tell you that common methods used for evaluation of an approach include metrics, benchmarks, and comparison to other approaches.\n\nsince there is only one option provided, which is \"unanswerable\", i will choose:\n\n1. unanswerable", "predicted_evidence": []}
{"question_id": "7883a52f008f3c4aabfc9f71ce05d7c4107e79bb", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "cd9776d03fe48903e43e916385df12e1e798070a", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "1a252ffeaebdb189317aefd6c606652ba9677112", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "da4d25dd9de09d16168788bb02ad600f5b0b3ba4", "predicted_answer": "single head", "predicted_evidence": []}
{"question_id": "2870fbce43a3cf6daf982f720137c008b30c60dc", "predicted_answer": "1. nouns, verbs, pronouns, subjects, objects, negation words, special bert tokens", "predicted_evidence": []}
{"question_id": "65b579b2c62982e2ff154c8160288c2950d509f2", "predicted_answer": "1. mrpc, sts-b, sst-2, qqp, rte, qnli, mnli", "predicted_evidence": []}
{"question_id": "b2c8c90041064183159cc825847c142b1309a849", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "68e3f3908687505cb63b538e521756390c321a1c", "predicted_answer": "1. 2.7 accuracy points", "predicted_evidence": []}
{"question_id": "2f9d30e10323cf3a6c9804ecdc7d5872d8ae35e4", "predicted_answer": "1. snap (stanford network analysis project)", "predicted_evidence": []}
{"question_id": "327e06e2ce09cf4c6cc521101d0aecfc745b1738", "predicted_answer": "1. accuracy with standard deviation", "predicted_evidence": []}
{"question_id": "40b9f502f15e955ba8615822e6fa08cb5fd29c81", "predicted_answer": "corpus 5kl, corpus 8kf", "predicted_evidence": []}
{"question_id": "ba56afe426906c4cfc414bca4c66ceb4a0a68121", "predicted_answer": "1. datasets used are celex (english, dutch), festival (italian), openlexuque (french), iit-guwahati (manipuri), e-hitz (basque)", "predicted_evidence": []}
{"question_id": "14634943d96ea036725898ab2e652c2948bd33eb", "predicted_answer": "1. authors report their best models have following accuracy: english celex (98.5%), dutch celex (99.47%), festival (99.990%), openlexique (100%), iit-guwahat (95.4%), e-hitz (99.83%)", "predicted_evidence": []}
{"question_id": "d71cb7f3aa585e256ca14eebdc358edfc3a9539c", "predicted_answer": "1. celex (dutch and english) - svm-hmm \n2. festival, e-hitz and openlexique - liang hyphenation \n3. iit-guwahat - entropy crf", "predicted_evidence": []}
{"question_id": "f6556d2a8b42b133eaa361f562745edbe56c0b51", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "def3d623578bf84139d920886aa3bd6cdaaa7c41", "predicted_answer": "arabic, czech and turkish", "predicted_evidence": []}
{"question_id": "d51069595f67a3a53c044c8a37bae23facbfa45d", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "1a6e2bd41ee43df83fef2a1c1941e6f95a619ae8", "predicted_answer": "1. entity recognition, semantic role labeling and co-reference resolution", "predicted_evidence": []}
{"question_id": "e6c163f80a11bd057bbd0b6e1451ac82edddc78d", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "6adfa9eee76b96953a76c03356bf41d8a9378851", "predicted_answer": "1.6% lower phone error rate on average", "predicted_evidence": []}
{"question_id": "450a359d117bcfa2de4ffd987f787945f25b3b25", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "70f84c73172211186de1a27b98f5f5ae25a94e55", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "10ddc5caf36fe9d7438eb5a3936e24580c4ffe6a", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "29571867fe00346418b1ec36c3b7685f035e22ce", "predicted_answer": "1. relation prediction, relation extraction, open ie", "predicted_evidence": []}
{"question_id": "1a678d081f97531d54b7122254301c20b3531198", "predicted_answer": "1. wikidata, reverb, fb15k, tacred", "predicted_evidence": []}
{"question_id": "b9f2a30f5ef664ff845d860cf4bfc2afb0a46e5a", "predicted_answer": "1. by assessing similarity of 360 pairs of relations from a subset of wikidata using an integer similarity score from 0 to 4", "predicted_evidence": []}
{"question_id": "3513682d4ee2e64725b956c489cd5b5995a6acf2", "predicted_answer": "monte-carlo", "predicted_evidence": []}
{"question_id": "30b5e5293001f65d2fb9e4d1fdf4dc230e8cf320", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "993b896771c31f3478f28112a7335e7be9d03f21", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "dee116df92f9f92d9a67ac4d30e32822c22158a6", "predicted_answer": "1. no", "predicted_evidence": []}
{"question_id": "94bee0c58976b58b4fef9e0adf6856fe917232e5", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "7efbe48e84894971d7cd307faf5f6dae9d38da31", "predicted_answer": "1. 300-hour english conversational speech", "predicted_evidence": []}
{"question_id": "7f452eb145d486c15ac4d1107fc914e48ebba60f", "predicted_answer": "1. the common voice website, iphone app", "predicted_evidence": []}
{"question_id": "bb71a638668a21c2d446b44cbf51676c839658f7", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "5fa464a158dc8abf7cef8ca7d42a7080670c1edd", "predicted_answer": "1. no", "predicted_evidence": []}
{"question_id": "e1f559da7fa501d3190073bca9ce4d4a12149e80", "predicted_answer": "1. unanswerable", "predicted_evidence": []}
{"question_id": "a96a1a354cb3a2a434b085e4d9c8844d0b672ec4", "predicted_answer": "unfortunately, i don't have enough information to provide a specific answer. however, based on your prompt, i can tell that there is only one option available.\n\n1. unanswerable", "predicted_evidence": []}
{"question_id": "427252648173c3ba78c211b86fa89fc9f4406653", "predicted_answer": "1. business and commerce (bus), government and politics (gov), physical and mental health (hea), law and order (law), lifestyle (lif), military (mil), general purpose (gen)", "predicted_evidence": []}
{"question_id": "b9025c39838ccc2a79c545bec4a676f7cc4600eb", "predicted_answer": "2", "predicted_evidence": []}
{"question_id": "be6971827707afcd13af3085d0a775a0bd61c5dd", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "19608e727b527562b750949e41e763908566b58e", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "0428e06f0550e1063a64d181210795053a8e6436", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "3f7a7e81908a763e5ca720f90570c5f224ac64f6", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "28e7711f94e093137eb8828f0b1eff1b05e4fa38", "predicted_answer": "unfortunately, i don't have enough information to provide a specific answer. however, based on my knowledge, i can try to give a general response.\n\nin natural language processing (nlp), dividing text into utterances is often done using various techniques such as:\n\n* punctuation-based segmentation\n* part-of-speech tagging\n* named entity recognition\n* dependency parsing\n\nhowever, without more context or information about the specific task or domain, it's difficult to provide a precise answer.\n\ngiven the options provided, i would choose \"1. unanswerable\" as the best response, acknowledging that more information is needed to provide an accurate answer.", "predicted_evidence": []}
{"question_id": "49b38189b8336ce41d0f0b4c5c9459722736e15b", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "40c2bab4a6bf3c0628079fcf19e8b52f27f51d98", "predicted_answer": "1. using generative process", "predicted_evidence": []}
{"question_id": "33d2919f3400cd3c6fbb6960d74187ec80b41cd6", "predicted_answer": "the selection model selects the best answer from the set $\\lbrace a_i\\rbrace _{i=1}^n$ observed during the interaction by predicting the difference of the f1 score to the average f1 of all variants.", "predicted_evidence": []}
{"question_id": "281cd4e78b27a62713ec43249df5000812522a89", "predicted_answer": "1. average claim length is 8.9 tokens.", "predicted_evidence": []}
{"question_id": "fb96c0cd777bb2961117feca19c6d41bfd8cfd42", "predicted_answer": "idebate.com, debatewise.org, procon.org", "predicted_evidence": []}
{"question_id": "534f69c8c90467d5aa4e38d7c25c53dbc94f4b24", "predicted_answer": "1. amazon mechanical turk (amt)", "predicted_evidence": []}
{"question_id": "090f2b941b9c5b6b7c34ae18c2cc97e9650f1f0b", "predicted_answer": "1. information retrieval", "predicted_evidence": []}
{"question_id": "5e032de729ce9fc727b547e3064be04d30009324", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "01dc6893fc2f49b732449dfe1907505e747440b0", "predicted_answer": "1. ethics, gender, human rights, sports, freedom of speech, society, religion, philosophy, health, culture, world, politics, environment, education, digital freedom, economy, science and law", "predicted_evidence": []}
{"question_id": "9776156fc93daa36f4613df591e2b49827d25ad2", "predicted_answer": "1. in terms of f1 score, the hybrid approach improved by 23.47% and 1.39% on bidaf and dcn respectively. the dca approach improved by 23.2% and 1.12% on bidaf and dcn respectively.", "predicted_evidence": []}
{"question_id": "03a911049b6d7df2b6391ed5bc129a3b65133bcd", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "f5e571207d9f4701b4d01199ef7d0bfcfa2c0316", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "c5ac07528cf99d353413c9d9ea61a1a699dd783e", "predicted_answer": "1. unigrams, bigrams, and trigrams, including sequences of punctuation, word2vec word embeddings", "predicted_evidence": []}
{"question_id": "6608f171b3e0dcdcd51b3e0c697d6e5003ab5f02", "predicted_answer": "1. adjective and adverb patterns, verb, subject, and object arguments, verbal patterns", "predicted_evidence": []}
{"question_id": "52b113e66fd691ae18b9bb8a8d17e1ee7054bb81", "predicted_answer": "1. vagalume website", "predicted_evidence": []}
{"question_id": "163a21c0701d5cda15be2d0eb4981a686e54a842", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "36b5f0f62ee9be1ab50d1bb6170e98328d45997d", "predicted_answer": "1. word2vec, wang2vec is not a real technique so i assume it's a typo and they meant to say glove, and fasttext", "predicted_evidence": []}
{"question_id": "6b91fe29175be8cd8f22abf27fb3460e43b9889a", "predicted_answer": "1. gospel, sertanejo, mpb, forr\u00f3, pagode, rock, samba, pop, ax\u00e9, funk-carioca, infantil, velha-guarda, bossa-nova and jovem-guarda", "predicted_evidence": []}
{"question_id": "aa7decee4e3006c2c99b1f331a5b32d44a565ef6", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "4b8a0e99bf3f2f6c80c57c0e474c47a5ee842b2c", "predicted_answer": "1. lstms with and without attention, hred, vhred with and without attention, mmi and reranking-rl", "predicted_evidence": []}
{"question_id": "a09633584df1e4b9577876f35e38b37fdd83fa63", "predicted_answer": "1. through amazon mturk annotators to determine plausibility and content richness of the response", "predicted_evidence": []}
{"question_id": "5e9732ff8595b31f81740082333b241d0a5f7c9a", "predicted_answer": "1. on diversity 6.87 and on relevance 4.6 points higher", "predicted_evidence": []}
{"question_id": "58edc6ed7d6966715022179ab63137c782105eaf", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "b366706e2fff6dd8edc89cc0c6b9d5b0790f43aa", "predicted_answer": "bpra, apra, bleu", "predicted_evidence": []}
{"question_id": "c165ea43256d7ee1b1fb6f5c0c8af5f7b585e60d", "predicted_answer": "gdp significantly outperforms the baselines on bleu: dstc2 (+0.0791), maluuba (+0.0492)", "predicted_evidence": []}
{"question_id": "e72a672f8008bbc52b93d8037a5fedf8956136af", "predicted_answer": "e2ecm, cdm", "predicted_evidence": []}
{"question_id": "57586358dd01633aa2ebeef892e96a549b1d1930", "predicted_answer": "dstc2, maluuba", "predicted_evidence": []}
{"question_id": "028910d643c103abd90045ccb07ee8adc5a3e177", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "975085e3b6679cc644fdd6ad11b7c2d1261a2dc6", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "609fbe627309775de415682f48588937d5dd8748", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "4a8bceb3b6d45f14c4749115d6aa83912f0b0a6e", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "7ce213657f7ee792148988c5a3578b24cd2f9c62", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "89ce18ee52c52a78b38c49b14574407b7ea2fb02", "predicted_answer": "1. attention-based lstm with emojis", "predicted_evidence": []}
{"question_id": "d3092cd32cd581a57fa4844f80fe18d6b920e903", "predicted_answer": "lstm with text embedding", "predicted_evidence": []}
{"question_id": "0b39c20db6e60ce07bf5465bd3c08fedc0587780", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "fb427239c8d44f524a6c1bf1ce5c3383d5c33e52", "predicted_answer": "the model has around 836m parameters.", "predicted_evidence": []}
{"question_id": "7c45c6e5db6cfca2d6de8751e28403b35420ae38", "predicted_answer": "256", "predicted_evidence": []}
{"question_id": "49ea25af6f75e2e96318bad5ecf784ce84e4f76b", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "aecd09a817c38cf7606e2888d0df7f14e5a74b95", "predicted_answer": "1. ordinal position, length of sentence, the ratio of nouns, the ratio of numerical entities, cue words, cosine position, relative length, tf-isf, pos features, document sentences, document words, topical category, ratio of verbs, ratio of adjectives, and ratio of adverbs", "predicted_evidence": []}
{"question_id": "81064bbd0a0d72a82d8677c32fb71b06501830a0", "predicted_answer": "1. rouge-1 increases by 0.05, rouge-2 by 0.06 and rouge-l by 0.09", "predicted_evidence": []}
{"question_id": "7d841b98bcee29aaa9852ef7ceea1213d703deba", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "4e8233826f9e04f5763b307988298e73f841af74", "predicted_answer": "i don't have enough information to determine if the dataset is balanced across categories. can you please provide more context or details about the dataset?", "predicted_evidence": []}
{"question_id": "adae0c32a69928929101d0ba37d36c0a45298ad6", "predicted_answer": "1. support vector machines (svms), logistic regression, na\u00efve bayes, perceptron, and decision trees, a two-layer bidirectional gated recurrent neural network (grnn) bibref20 and convolutional neural network (cnn) (as designed in bibref21)", "predicted_evidence": []}
{"question_id": "d0f831c97d345a5b8149a9d51bf321f844518434", "predicted_answer": "1. binary label of stress or not stress", "predicted_evidence": []}
{"question_id": "1ccfd288f746c35006f5847297ab52020729f523", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "ed6462da17c553bda112ef35917fefe6942fce3c", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "b8cee4782e05afaeb9647efdb8858554490feba5", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "915cf3d481164217290d7b1eb9d48ed3e249196d", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "d6e8b32048ff83c052e978ff3b8f1cb097377786", "predicted_answer": "1. by annotators on amazon mechanical turk.", "predicted_evidence": []}
{"question_id": "e26e7e9bcd7e2cea561af596c59b98e823653a4b", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "b24767fe7e6620369063e646fd3048dc645a8348", "predicted_answer": "overlapping dialogue acts", "predicted_evidence": []}
{"question_id": "0a7ac8eccbc286e0ab55bc5949f3f8d2ea2d1a60", "predicted_answer": "one", "predicted_evidence": []}
{"question_id": "e84e80067b3343d136fd75300691c8b3d3efbdac", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "45bd22f2cfb62a5f79ec3c771c8324b963567cc0", "predicted_answer": "i think there may be a misunderstanding here.\n\nthe options provided don't seem to match the question. the option \"1. yes\" doesn't make sense as an answer to the question \"where do they collect the synthetic data?\" because it's not a location.\n\nif i had to provide a best guess, i would say that the question is incomplete or missing context, and i couldn't provide a meaningful answer.", "predicted_evidence": []}
{"question_id": "936878cff0e6e327b2554ee5d46686797ee92cf2", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "58c1b162a4491d4a5ae0ff86cc8bd64e98739620", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "4dad15fee1fe01c3eadce8f0914781ca0a6e3f23", "predicted_answer": "1. they exclude slot-specific parameters and incorporate better feature representation of user utterance and dialogue states using syntactic information and convolutional neural networks (cnn).", "predicted_evidence": []}
{"question_id": "892c346617a3391c7dafc9da1b65e5ea3890294d", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "36feaac9d9dee5ae09aaebc2019b014e57f61fbf", "predicted_answer": "1. by the number of parameters.", "predicted_evidence": []}
{"question_id": "df25dd9004a3b367202d7731ee912a8052a35780", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "5328cc2588b2bf7b91f4e0f342e8cbfc6dc8ac00", "predicted_answer": "1. lstm-based rnn-t", "predicted_evidence": []}
{"question_id": "2ebd7a59baad1f935fe83f90526557bfa9df4047", "predicted_answer": "unfortunately, i don't have information on what the previous state of the art accuracy was on librispeech benchmark. therefore, my response is:\n\n1. unanswerable", "predicted_evidence": []}
{"question_id": "766e2e35968ef7434b56330aa41957c5d5f8d0ee", "predicted_answer": "1. 970 hours of audio data with corresponding text transcripts (around 10m word tokens) and an additional 800m word token text only dataset", "predicted_evidence": []}
{"question_id": "63a77d2640df8315bf0bc3925fdd7e27132b1244", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "50be9e6203c40ed3db48ed37103f967ef0ea946c", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "36a9230fadf997d3b0c5fc8af8d89bd48bf04f12", "predicted_answer": "rnn", "predicted_evidence": []}
{"question_id": "496304f63006205ee63da376e02ef1b3010c4aa1", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "00e9f088291fcf27956f32a791f87e4a1e311e41", "predicted_answer": "1. multi-lingual nmt, natural language inference, constituency parsing, skip-thought vectors", "predicted_evidence": []}
{"question_id": "e2f269997f5a01949733c2ec8169f126dabd7571", "predicted_answer": "all of them", "predicted_evidence": []}
{"question_id": "317a6f211ecf48c58f008c12fbd5d41901db3e36", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "a726046eec1e2efa5fe3926963863bf755e64682", "predicted_answer": "1. german, english, chinese", "predicted_evidence": []}
{"question_id": "6d9fbd42b54313cfdc2665809886330f209e9286", "predicted_answer": "iwslt16", "predicted_evidence": []}
{"question_id": "bb8f62950acbd4051774f1bfc50e3d424dd33b7c", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "d653d994ef914d76c7d4011c0eb7873610ad795f", "predicted_answer": "1.", "predicted_evidence": []}
{"question_id": "880a76678e92970791f7c1aad301b5adfc41704f", "predicted_answer": "1.", "predicted_evidence": []}
{"question_id": "e3dc8689d8db31f04797f515fe224f6075f5cb16", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "cfb5ab893ed77f9df7eeb4940b6bacdef5acccea", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "a5abd4dd91e6f2855e9098bd6ae1481c0fdb0d4a", "predicted_answer": "tb-dense, matres", "predicted_evidence": []}
{"question_id": "e67d2266476abd157fc8c396b3dfb70cb343471e", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "c69f4df4943a2ca4c10933683a02b179a5e76f64", "predicted_answer": "svt", "predicted_evidence": []}
{"question_id": "6aed1122050b2d508dc1790c13cdbe38ff126089", "predicted_answer": "1. attention-based sequence-to-sequence model", "predicted_evidence": []}
{"question_id": "8740c3000e740ac5c0bc8f329d908309f7ffeff6", "predicted_answer": "mojitalk, personachat, empathetic-dialogues", "predicted_evidence": []}
{"question_id": "7772cb23b7609f1d4cfd6511ac3fcdc20f8481ba", "predicted_answer": "table tabref44", "predicted_evidence": []}
{"question_id": "acf278679c584ae4f332f6134711602af26edfb4", "predicted_answer": "unfortunately, i don't have enough information to provide a specific answer. therefore, my response is:\n\n1. unanswerable", "predicted_evidence": []}
{"question_id": "13f7d50b3b8b0b97d90401eeb0a4e97c9eab3a76", "predicted_answer": "unfortunately, i couldn't find a reliable source confirming the specific data the prague dependency treebank is built on. therefore, my response would be:\n\n1. unanswerable", "predicted_evidence": []}
{"question_id": "48fb76ae9921c9d181f65afc63a42af8ba3bc519", "predicted_answer": "1. large raw czech corpora available from the lindat/clarin repository, czech wikipedia", "predicted_evidence": []}
{"question_id": "13149342ccbb7a6df9b4b1bed890cfbdc1331c1f", "predicted_answer": "1. a total of 2,560 pseudo-tweets in three different languages: japanese (ja), english (en) and chinese (zh)", "predicted_evidence": []}
{"question_id": "fbe149bd76863575b98fafb3679f411d3d21b4a3", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "6992f8e5a33f0af0f2206769484c72fecc14700b", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "a91abc7983fffa6b2e1e46133f559cec3d7d9438", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "c45feda62f23245f53e855706e2d8ea733b7fd03", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "9785ecf1107090c84c57112d01a8e83418a913c1", "predicted_answer": "german, spanish, chinese", "predicted_evidence": []}
{"question_id": "e051d68a7932f700e6c3f48da57d3e2519936c6d", "predicted_answer": "1. bidirectional lstm based ner model of flair", "predicted_evidence": []}
{"question_id": "9e2e5918608a2911b341d4887f58a4595d7d1429", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "0ec4143a4f1a8f597b435f83c0451145be2ab95b", "predicted_answer": "1. frequency masking, time masking, additive noise, speed and volume perturbation", "predicted_evidence": []}
{"question_id": "90159e143487505ddc026f879ecd864b7f4f479e", "predicted_answer": "1.", "predicted_evidence": []}
{"question_id": "d10e256f2f724ad611fd3ff82ce88f7a78bad7f7", "predicted_answer": "1. macro f1 score of 0.62", "predicted_evidence": []}
{"question_id": "c691b47c0380c9529e34e8ca6c1805f98288affa", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "892e42137b14d9fabd34084b3016cf3f12cac68a", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "dc69256bdfe76fa30ce4404b697f1bedfd6125fe", "predicted_answer": "1. hindi, english and german", "predicted_evidence": []}
{"question_id": "097ab15f58cb1fce5b5ffb5082b8d7bbee720659", "predicted_answer": "i'm happy to help! however, i notice that there is only one option provided, which is \"thai\". could you please provide more options so i can give a more accurate answer?", "predicted_evidence": []}
{"question_id": "b8d5e9fa08247cb4eea835b19377262d86107a9d", "predicted_answer": "1. ibm-ub-1 dataset bibref25, iam-ondb dataset bibref42, the icdar-2013 competition for online handwriting chinese character recognition bibref45, icfhr2018 competition on vietnamese online handwritten text recognition using vnondb bibref50", "predicted_evidence": []}
{"question_id": "8de64483ae96c0a03a8e527950582f127b43dceb", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "4d062673b714998800e61f66b6ccbf7eef5be2ac", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "f4238f558d6ddf3849497a130b3a6ad866ff38b3", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "3582fac4b2705db056f75a14949db7b80cbc3197", "predicted_answer": "unfortunately, i don't have enough information about the previous jentzsch paper to provide a specific answer. therefore, my response is:\n\n1. unanswerable", "predicted_evidence": []}
{"question_id": "96dcabaa8b6bd89b032da609e709900a1569a0f9", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "f416c6818a7a8acb7ec4682ed424ecdbd7dd6df1", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "a1d422cb2e428333961370496ca281a1be99fdff", "predicted_answer": "1. coherence, logical consistency, fluency and diversity", "predicted_evidence": []}
{"question_id": "3de9bf4b0b667b3f1181da9f006da1354565bcbd", "predicted_answer": "1. bleu, embedding-based metrics (average, extrema, greedy and coherence), entropy-based metrics (ent-{1,2}), distinct metrics (dist-{1,2,3} and intra-{1,2,3})", "predicted_evidence": []}
{"question_id": "1a1293e24f4924064e6fb9998658f5a329879109", "predicted_answer": "dialogwae", "predicted_evidence": []}
{"question_id": "3ccd337f77c5d2f7294eb459ccc1770796c2eaef", "predicted_answer": "model confidence, continuity, query-relatedness, repetitiveness, specificity", "predicted_evidence": []}
{"question_id": "f6937199e4b06bfbaa22edacc7339410de9703db", "predicted_answer": "1. personachat bibref12, dailydialog bibref13, opensubtitles bibref7", "predicted_evidence": []}
{"question_id": "61c9f97ee1ac5a4b8654aa152f05f22e153e7e6e", "predicted_answer": "1. wikipedia toxic comments", "predicted_evidence": []}
{"question_id": "9ae084e76095194135cd602b2cdb5fb53f2935c1", "predicted_answer": "1. word error rate", "predicted_evidence": []}
{"question_id": "67ee7a53aa57ce0d0bc1a20d41b64cb20303f4b7", "predicted_answer": "1. 163,110,000 utterances", "predicted_evidence": []}
{"question_id": "7eb3852677e9d1fb25327ba014d2ed292184210c", "predicted_answer": "1. from youtube videos, with associated transcripts obtained from semi-supervised caption filtering, from a voice search service", "predicted_evidence": []}
{"question_id": "4f9a8b50903deb1850aee09c95d1b6204a7410b4", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "c96a6b30d71c6669592504e4ee8001e9d1eb1fba", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "42d66726b5bf8de5b0265e09d76f5ab00c0e851a", "predicted_answer": "single-turn, multi-turn", "predicted_evidence": []}
{"question_id": "c418deef9e44bc8448d9296c6517824cb95bd554", "predicted_answer": "1. f1-score, bleu score", "predicted_evidence": []}
{"question_id": "d6d29040e7fafceb188e62afba566016b119b23c", "predicted_answer": "1. pdp-60, wsc-273", "predicted_evidence": []}
{"question_id": "21663d2744a28e0d3087fbff913c036686abbb9a", "predicted_answer": "unfortunately, i don't have enough information to determine how their model differs from bert. however, based on the options provided, my response would be:\n\n1. their model does not differ from bert.\n\nplease note that this is a guess and may not be accurate without more context or information about \"their model\".", "predicted_evidence": []}
{"question_id": "d8cecea477dfc5163dca6e2078a2fe6bc94ce09f", "predicted_answer": "1. accuracy", "predicted_evidence": []}
{"question_id": "dd2f21d60cfca3917a9eb8b192c194f4de85e8b2", "predicted_answer": "1. interdependence between rate and distortion, impact of kl on the sharpness of the approximated posteriors, demonstrate how certain generative behaviours could be imposed on vaes via a range of maximum channel capacities, some experiments to find if any form of syntactic information is encoded in the latent space", "predicted_evidence": []}
{"question_id": "ccf7415b515fe5c59fa92d4a8af5d2437c591615", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "fee5aef7ae521ccd1562764a91edefecec34624d", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "90f80a94fabaab72833256572db1d449c2779beb", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "5872279c5165cc8a0c58cf1f89838b7c43217b0e", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "da55878d048e4dca3ca3cec192015317b0d630b1", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "7d300176afa04947ac847135ac6ea2929908c0b0", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "df9d16a2c4983a0ff46081e3ff4d6e7ef3338264", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "8c35caf3772637e6297009ceab38f7f5be38ea9d", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "3a1bd3ec1a7ce9514da0cb2dfcaa454ba8c0ed14", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "39492338e27cb90bf1763e4337c2f697cf5082ba", "predicted_answer": "1. 10 cnns and 10 lstms", "predicted_evidence": []}
{"question_id": "a7adb63db5066d39fdf2882d8a7ffefbb6b622f0", "predicted_answer": "1. there is no baseline.", "predicted_evidence": []}
{"question_id": "980568848cc8e7c43f767da616cf1e176f406b05", "predicted_answer": "1. 27", "predicted_evidence": []}
{"question_id": "f1b738a7f118438663f9d77b4ccd3a2c4fd97c01", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "5a23f436a7e0c33e4842425cf86d5fd8ba78ac92", "predicted_answer": "1. 553,451 documents", "predicted_evidence": []}
{"question_id": "2f4acd34eb2d09db9b5ad9b1eb82cb4a88c13f5b", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "e7329c403af26b7e6eef8b60ba6fefbe40ccf8ce", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "e79a5e435fcf5587535f06c9215d19a66caadaff", "predicted_answer": "determining sentiment from figurative language in twitter", "predicted_evidence": []}
{"question_id": "f7d67d6c6fbc62b2953ab74db6871b122b3c92cc", "predicted_answer": "1. it is an order of magnitude more efficient in terms of training time., his model requires pre-training and mutual-learning and requires days of training time, whereas the simple architecture we propose requires on the order of an hour", "predicted_evidence": []}
{"question_id": "085147cd32153d46dd9901ab0f9195bfdbff6a85", "predicted_answer": "2. mvcnn", "predicted_evidence": []}
{"question_id": "c0035fb1c2b3de15146a7ce186ccd2e366fb4da2", "predicted_answer": "1. in terms of subj the average mgnc-cnn is better than the average score of baselines by 0.5. similarly, scores of sst-1, sst-2, and trec where mgnc-cnn has similar improvements. \nin case of irony the difference is about 2.0.", "predicted_evidence": []}
{"question_id": "a8e4a67dd67ae4a9ebf983a90b0d256f4b9ff6c6", "predicted_answer": "sst-2", "predicted_evidence": []}
{"question_id": "34dd0ee1374a3afd16cf8b0c803f4ef4c6fec8ac", "predicted_answer": "c-cnn", "predicted_evidence": []}
{"question_id": "53377f1c5eda961e438424d71d16150e669f7072", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "f37ed011e7eb259360170de027c1e8557371f002", "predicted_answer": "6.53%", "predicted_evidence": []}
{"question_id": "41d3750ae666ea5a9cea498ddfb973a8366cccd6", "predicted_answer": "1. annotators are asked how attractive the headlines are, likert scale from 1 to 10 (integer values)", "predicted_evidence": []}
{"question_id": "90b2154ec3723f770c74d255ddfcf7972fe136a2", "predicted_answer": "1. human evaluation task about the style strength", "predicted_evidence": []}
{"question_id": "f3766c6937a4c8c8d5e954b4753701a023e3da74", "predicted_answer": "1. fine-tuned the gpt-2 medium model bibref51 on our collected headlines and then used it to measure the perplexity (ppl) on the generated outputs", "predicted_evidence": []}
{"question_id": "2898e4aa7a3496c628e7ddf2985b48fb11aa3bba", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "fa9df782d743ce0ce1a7a5de6a3de226a7e423df", "predicted_answer": "1. the languages considered were english, chinese, german, russian, arabic, spanish, french", "predicted_evidence": []}
{"question_id": "6270d5247f788c4627be57de6cf30112560c863f", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "cb370692fe0beef90cdaa9c8e43a0aab6f0e117a", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "d0c636fa9ef99c4f44ab39e837a680217b140269", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "c47f593a5b92abc2e3c536fe2baaca226913688b", "predicted_answer": "see figure 3", "predicted_evidence": []}
{"question_id": "c3a9732599849ba4a9f07170ce1e50867cf7d7bf", "predicted_answer": "4) fasttext algorithm with bidirectional lstm (fasttext-bilstm)", "predicted_evidence": []}
{"question_id": "0fd678d24c86122b9ab27b73ef20216bbd9847d1", "predicted_answer": "1. accuracy on each dataset and the average accuracy on all datasets.", "predicted_evidence": []}
{"question_id": "b556fd3a9e0cff0b33c63fa1aef3aed825f13e28", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "0db1ba66a7e75e91e93d78c31f877364c3724a65", "predicted_answer": "1. sentiment classification, transferability of shared sentence representation, introducing sequence labeling as auxiliary task", "predicted_evidence": []}
{"question_id": "b44ce9aae8b1479820555b99ce234443168dc1fe", "predicted_answer": "1. multiun bibref20, opensubtitles bibref21", "predicted_evidence": []}
{"question_id": "b9c0049a7a5639c33efdb6178c2594b8efdefabb", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "99c50d51a428db09edaca0d07f4dab0503af1b94", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "d1747b1b56fddb05bb1225e98fd3c4c043d74592", "predicted_answer": "1. convolutional neural network , bidirectional recurrent neural network model with attention mechanism", "predicted_evidence": []}
{"question_id": "5a29b1f9181f5809e2b0f97b4d0e00aea8996892", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "f5db12cd0a8cd706a232c69d94b2258596aa068c", "predicted_answer": "42% (66.0 - 24.1)", "predicted_evidence": []}
{"question_id": "2c8d5e3941a6cc5697b242e64222f5d97dba453c", "predicted_answer": "1. bert on quora drops from 94.6% to 24.1%", "predicted_evidence": []}
{"question_id": "78102422a5dc99812739b8dd2541e4fdb5fe3c7a", "predicted_answer": "the provided options do not include a typical description of a discriminator in a generative adversarial setup. however, based on common knowledge about gans (generative adversarial networks), i'll select an option that might be closest to describing a discriminator's role, although it seems incomplete or inaccurate.\n\n1. current model", "predicted_evidence": []}
{"question_id": "930c51b9f3936d936ee745716536a4b40f531c7f", "predicted_answer": "quora, mrpc", "predicted_evidence": []}
{"question_id": "20eb673b01d202b731e7ba4f84efc10a18616dd3", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "e8e6719d531e7bef5d827ac92c7b1ab0b8ec3c8e", "predicted_answer": "unfortunately, i don't have enough information to provide a specific answer from the options given, as there is only one option and it's \"unanswerable\". however, i can try to provide an answer based on general knowledge.\n\nsome corpus characteristics that may correlate with more equitable gender balance include:\n\n* balanced representation of male and female authors or speakers\n* similar frequencies of masculine and feminine pronouns\n* equal distribution of topics related to men's and women's interests\n* avoidance of biased language or stereotypes\n\nplease note that this is a general answer, and the actual correlation may depend on various factors.", "predicted_evidence": []}
{"question_id": "f6e5febf2ea53ec80135bbd532d6bb769d843dd8", "predicted_answer": "unfortunately, i don't have enough information to provide a specific answer. therefore, my response is:\n\n1. unanswerable", "predicted_evidence": []}
{"question_id": "4059c6f395640a6acf20a0ed451d0ad8681bc59b", "predicted_answer": "\u03b4softmax = \u03b4output * diag(softmax(output)) - softmax(output) * \u03b4output^t * softmax(output)", "predicted_evidence": []}
{"question_id": "99d7bef0ef395360b939a3f446eff67239551a9d", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "a1097ce59270d6f521d92df8d2e3a279abee3e67", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "56e58bdf0df76ad1599021801f6d4c7b77953e29", "predicted_answer": "1. influence of each word on the score of the correct relation, that impact should and does still correlate with human judgments", "predicted_evidence": []}
{"question_id": "e74ba39c35af53d3960be5a6c86eddd62cef859f", "predicted_answer": "none of the above options are correct as there is only one option provided and it's a statement rather than an option for comparison.", "predicted_evidence": []}
{"question_id": "458f3963387de57fdc182875c9ca3798b612b633", "predicted_answer": "gpt2, scibert model of bibref11", "predicted_evidence": []}
{"question_id": "69a88b6be3b34acc95c5e36acbe069c0a0bc67d6", "predicted_answer": "1. 8.1 million scientific documents, 154k computer science articles, 622k citing sentences", "predicted_evidence": []}
{"question_id": "7befb7a8354fca9d2a94e3fd4364625c98067ebb", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "da1994421934082439e8fe5071a01d3d17b56601", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "30c6d34b878630736f819fd898319ac4e71ee50b", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "a4ff1b91643e0c8a0d4cc1502d25ca85995cf428", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "544e29937e0c972abcdd27c953dc494b2376dd76", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "b8fdc600f9e930133bb3ec8fbcc9c600d60d24b0", "predicted_answer": "1. unanswerable", "predicted_evidence": []}
{"question_id": "bdc93ac1b8643617c966e91d09c01766f7503872", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "4ca0d52f655bb9b4bc25310f3a76c5d744830043", "predicted_answer": "1. 1 000 labeled dialogues for training and 240 unlabeled dialogues for evaluation", "predicted_evidence": []}
{"question_id": "d2fbf34cf4b5b1fd82394124728b03003884409c", "predicted_answer": "i don't have enough information to determine the correct answer. however, based on the options provided, i can only give one possible answer:\n\n1. idea", "predicted_evidence": []}
{"question_id": "4c71ed7d30ee44cf85ffbd7756b985e32e8e07da", "predicted_answer": "1. document categorization, regression tasks", "predicted_evidence": []}
{"question_id": "1949d84653562fa9e83413796ae55980ab7318f2", "predicted_answer": "1. mean reciprocal rank", "predicted_evidence": []}
{"question_id": "7ee660927e2b202376849e489faa7341518adaf9", "predicted_answer": "1.", "predicted_evidence": []}
{"question_id": "f6380c60e2eb32cb3a9d3bca17cf4dc5ae584eca", "predicted_answer": "none of the above options directly answers why big data is not appropriate for a task. however, i will choose option 1 as it implies that sometimes smaller datasets can be more effective in certain situations, which could indirectly suggest that big data might not always be necessary or suitable.", "predicted_evidence": []}
{"question_id": "c7d99e66c4ab555fe3d616b15a5048f3fe1f3f0e", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "400efd1bd8517cc51f217b34cbf19c75d94b1874", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "4698298d506bef02f02c80465867f2cd12d29182", "predicted_answer": "bibref35 for vqa dataset, bibref5, bibref36", "predicted_evidence": []}
{"question_id": "4e2cb1677df949ee3d1d3cd10962b951da907105", "predicted_answer": "1. decoder that generates question using an lstm-based language model", "predicted_evidence": []}
{"question_id": "9cc0fd3721881bd8e246d20fff5d15bd32365655", "predicted_answer": "1. image", "predicted_evidence": []}
{"question_id": "82c4863293a179fe5c0d9a1ff17d224bde952f54", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "88d9d32fb7a22943e1f4868263246731a1726e6e", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "af82043e7d046c2fb1ed86ef9b48c35492e6a48c", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "1bc8904118eb87fa5949ad7ce5b28ad3b3082bd0", "predicted_answer": "1. twitter", "predicted_evidence": []}
{"question_id": "5dc1aca619323ea0d4717d1f825606b2b7c21f01", "predicted_answer": "1.", "predicted_evidence": []}
{"question_id": "dd5c9a370652f6550b4fd13e2ac317eaf90973a8", "predicted_answer": "1. 0.9098 correlation", "predicted_evidence": []}
{"question_id": "39c78924df095c92e058ffa5a779de597e8c43f4", "predicted_answer": "1. using latent dirichlet allocation on tf-idf transformed from the corpus", "predicted_evidence": []}
{"question_id": "a95188a0f35d3cb3ca70ae1527d57ac61710afa3", "predicted_answer": "1. 60,000", "predicted_evidence": []}
{"question_id": "a1557ec0f3deb1e4cd1e68f4880dcecda55656dd", "predicted_answer": "1. northeast u.s., west u.s. and south u.s.", "predicted_evidence": []}
{"question_id": "096f5c59f43f49cab1ef37126341c78f272c0e26", "predicted_answer": "51,104", "predicted_evidence": []}
{"question_id": "c348a8c06e20d5dee07443e962b763073f490079", "predicted_answer": "1. evidence extraction and answer synthesis", "predicted_evidence": []}
{"question_id": "0300cf768996849cab7463d929afcb0b09c9cf2a", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "dd8f72cb3c0961b5ca1413697a00529ba60571fe", "predicted_answer": "1. there are several related passages for each question in the ms-marco dataset., ms-marco also annotates which passage is correct", "predicted_evidence": []}
{"question_id": "fbd094918b493122b3bba99cefe5da80cf88959c", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "78661bdd4d11148e07bdf17141cf088db4ad60c6", "predicted_answer": "1. an official f1-score of 0.2905 on the test set", "predicted_evidence": []}
{"question_id": "95d98b2a7fbecd1990ec9a070f9d5624891a4f26", "predicted_answer": "4,792", "predicted_evidence": []}
{"question_id": "586566de02abdf20b7bfd0d5a43ba93cb02795c3", "predicted_answer": "1. a non-parameter optimized linear-kernel svm that uses tf-idf bag-of-word vectors as inputs", "predicted_evidence": []}
{"question_id": "dfd9302615b27abf8cbef1a2f880a73dd5f0c753", "predicted_answer": "bert-large-wwm", "predicted_evidence": []}
{"question_id": "e09dcb6fc163bba7d704178e7edba2e630b573c2", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "c8f11561fc4da90bcdd72f76414421e1527c0287", "predicted_answer": "ljspeech", "predicted_evidence": []}
{"question_id": "51de39c8bad62d3cbfbec1deb74bd8a3ac5e69a8", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "d9cbcaf8f0457b4be59178446f1a280d17a923fa", "predicted_answer": "direct comparison of model parameters", "predicted_evidence": []}
{"question_id": "fc69f5d9464cdba6db43a525cecde2bf6ddaaa57", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "e1f5531ed04d0aae1dfcb0559f1512a43134c43a", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "4a4b7c0d3e7365440b49e9e6b67908ea5cea687d", "predicted_answer": "binary-bert", "predicted_evidence": []}
{"question_id": "da845a2a930fd6a3267950bec5928205b6c6e8e8", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "2fa0b9d0cb26e1be8eae7e782ada6820bc2c037f", "predicted_answer": "1. 97.32%", "predicted_evidence": []}
{"question_id": "76ce9e02d97e2d77fe28c0fa78526809e7c195c6", "predicted_answer": "madamira bibref6 system", "predicted_evidence": []}
{"question_id": "64c7545ce349265e0c97fd6c434a5f8efdc23777", "predicted_answer": "1. lemmatization is done by an expert arabic linguist where spelling corrections are marked, and lemmas are provided with full diacritization", "predicted_evidence": []}
{"question_id": "47822fec590e840438a3054b7f512fec09dbd1e1", "predicted_answer": "70 articles", "predicted_evidence": []}
{"question_id": "989271972b3176d0a5dabd1cc0e4bdb671269c96", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "26c64edbc5fa4cdded69ace66fdba64a9648b78e", "predicted_answer": "1. unanswerable", "predicted_evidence": []}
{"question_id": "e06e1b103483e1e58201075c03e610202968c877", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "b0fd686183b056ea3f63a7ab494620df1d598c24", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "7065e6140dbaffadebe62c9c9d3863ca0f829d52", "predicted_answer": "seven", "predicted_evidence": []}
{"question_id": "9508e9ec675b6512854e830fa89fa6a747b520c5", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "a65e5c97ade6e697ec10bcf3c3190dc6604a0cd5", "predicted_answer": "the e2e nlg challenge dataset", "predicted_evidence": []}
{"question_id": "e28a6e3d8f3aa303e1e0daff26b659a842aba97b", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "0fce128b8aaa327ac0d58ec30cd2ecbea2019baa", "predicted_answer": "1. seq2seq, hlstm, hlstm+copy, hlstm+graph attention, hlstm+contextual attention", "predicted_evidence": []}
{"question_id": "7a7e279170e7a2f3bc953c37ee393de8ea7bd82f", "predicted_answer": "cloze-style reading comprehension and user query reading comprehension questions", "predicted_evidence": []}
{"question_id": "e3981a11d3d6a8ab31e1b0aa2de96f253653cfb2", "predicted_answer": "1. english", "predicted_evidence": []}
{"question_id": "74b0d3ee0cc9b0a3d9b264aba9901ff97048a897", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "9eb5b336b3dcb7ab63f673ba9ab1818573cce6c3", "predicted_answer": "1. 1.1 million sentences, 119 different relation types (unique predicates)", "predicted_evidence": []}
{"question_id": "0a92352839b549d07ac3f4cb997b8dc83f64ba6f", "predicted_answer": "1. 2 accuracy points", "predicted_evidence": []}
{"question_id": "242f96142116cf9ff763e97aecd54e22cb1c8b5a", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "fcd0bd2db39898ee4f444ae970b80ea4d1d9b054", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "5cc937c2dcb8fd4683cb2298d047f27a05e16d43", "predicted_answer": "1. continuous relaxation to top-k-argmax", "predicted_evidence": []}
{"question_id": "37016cc987d33be5ab877013ef26ec7239b48bd9", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "b3dc6d95d1570ad9a58274539ff1def12df8f474", "predicted_answer": "1. through the experiments, we empirically studied our analysis on dirl and the effectiveness of our proposed solution in dealing with the problem it suffered from.", "predicted_evidence": []}
{"question_id": "cc5d3903913fa2e841f900372ec74b0efd5e0c71", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "c95fd189985d996322193be71cf5be8858ac72b5", "predicted_answer": "information extraction", "predicted_evidence": []}
{"question_id": "4a61260d6edfb0f93100d92e01cf655812243724", "predicted_answer": "machine translation, sentiment analysis, and statistical machine are not the top 3 cited nlp areas. however, based on general knowledge, i would say that the top 3 cited nlp areas are:\n\n1. sentiment analysis\n2. machine translation\n3. named entity recognition", "predicted_evidence": []}
{"question_id": "5c95808cd3ee9585f05ef573b0d4a52e86d04c60", "predicted_answer": "cl journal and emnlp conference", "predicted_evidence": []}
{"question_id": "b6f5860fc4a9a763ddc5edaf6d8df0eb52125c9e", "predicted_answer": "english, chinese, french, japanese and arabic", "predicted_evidence": []}
{"question_id": "7955dbd79ded8ef4ae9fc28b2edf516320c1cb55", "predicted_answer": "1. size, demographics, areas of research, impact, and correlation of citations with demographic attributes (age and gender)", "predicted_evidence": []}
{"question_id": "6bff681f1f6743ef7aa6c29cc00eac26fafdabc2", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "205163715f345af1b5523da6f808e6dbf5f5dd47", "predicted_answer": "1. 44,896 articles", "predicted_evidence": []}
{"question_id": "8d989490c5392492ad66e6a5047b7d74cc719f30", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "a7829abed2186f757a59d3da44893c0172c7012b", "predicted_answer": "1. number of coattention blocks, the batch size, and the number of epochs trained and ensembled our three best networks", "predicted_evidence": []}
{"question_id": "707db46938d16647bf4b6407b2da84b5c7ab4a81", "predicted_answer": "2. transformer skip improves f1 from 74.34 to 74.95", "predicted_evidence": []}
{"question_id": "d72548fa4d29115252605d5abe1561a3ef2430ca", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "24d06808fa3b903140659ee5a471fdfa86279980", "predicted_answer": "1. standard transformer base model", "predicted_evidence": []}
{"question_id": "dba3d05c495e2c8ca476139e78f65059db2eb72d", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "0062ad4aed09a57d0ece6aa4b873f4a4bf65d165", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "67a28fe78f07c1383176b89e78630ee191cf15db", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "d8de12f5eff64d0e9c9e88f6ebdabc4cdf042c22", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "9cba2ee1f8e1560e48b3099d0d8cf6c854ddea2e", "predicted_answer": "1. the system benefits from filters of each size., features of multigranular phrases are extracted with variable-size convolution filters.", "predicted_evidence": []}
{"question_id": "7975c3e1f61344e3da3b38bb12e1ac6dcb153a18", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "eddb18109495976123e10f9c6946a256a55074bd", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "ea6764a362bac95fb99969e9f8c773a61afd8f39", "predicted_answer": "1. 82.0%", "predicted_evidence": []}
{"question_id": "62c4c8b46982c3fcf5d7c78cd24113635e2d7010", "predicted_answer": "1. unanswerable", "predicted_evidence": []}
{"question_id": "e9cfe3f15735e2b0d5c59a54c9940ed1d00401a2", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "52ed2eb6f4d1f74ebdc4dcddcae201786d4c0463", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "2c576072e494ab5598667cd6b40bc97fdd7d92d7", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "8602160e98e4b2c9c702440da395df5261f55b1f", "predicted_answer": "the three datasets used in the paper are not explicitly listed in the provided options. however, based on the information given, i can make an educated guess that the three datasets might be related to the apda shared task.\n\nmy response would be:\n\n1 (assuming it refers to the 3 datasets mentioned)", "predicted_evidence": []}
{"question_id": "57fdb0f6cd91b64a000630ecb711550941283091", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "3aa43a0d543b88d40e4f3500c7471e263515be40", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "d82ec1003a3db7370994c7522590f7e5151b1f33", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "58f08d38bbcffb2dd9d660faa8026718d390d64b", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "89e1e0dc5d15a05f8740f471e1cb3ddd296b8942", "predicted_answer": "1. the punchline of the joke", "predicted_evidence": []}
{"question_id": "2815bac42db32d8f988b380fed997af31601f129", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "de03e8cc1ceaf2108383114460219bf46e00423c", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "8a276dfe748f07e810b3944f4f324eaf27e4a52c", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "0716b481b78d80b012bca17c897c62efbe7f3731", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "fed0785d24375ebbde51fb0503b93f14da1d8583", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "675d7c48541b6368df135f71f9fc13a398f0c8c6", "predicted_answer": "1. the transformer models", "predicted_evidence": []}
{"question_id": "868c69c8f623e30b96df5b5c8336070994469f60", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "f809fd0d3acfaccbe6c8abb4a9d951a83eec9a32", "predicted_answer": "1. labeled by experts", "predicted_evidence": []}
{"question_id": "c4a6b727769328333bb48d59d3fc4036a084875d", "predicted_answer": "1. human, fastqa, bidaf, coref-gru, mhpgm, weaver / jenga, mhqa-grn", "predicted_evidence": []}
{"question_id": "bbeb74731b9ac7f61e2d74a7d9ea74caa85e62ef", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "93e8ce62361b9f687d5200d2e26015723721a90f", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "d05d667822cb49cefd03c24a97721f1fe9dc0f4c", "predicted_answer": "1. assign a value to the relation based on whether mentions occur in the same document, if mentions are identical, or if mentions are in the same coreference chain.", "predicted_evidence": []}
{"question_id": "2a1e6a69e06da2328fc73016ee057378821e0754", "predicted_answer": "1. exact matches to the entity string and predictions from a coreference resolution system", "predicted_evidence": []}
{"question_id": "63403ffc0232ff041f3da8fa6c30827cfd6404b7", "predicted_answer": "1. accuracy", "predicted_evidence": []}
{"question_id": "a25c1883f0a99d2b6471fed48c5121baccbbae82", "predicted_answer": "1. during testing: 67.6 for single model without coreference, 66.4 for single model with coreference, 71.2 for ensemble of 5 models", "predicted_evidence": []}
{"question_id": "a88f8cae1f59cdc4f1f645e496d6d2ac4d9fba1b", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "bea60603d78baeeb6df1afb53ed08d8296b42f1e", "predicted_answer": "unfortunately, i don't have enough information to provide a specific answer. however, based on common practices in ai and machine learning, some popular baseline models that are often used include:\n\n* word2vec (for natural language processing tasks)\n* vgg16 (for computer vision tasks)\n* lstm (for sequence prediction tasks)\n\nplease note that the choice of baseline model depends heavily on the specific task or problem being addressed.\n\nif i had to choose from your options, i would say \"1. unanswerable\" since there isn't enough context provided to give a more specific answer.", "predicted_evidence": []}
{"question_id": "37db7ba2c155c2f89fc7fb51fffd7f193c103a34", "predicted_answer": "1. support vector machine (svm), logistic regression (log.reg), random forest (rf), gradient boosting (xgb)", "predicted_evidence": []}
{"question_id": "c2cbc2637761a2c2cf50f5f8caa248814277430e", "predicted_answer": "1. support vector machine (svm), logistic regression (log.reg), random forest (rf) and gradient boosting (xgb)", "predicted_evidence": []}
{"question_id": "774ead7c642f9a6c59cfbf6994c07ce9c6789a35", "predicted_answer": "i think there may be a misunderstanding! you provided only one option, but i'll do my best to help.\n\nsince i don't have more options to choose from, i'll take a guess that sarcasm is conveyed in different ways in various domains beyond just amazon reviews. some possible domains where sarcasm might be conveyed differently could include:\n\n* social media\n* literature (e.g., satire)\n* comedy and stand-up routines\n* everyday conversations (e.g., cultural or regional differences)\n\nplease provide more options or clarify the question, and i'll do my best to help!", "predicted_evidence": []}
{"question_id": "d86c7faf5a61d73a19397a4afa2d53206839b8ad", "predicted_answer": "1. language, vision, acoustic", "predicted_evidence": []}
{"question_id": "082bc58e1a2a65fc1afec4064a51e4c785674fd7", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "46563a1fb2c3e1b39a185e4cbb3ee1c80c8012b7", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "6b7d76c1e1a2490beb69609ba5652476dde8831b", "predicted_answer": "1.", "predicted_evidence": []}
{"question_id": "37753fbffc06ce7de6ada80c89f1bf5f190bbd88", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "7ee29d657ccb8eb9d5ec64d4afc3ca8b5f3bcc9f", "predicted_answer": "1. best performance achieved is 0.72 f1 score", "predicted_evidence": []}
{"question_id": "b42323d60827ecf0d9e478c9a31f90940cfae975", "predicted_answer": "1. contains thousands of xml files, each of which are constructed by several records", "predicted_evidence": []}
{"question_id": "1a69696034f70fb76cd7bb30494b2f5ab97e134d", "predicted_answer": "0.0072", "predicted_evidence": []}
{"question_id": "9a596bd3a1b504601d49c2bec92d1592d7635042", "predicted_answer": "1. answer with content missing: (table ii) proposed model has f1 score of  0.7220.", "predicted_evidence": []}
{"question_id": "1ba28338d3f993674a19d2ee2ec35447e361505b", "predicted_answer": "1. chowdhury bibref14 and thomas et al. bibref11, fbk-irst bibref10, liu et al. bibref9, sahu et al. bibref12", "predicted_evidence": []}
{"question_id": "8ec94313ea908b6462e1f5ee809a977a7b6bdf01", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "f052444f3b3bf61a3f226645278b780ebd7774db", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "79ed71a3505cf6f5e8bf121fd7ec1518cab55cae", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "74eb363ce30c44d318078cc1a46f8decf7db3ade", "predicted_answer": "1. unanswerable", "predicted_evidence": []}
{"question_id": "790ed4458a23aa23e2b5399259e50083c86d9e14", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "562a2feeba9580f5435a94396f2a8751f79a4d5c", "predicted_answer": "glove, twitter word2vec", "predicted_evidence": []}
{"question_id": "d4e78d3205e98cafdf93ddaa95627ea00b7c4d55", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "8b51db1f7a6293b5bd8be49386cce45989b8079f", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "f37128d3533dabb58aadf2e8f9aa30f5bda81cd9", "predicted_answer": "unfortunately, i don't have enough context to determine which organization or entity \"they\" refers to. however, based on common practices, i'll take a guess that the definition of hate speech used is likely similar to those found in international human rights law, such as the one provided by the international covenant on civil and political rights (iccpr) or the european court of human rights.\n\nthat being said, since there's only one option available, i'll choose:\n\n1. unanswerable", "predicted_evidence": []}
{"question_id": "0b9021cefca71081e617a362e7e3995c5f1d2a88", "predicted_answer": "1. cnn-c, cnn-w, cnn-lex-c, cnn-lex-w, bi-lstm-c , bi-lstm-w, lex-rule, bow", "predicted_evidence": []}
{"question_id": "6ad92aad46d2e52f4e7f3020723922255fd2b603", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "4fdc707fae5747fceae68199851e3c3186ab8307", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "2d307b43746be9cedf897adac06d524419b0720b", "predicted_answer": "1. travel dataset contains 4100 raw samples, 11291 clauses, hotel dataset contains 3825 raw samples, 11264 clauses, and the mobile dataset contains 3483 raw samples and 8118 clauses", "predicted_evidence": []}
{"question_id": "fe90eec1e3cdaa41d2da55864c86f6b6f042a56c", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "9d5df9022cc9eb04b9f5c5a9d8308a332ebdf50c", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "dbf606cb6fc1d070418cc25e38ae57bbbb7087a0", "predicted_answer": "1, 2, 3, and 4.", "predicted_evidence": []}
{"question_id": "9651fbd887439bf12590244c75e714f15f50f73d", "predicted_answer": "1. the advantage of pre-training gradually diminishes with the increase of labeled data, fixed representations yield better results than fine-tuning in some cases, pre-training the seq2seq encoder outperforms pre-training the decoder", "predicted_evidence": []}
{"question_id": "1fd969f53bc714d9b5e6604a7780cbd6b12fd616", "predicted_answer": "1. fine-tuning schedules that elaborately design the control of learning rates for optimization, proxy tasks that leverage labeled data to help the pre-trained model better fit the target data distribution, knowledge distillation approaches that ditch the paradigm of initialization with pre-trained parameters by adopting the pre-trained model as a teacher network", "predicted_evidence": []}
{"question_id": "cd37ad149d500e1c7d2de9de1f4bae8dcc443a72", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "14eb2b89ba39e56c52954058b6b799a49d1b74bf", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "83f24e4bbf9de82d560cdde64b91d6d672def6bf", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "6b8a3100895f2192e08973006474428319dc298e", "predicted_answer": "mncut spectral clustering algorithm", "predicted_evidence": []}
{"question_id": "daf624f7d1623ccd3facb1d93d4d9d616b3192f4", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "74261f410882551491657d76db1f0f2798ac680f", "predicted_answer": "french (fr), brazilian portuguese (pt), italian (it), polish (pl), croatian (hr), and finnish (fi).", "predicted_evidence": []}
{"question_id": "3d34a02ceebcc93ee79dc073c408651d25e538bc", "predicted_answer": "unfortunately, i don't have enough information about the paper in question. however, based on the options provided, my response would be:\n\n1. support vector machines (svm) classifier", "predicted_evidence": []}
{"question_id": "96992460cfc5f0b8d065ee427067147293746b7a", "predicted_answer": "1. f1, accuracy", "predicted_evidence": []}
{"question_id": "363ddc06db5720786ed440927d7fbb7d0a8078ae", "predicted_answer": "1. stylometric, lexical, grammatical, and semantic", "predicted_evidence": []}
{"question_id": "f12a282571f842b818d4bee86442751422b52337", "predicted_answer": "1. tf-idf-based features", "predicted_evidence": []}
{"question_id": "5b1cd21936aeec85233c978ba8d7282931522a3a", "predicted_answer": "i'm happy to help! however, i must point out that the provided option does not directly answer the question about the size of the dataset.\n\nbased on the given information, my best guess is:\n\nthere is no direct answer available in the provided options.", "predicted_evidence": []}
{"question_id": "964705a100e53a9181d1a5ac8150696de12ecaf0", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "f08a66665f01c91cb9dfe082e9d1015ecf3df71d", "predicted_answer": "i'm happy to help! however, i notice that there's only one option provided, and it doesn't seem to be a complete sentence. could you please rephrase the question or provide more options? i'll do my best to assist you.\n\nif not, based on the given information, i can only respond with:\n\n1. unanswerable", "predicted_evidence": []}
{"question_id": "c65b6470b7ed0a035548cc08e0bc541c2c4a95a7", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "6e2899c444baaeb0469599f65722780894f90f29", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "896e99d7f8f957f6217185ff787e94f84c136087", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "63c0128935446e26eacc7418edbd9f50cba74455", "predicted_answer": "1. 440 sentences, 2247 triples extracted from those sentences, and 11262 judgements on those triples.", "predicted_evidence": []}
{"question_id": "9a94dcee17cdb9a39d39977191e643adece58dfc", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "18e915b917c81056ceaaad5d6581781c0168dac9", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "9c68d6d5451395199ca08757157fbfea27f00f69", "predicted_answer": "1. openie4 and miniie", "predicted_evidence": []}
{"question_id": "372fbf2d120ca7a101f70d226057f9639bf1f9f2", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "f14ff780c28addab1d738f676c4ec0b4106356b6", "predicted_answer": "1. meta vertex candidate identification. edit distance and word lengths distance are used to determine whether two words should be merged into a meta vertex (only if length distance threshold is met, the more expensive edit distance is computed). the meta vertex creation. as common identifiers, we use the stemmed version of the original vertices and if there is more than one resulting stem, we select the vertex from the identified candidates that has the highest centrality value in the graph and its stemmed version is introduced as a novel vertex (meta vertex).", "predicted_evidence": []}
{"question_id": "b799936d6580c0e95102027175d3fe184f0ee253", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "568ce2f5355d009ec9bc1471fb5ea74655f7e554", "predicted_answer": "unfortunately, i don't have enough information about the proposed method to determine its interpretability. therefore, my response is:\n\n1. unanswerable", "predicted_evidence": []}
{"question_id": "c000a43aff3cb0ad1cee5379f9388531b5521e9a", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "a5b67470a1c4779877f0d8b7724879bbb0a3b313", "predicted_answer": "1. micro-averaged f1", "predicted_evidence": []}
{"question_id": "12cfbaace49f9363fcc10989cf92a50dfe0a55ea", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "4640793d82aa7db30ad7b88c0bf0a1030e636558", "predicted_answer": "1. chiu and nichols (2016), lample et al. (2016), ma and hovy (2016), yang et al. (2017), hashimoto et al. (2016), s\u00f8gaard and goldberg (2016)", "predicted_evidence": []}
{"question_id": "a9c5252173d3df1c06c770c180a77520de68531b", "predicted_answer": "conll 2003, conll 2000", "predicted_evidence": []}
{"question_id": "a45edc04277a458911086752af4f17405501230f", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "8c8a32592184c88f61fac1eef12c7d233dbec9dc", "predicted_answer": "1.", "predicted_evidence": []}
{"question_id": "16646ee77975fed372b76ce639e2664ae2105dcf", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "9c0cf1630804366f7a79a40934e7495ad9f32346", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "a4d8fdcaa8adf99bdd1d7224f1a85c610659a9d3", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "9ac923be6ada1ba2aa20ad62b0a3e593bb94e085", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "3b995a7358cefb271b986e8fc6efe807f25d60dc", "predicted_answer": "1. glove; sgns", "predicted_evidence": []}
{"question_id": "2210178facc0e7b3b6341eec665f3c098abef5ac", "predicted_answer": "gru", "predicted_evidence": []}
{"question_id": "7cf726db952c12b1534cd6c29d8e7dfa78215f9e", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "f9751e0ca03f49663a5fc82b33527bc8be1ed0aa", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "ce18c50dadab7b9f28141fe615fd7de69355d9dd", "predicted_answer": "1. rdf was designed as an abstract information model and fhir was designed for operational use in a healthcare setting, rdf makes statements of fact, whereas fhir makes records of events, rdf is intended to have the property of monotonicity, meaning that previous facts cannot be invalidated by new facts", "predicted_evidence": []}
{"question_id": "5a230fe4f0204bf2eebc0e944cf8defaf33d165c", "predicted_answer": "1. one of the several formats into which fhir can be serialized is rdf, there is the potential for a slight mismatch between the models", "predicted_evidence": []}
{"question_id": "d3bb06d730efbedd30ec226fe8cf828a4773bf5c", "predicted_answer": "1. health level seven fast healthcare interoperability resources (hl7 fhir), resource description framework (rdf)", "predicted_evidence": []}
{"question_id": "2255c36c8c7ed6084da577b480eb01d349f52943", "predicted_answer": "1.", "predicted_evidence": []}
{"question_id": "9e391c8325b48f6119ca4f3d428b1b2b037f5c13", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "5bcc12680cf2eda2dd13ab763c42314a26f2d993", "predicted_answer": "1. for sentence-level prediction they used tolerance accuracy, for segment retrieval accuracy and mrr and for the pipeline approach they used overall accuracy", "predicted_evidence": []}
{"question_id": "7a53668cf2da4557735aec0ecf5f29868584ebcf", "predicted_answer": "1. tutorial videos for a photo-editing software", "predicted_evidence": []}
{"question_id": "8051927f914d730dfc61b2dc7a8580707b462e56", "predicted_answer": "1. a sentence-level prediction algorithm, a segment retrieval algorithm and a pipeline segment retrieval algorithm", "predicted_evidence": []}
{"question_id": "09621c9cd762e1409f22d501513858d67dcd3c7c", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "10ddac87daf153cf674589cc1c64a795907d5d9a", "predicted_answer": "1. significantly improves the accuracy and f1 score of aspect polarity classification", "predicted_evidence": []}
{"question_id": "6cd874c4ae8e70f3c98c7176191c13a7decfbc45", "predicted_answer": "none of the above options. the state-of-the-art on semeval-2014 task 4 restaurant and laptop dataset at that time was around 80% accuracy achieved by several systems including iit-t's system, ynu-hpcc's system, and nlp-iit's system.", "predicted_evidence": []}
{"question_id": "b807dd3d42251615b881632caa5e331e2203d269", "predicted_answer": "gann", "predicted_evidence": []}
{"question_id": "d39c911bf2479fdb7af339b59acb32073242fab3", "predicted_answer": "car, phone, notebook, camera", "predicted_evidence": []}
{"question_id": "f53be1266be1fea5598a671080226c9c983b69e3", "predicted_answer": "unfortunately, i don't have enough information to provide a specific answer. however, based on my understanding of the context, i'll take a guess.\n\nsince there's only one option available, i'll choose:\n\n1. unanswerable", "predicted_evidence": []}
{"question_id": "3be8859103016ce2afe4c0a8552b9d980f7958bf", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "e9f868f22ae70c7681c28228b6019e155013f8d6", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "7aaaf7bff9947c6d3b954ae25be87e6e1c49db6d", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "4a2248e1c71c0b0183ab0d225440cae2da396b8d", "predicted_answer": "1. evaluation dataset of japanese lexical simplification kodaira", "predicted_evidence": []}
{"question_id": "1244cf6d75e3aa6d605a0f4b141c015923a3f2e7", "predicted_answer": "4", "predicted_evidence": []}
{"question_id": "c8b9b962e4d40c50150b2f8873a4004f25398464", "predicted_answer": "1.", "predicted_evidence": []}
{"question_id": "616c205142c7f37b3f4e81c0d1c52c79f926bcdc", "predicted_answer": "sumbt bibref17", "predicted_evidence": []}
{"question_id": "496e81769a8d9992dae187ed60639ff2eec531f3", "predicted_answer": "english and chinese", "predicted_evidence": []}
{"question_id": "f103789b85b00ec973076652c639bd31c605381e", "predicted_answer": "1. senseval-2 (se2), senseval-3 (se3), semeval 2013 task 12 (se13), and semeval 2015 task 13 (se15), ontonotes release 5.0", "predicted_evidence": []}
{"question_id": "9c4a4dfa7b0b977173e76e2d2f08fa984af86f0e", "predicted_answer": "i don't have enough information to answer this question accurately. however, i can try to make an educated guess.\n\nunfortunately, my guess would be that tp-n2f is likely faster than lstm-based seq2seq in terms of training and inference speed, but i couldn't find any specific numbers or comparisons to support this claim.\n\nif you could provide more context or information about tp-n2f and lstm-based seq2seq, i may be able to give a more accurate answer.", "predicted_evidence": []}
{"question_id": "4c7ac51a66c15593082e248451e8f6896e476ffb", "predicted_answer": "full testing set accuracy: 84.02 \ncleaned testing set accuracy: 93.48", "predicted_evidence": []}
{"question_id": "05671d068679be259493df638d27c106e7dd36d0", "predicted_answer": "operation accuracy: 71.89\nexecution accuracy: 55.95", "predicted_evidence": []}
{"question_id": "a3a871ca2417b2ada9df1438d282c45e4b4ad668", "predicted_answer": "table tabref20", "predicted_evidence": []}
{"question_id": "0fcac64544842dd06d14151df8c72fc6de5d695c", "predicted_answer": "hierarchical blstm-crf", "predicted_evidence": []}
{"question_id": "4e841138f307839fd2c212e9f02489e27a5f830c", "predicted_answer": "1. da recognition is aimed to assign a label to each utterance in a conversation. it can be formulated as a supervised classification problem.", "predicted_evidence": []}
{"question_id": "37103369e5792ece49a71666489016c4cea94cda", "predicted_answer": "i don't have enough information to determine which natural language(s) are studied. however, i can suggest that many languages are studied in various fields such as linguistics, anthropology, and language education.\n\nsince there is only one option available, i will choose:\n\n1. unanswerable", "predicted_evidence": []}
{"question_id": "479d334b79c1eae3f2aa3701d28aa0d8dd46036a", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "b02d2d351bd2e49d4d59db0a8a6ef23cb90bfbc4", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "a035472a5c6cf238bed62b63d28100c546d40bd5", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "3213529b6405339dfd0c1d2a0f15719cdff0fa93", "predicted_answer": "1. the baseline models used are drqa modified to support answering no answer questions, drqa+coqa which is pre-tuned on coqa dataset, vanilla bert, bert+review tuned on domain reviews, bert+coqa tuned on the supervised coqa data", "predicted_evidence": []}
{"question_id": "70afd28b0ecc02eb8e404e7ff9f89879bf71a670", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "42c02c554ab4ceaf30a8ca770be4f271887554c2", "predicted_answer": "1. non-english code is a large-scale phenomena., transliteration is common in identifiers for all languages., languages clusters into three distinct groups based on how speakers use identifiers/comments/transliteration., non-latin script users write comments in their l1 script but write identifiers in english., right-to-left (rtl) language scripts, such as arabic, have no observed prevalence on github identifiers", "predicted_evidence": []}
{"question_id": "5f0bb32d70ee8e4c4c59dc5c193bc0735fd751cc", "predicted_answer": "1. dialogue simulator", "predicted_evidence": []}
{"question_id": "a88a454ac1a1230263166fd824e5daebb91cb05a", "predicted_answer": "1. back translation between english and chinese", "predicted_evidence": []}
{"question_id": "bbaf7cbae88c085faa6bbe3319e4943362fe1ad4", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "a6b99b7f32fb79a7db996fef76e9d83def05c64b", "predicted_answer": "1. active intent accuracy, requested slot f1, average goal accuracy, joint goal accuracy", "predicted_evidence": []}
{"question_id": "d47c074012eae27426cd700f841fd8bf490dcc7b", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "b43fa27270eeba3e80ff2a03754628b5459875d6", "predicted_answer": "1. alarm, banks, buses, calendar, events, flights, homes, hotels, media, messaging, movies, music, payment, rental cars, restaurants, ride sharing, services, train, travel, weather", "predicted_evidence": []}
{"question_id": "458dbf217218fcab9153e33045aac08a2c8a38c6", "predicted_answer": "1. total number of annotated data:\nsemeval'15: 10712\nsemeval'16: 28632\ntass'15: 69000\nsentipol'14: 6428", "predicted_evidence": []}
{"question_id": "cebf3e07057339047326cb2f8863ee633a62f49f", "predicted_answer": "arabic, german, portuguese, russian, swedish", "predicted_evidence": []}
{"question_id": "ef8099e2bc0ac4abc4f8216740e80f2fa22f41f6", "predicted_answer": "1. spanish, english, italian, arabic, german, portuguese, russian and swedish", "predicted_evidence": []}
{"question_id": "1e68a1232ab09b6bff506e442acc8ad742972102", "predicted_answer": "1.", "predicted_evidence": []}
{"question_id": "0bd992a6a218331aa771d922e3c7bb60b653949a", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "052d19b456f1795acbb8463312251869cc5b38da", "predicted_answer": "unfortunately, i don't have enough information to provide a specific answer. however, based on general knowledge, some common metrics used to evaluate results include:\n\n* key performance indicators (kpis)\n* return on investment (roi)\n* customer satisfaction\n* net promoter score (nps)\n* conversion rate\n* time-to-market\n\nsince i don't have more context about the specific question, my best guess is that none of these options are listed. therefore, i will choose:\n\n1. unanswerable", "predicted_evidence": []}
{"question_id": "7b89515d731d04dd5cbfe9c2ace2eb905c119cbc", "predicted_answer": "1. the three baseline models are the i-vector model, a standard rnn lid system and a multi-task rnn lid system.", "predicted_evidence": []}
{"question_id": "1db37e98768f09633dfbc78616992c9575f6dba4", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "79a28839fee776d2fed01e4ac39f6fedd6c6a143", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "da2b43d7d048f3f59adf26a67ce66bd2d8a06326", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "b7708cbb50085eb41e306bd2248f1515a5ebada8", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "17988d65e46ff7d756076e9191890aec177b081e", "predicted_answer": "1. no", "predicted_evidence": []}
{"question_id": "11c77ee117cb4de825016b6ccff59ff021f84a38", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "0b92fb692feb35d4b4bf4665f7754d283d6ad5f3", "predicted_answer": "1. results that for the in-domain training case, our models bert-ada lapt and bert-ada rest achieve performance close to state-of-the-art on the laptops dataset, new state-of-the-art on the restaurants dataset with accuracies of $79.19\\%$ and $87.14\\%$, respectively.", "predicted_evidence": []}
{"question_id": "521a7042b6308e721a7c8046be5084bc5e8ca246", "predicted_answer": "1. graph-like structures where arcs connect nodes representing multiple hypothesized words, thus allowing multiple incoming arcs unlike 1-best sequences", "predicted_evidence": []}
{"question_id": "06776b8dfd1fe27b5376ae44436b367a71ff9912", "predicted_answer": "mandarin dataset", "predicted_evidence": []}
{"question_id": "f1831b2e96ff8ef65b8fde8b4c2ee3e04b7ac4bf", "predicted_answer": "1. nmi between cluster assignments and ground truth tones for all sylables is:\nmandarin: 0.641\ncantonese: 0.464", "predicted_evidence": []}
{"question_id": "20ec88c45c1d633adfd7bff7bbf3336d01fb6f37", "predicted_answer": "1. precision, recall, f1", "predicted_evidence": []}
{"question_id": "a4fe5d182ddee24e5bbf222d6d6996b3925060c8", "predicted_answer": "conll 2003, germeval 2014, conll 2002, egunkaria, muc7, wikigold, meantime, sonar-1, ancora 2.0", "predicted_evidence": []}
{"question_id": "f463db61de40ae86cf5ddd445783bb34f5f8ab67", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "3d7ab856a5cade7ab374fc2f2713a4d0a30bbd56", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "212977344f4bf2ae8f060bdac0317db2d1801724", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "0c29d08f766b06ceb2421aa402e71a2d65a5a381", "predicted_answer": "1. convolutional neural network (cnn)", "predicted_evidence": []}
{"question_id": "c9ee70c481c801892556eb6b9fd8ee38197923be", "predicted_answer": "1. language-independent (e.g., punctuation marks, positive and negative emoticons, quotations, personal pronouns, tweet's length, named entities),  language-dependent relying on dedicated lexicons (e.g., negation, opinion lexicons, opposition words)", "predicted_evidence": []}
{"question_id": "a24a7a460fd5e60d71a7e787401c68caa4702df6", "predicted_answer": "1. aravec for arabic, fasttext for french, and word2vec google news for english.", "predicted_evidence": []}
{"question_id": "e8d1792fc56a32bd4c95f61c2ea4cf29088edd7c", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "ceda2a4872132b8e0a526c0f2c701d0df060c3af", "predicted_answer": "lstm", "predicted_evidence": []}
{"question_id": "5758ebff49807a51d080b0ce10ba3f86dcf71925", "predicted_answer": "1. low-rank approximation of the co-occurrence matrix", "predicted_evidence": []}
{"question_id": "e84ba95c9a188fda4563f45e53fbc8728d8b5dab", "predicted_answer": "one model per topic.", "predicted_evidence": []}
{"question_id": "caf9819be516d2c5a7bfafc80882b07517752dfa", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "b1e90a546dc92e96b657fff5dad8e89f4ac6ed5e", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "f8d32088d17b32b0c877d59965b35c4f51f0ceea", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "4f0f446bf4518af7f539f6283145135192d5c00b", "predicted_answer": "1. logistic regression (lr), random forest (rf), support vector machines (svm)", "predicted_evidence": []}
{"question_id": "663b36f99ad2422f4d3a8c6398ebf55ceab7770d", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "be595b2017545b0359db6abf4914a155bdd10d23", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "79b174d20ea5dd4f35e25c9425fb97f40e27cd6f", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "21a96b328b43a568f9ba74cbc6d4689dbc4a3d7b", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "30803eefd7cdeb721f47c9ca72a5b1d750b8e03b", "predicted_answer": "1. eer 16.04, cmindet 0.6012, cdet 0.6107", "predicted_evidence": []}
{"question_id": "442f8da2c988530e62e4d1d52c6ec913e3ec5bf1", "predicted_answer": "cebuano and mandarin, tagalog and cantonese", "predicted_evidence": []}
{"question_id": "ae60079da9d3d039965368acbb23c6283bc3da94", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "83f567489da49966af3dc5df2d9d20232bb8cb1e", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "ff0f77392abc905fe76e0b8c28a76dfb0372a0ec", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "6c4cd8da5b4b298f29af3123b58d9a5d4b02180b", "predicted_answer": "1. unanswerable", "predicted_evidence": []}
{"question_id": "ed4fb6bce855ca932548689e45fde21f26a71035", "predicted_answer": "coattention is a deep learning technique used in natural language processing and computer vision tasks, particularly for visual question answering (vqa) and image captioning. it allows the model to jointly attend to both the input text and the input image, enabling it to better understand the context and relationships between them.\n\nsince there's only one option provided which is \"unanswerable\", i'll choose that as the best answer isn't available in the options list.", "predicted_evidence": []}
{"question_id": "4cc5ba404d6a47363f119d9db7266157d3bb246b", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "1d72770d075b22411ec86d8bdee532f8c643740b", "predicted_answer": "1. 3.1 f1 gain on the original dev set, 11 f1 gain on the multi-hop dev set, 10 f1 gain on the out-of-domain dev set.", "predicted_evidence": []}
{"question_id": "af1439c68b28c27848203f863675946380d28943", "predicted_answer": "1. roberta baseline", "predicted_evidence": []}
{"question_id": "046ff04d1018447b22e00acb125125cae5a23fb7", "predicted_answer": "small_parallel_enja", "predicted_evidence": []}
{"question_id": "5a06f11aa75a8affde3d595c40fb03e06769e368", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "ffbd6f583692db66b719a846ba2b7f6474df481a", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "74fe054f5243c8593ddd2c0628f91657246b7dfa", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "cc2b98b46497c71e955e844fb36e9ef6e2784640", "predicted_answer": "bleu, ribes, and token-level delay", "predicted_evidence": []}
{"question_id": "6959e87cf2668a03854da3f042c87e6fdb2ade8a", "predicted_answer": "unfortunately, i don't have specific information on the size of figureqa and dvqa datasets. therefore, my response is:\n\n1. unanswerable", "predicted_evidence": []}
{"question_id": "a7f07ae48eed084c3144214228f4ecb72bc0a0e3", "predicted_answer": "img-only, ques-only, san, sandy, voes-oracle, voes", "predicted_evidence": []}
{"question_id": "eced6a6dffe43c28e6d06ab87eed98c135f285a3", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "7fdeef2b1c8f6bd5d7c3a44e533d8aae2bbc155f", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "be074c880263f56e0d4a8f42d9a95d2d77ac2280", "predicted_answer": "1. landing pages of urls", "predicted_evidence": []}
{"question_id": "2a57fdc7e985311989b6829c1ceb201096e5c809", "predicted_answer": "1. parts of speech (pos) tags, prior polarity of the words, capitalization, negation, text feature", "predicted_evidence": []}
{"question_id": "53807f435d33fe5ce65f5e7bda7f77712194f6ab", "predicted_answer": "1.  only 1 in 9 qualitative papers in human-computer interaction reported inter-rater reliability metrics, low-effort responses from crowdworkers", "predicted_evidence": []}
{"question_id": "2ec9c1590c96f17a66c7d4eb95dc5d3a447cb973", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "208e667982160cfbce49ef49ad96f6ab094292ac", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "35eb8464e934a2769debe14148667c61bf1da243", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "5774e019101415a43e0b5a780179fd897fc013fd", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "fc33a09401d12f4fe2338b391301380d34a60e5f", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "1b046ec7f0e1a33e77078bedef7e83c5c07b61de", "predicted_answer": "1. from january 1, 2020 until april 15, 2020", "predicted_evidence": []}
{"question_id": "55fb92afa118450f09329764efe22612676c2d85", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "19cdce39e8265e7806212eeee2fd55f8ef2f3d47", "predicted_answer": "1. more than 3,934,610 million tweets", "predicted_evidence": []}
{"question_id": "524abe0ab77db168d5b2f0b68dba0982ac5c1d8e", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "858c51842fc3c1f3e6d2d7d853c94f6de27afade", "predicted_answer": "unfortunately, i don't have enough information to determine which classifier showed the best performance. the options only list one choice: logistic regression. can you please provide more context or additional options?", "predicted_evidence": []}
{"question_id": "7c9c73508da628d58aaadb258f3a9d4cc2a8a9b3", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "7b2bf0c1a24a2aa01d49f3c7e1bdc7401162c116", "predicted_answer": "1. by using a bayesian approach  and by using word-pairs, where they extract all the pairs of co-occurring words within each tweet.  they search for the words that achieve the highest number of spikes matching the days of events.", "predicted_evidence": []}
{"question_id": "e09e89b3945b756609278dcffb5f89d8a52a02cd", "predicted_answer": "5575 speeches", "predicted_evidence": []}
{"question_id": "0cf5132ac7904b7b81e17938d5815f70926a5180", "predicted_answer": "1. fasttext and svm bibref16", "predicted_evidence": []}
{"question_id": "1d860d7f615b9ca404c504f9df4231a702f840ef", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "ed7985e733066cd067b399c36a3f5b09e532c844", "predicted_answer": "1. they use a left-to-right attention mask so that the input tokens can only attend to other input tokens, and the target tokens can only attend to the input tokens and already generated target tokens.", "predicted_evidence": []}
{"question_id": "cd8de03eac49fd79b9d4c07b1b41a165197e1adb", "predicted_answer": "1.", "predicted_evidence": []}
{"question_id": "63850ac98a47ae49f0f49c1c1a6e45c6c447272c", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "313087c69caeab2f58e7abd62664d3bd93618e4e", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "8ec2ca6c7f60c46eedac1fe0530b5c4448800fec", "predicted_answer": "none of the above options are correct. the correct answer is not provided in the options list.\n\nhowever, i can tell you that a facet is actually a flat surface on a geometric shape, often referring to a cut gemstone, such as a diamond.", "predicted_evidence": []}
{"question_id": "cfbccb51f0f8f8f125b40168ed66384e2a09762b", "predicted_answer": "1. they perform t-sne clustering to analyze discourse embeddings", "predicted_evidence": []}
{"question_id": "feb4e92ff1609f3a5e22588da66532ff689f3bcc", "predicted_answer": "1. character bigram cnn classifier", "predicted_evidence": []}
{"question_id": "f10325d022e3f95223f79ab00f8b42e3bb7ca040", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "5e65bb0481f3f5826291c7cc3e30436ab4314c61", "predicted_answer": "1. entity grid with grammatical relations and rst discourse relations.", "predicted_evidence": []}
{"question_id": "848ab388703c24faad79d83d254e4fd88ab27e2a", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "68794289ed6078b49760dc5fdf88618290e94993", "predicted_answer": "1. a sequence of logical statements represented in a computational graph", "predicted_evidence": []}
{"question_id": "62048ea0aab61abe21fb30d70c4a1bc5fb946137", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "25e4dbc7e211a1ebe02ee8dff675b846fb18fdc5", "predicted_answer": "1. raw data from gigaword, automatically segmented text from gigaword, heterogenous training data from people's daily, pos data from people's daily", "predicted_evidence": []}
{"question_id": "9893c5f36f9d503678749cb0466eeaa0cfc9413f", "predicted_answer": "five-character window context", "predicted_evidence": []}
{"question_id": "5d85d7d4d013293b4405beb4b53fa79ac7c03401", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "6dc9960f046ec6bd280a721724458f66d5a9a585", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "75b69eef4a38ec16df63d60be9708a3c44a79c56", "predicted_answer": "for story generation at sample level, the proposed metric is 2.61 times better (0.387/0.148). at model level, it's 2.09 times better (0.631/0.302).\n\nfor dialogue at sample level, the proposed metric is 1.38 times better (0.472/0.341). at model level, it's 1.42 times better (0.783/0.553).", "predicted_evidence": []}
{"question_id": "7488855f09b97eb6a027212fb7ace1d338f36a2b", "predicted_answer": "1. no", "predicted_evidence": []}
{"question_id": "1083ec9a2a33f7fe2b6b51bbcebd2d9aec4b4de2", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "58a00ca123d67b9be55021493384c0acef4c568d", "predicted_answer": "1. learn to ask unanswerable questions by editing answerable ones with word exchanges, negations, etc", "predicted_evidence": []}
{"question_id": "199bdb3a6b1f7c89d95ea6c6ddbbb5eff484fa1f", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "5ea87432b9166d6a4ab8806599cd2b1f9178622f", "predicted_answer": "1.", "predicted_evidence": []}
{"question_id": "3af9156b95a4c2d67cc54b80b92cc7b918fea2a9", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "7e328cc3cffa521e73f111d6796aaa9661c8eb07", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "80f19be1cbe1f0ec89bbafb9c5f7a8ded37881fb", "predicted_answer": "1. cbow and skip-gram methods in the fasttext tool bibref9", "predicted_evidence": []}
{"question_id": "b3238158392684a5a6b62a7eabaa2a10fbecf3e6", "predicted_answer": "the kgr10 corpus was created by crawling the most relevant content of the website, including all subsites.", "predicted_evidence": []}
{"question_id": "526ae24fa861d52536b66bcc2d2ddfce483511d6", "predicted_answer": "1. relative wer improvement of 10%.", "predicted_evidence": []}
{"question_id": "8a5254ca726a2914214a4c0b6b42811a007ecfc6", "predicted_answer": "1. transcribed data is available for duration of 38h 54m 38s for 8 speakers.", "predicted_evidence": []}
{"question_id": "3c0d66f9e55a89d13187da7b7128666df9a742ce", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "13d92cbc2c77134626e26166c64ca5c00aec0bf5", "predicted_answer": "1. hotspotqa: yang, ding, muppet \nfever: hanselowski, yoneda, nie", "predicted_evidence": []}
{"question_id": "9df4a7bd0abb99ae81f0ebb29c488f1caa0f268f", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "b7291845ccf08313e09195befd3c8030f28f6a9e", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "ac54a9c30c968e5225978a37032158a6ffd4ddb8", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "b236b9827253037b2fd7884d7bfec74619d96293", "predicted_answer": "1. significant map performance improvement compared to the previous best model, compclip-lm (0.696 to 0.734 absolute)", "predicted_evidence": []}
{"question_id": "b53efdbb9e53a65cd3828a3eb485c70f782a06e5", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "4d5e2a83b517e9c082421f11a68a604269642f29", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "2c3b2c3bab6d18cb0895462e3cfd91cd0dee7f7d", "predicted_answer": "bidaf, bert", "predicted_evidence": []}
{"question_id": "ea51aecd64bd95d42d28ab3f1b60eecadf6d3760", "predicted_answer": "books, dvds, electronics, kitchen appliances", "predicted_evidence": []}
{"question_id": "e4cc2e73c90e568791737c97d77acef83588185f", "predicted_answer": "1. 8000", "predicted_evidence": []}
{"question_id": "cc28919313f897358ef864948c65318dc61cb03c", "predicted_answer": "1. string kernels, sst, ke-meta, sfa, coral, tr-tradaboost, transductive string kernels, transductive kernel classifier", "predicted_evidence": []}
{"question_id": "b3857a590fd667ecc282f66d771e5b2773ce9632", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "b653f55d1dad5cd262a99502f63bf44c58ccc8cf", "predicted_answer": "1. fisher corpus english part 1", "predicted_evidence": []}
{"question_id": "22c802872b556996dd7d09eb1e15989d003f30c0", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "a7510ec34eaec2c7ac2869962b69cc41031221e5", "predicted_answer": "1. 52.0%", "predicted_evidence": []}
{"question_id": "869aaf397c9b4da7ab52d6dd0961887ae08da9ae", "predicted_answer": "bengali, english, german, spanish, dutch, amharic, arabic, hindi, somali", "predicted_evidence": []}
{"question_id": "871c34219eb623bde9ac3937aa0f28fc3ad69445", "predicted_answer": "for character error rate: character unit the rnn-transducer \nfor word error rate: classic rnn-transducer", "predicted_evidence": []}
{"question_id": "285858416b1583aa3d8ba0494fd01c0d4332659f", "predicted_answer": "1) investigate errors produced by the end-to-end methods and explore several approaches to correct common errors done in french, 2) compare the end-to-end methods in a slu context and evaluate the semantic value of the partially correct produced words", "predicted_evidence": []}
{"question_id": "150af1f5f4ce0ec94a7114397cffc59c4798441e", "predicted_answer": "unfortunately, i don't have enough information to provide a specific answer from the options given, as there is only one option and it's \"unanswerable\". however, i can try to provide an alternative answer.\n\nin general, acoustic units such as phonemes, syllables, and diphones are often used to model languages. for french specifically, some research suggests that using a combination of phonemes and syllables may be effective for modeling the language.\n\nif i had to choose from a hypothetical list of options, i might say:\n\n* phonemes\n* syllables\n* diphones\n\nplease note that this is just an educated guess, and the best answer would depend on the specific context and requirements of the model.", "predicted_evidence": []}
{"question_id": "acc512c57aef4d5a15c15e3593f0a9b3e7e7e8b8", "predicted_answer": "1, 2, and 3", "predicted_evidence": []}
{"question_id": "e75f5bd7cc7107f10412d61e3202a74b082b0934", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "58819fd80c9fbe8674f147bd84a45a25f674a093", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "694dd76a37ad9e8083c546e9bd083c5c3b65695c", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "dd3240045f662d9e2f4067ad5399a9cbfe25cc32", "predicted_answer": "1. unanswerable", "predicted_evidence": []}
{"question_id": "2223d8f417c532bd845d5ade792e955486b536a3", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "675f28958c76623b09baa8ee3c040ff0cf277a5a", "predicted_answer": "1. 300,000 sentences with 1.5 million single-quiz questions", "predicted_evidence": []}
{"question_id": "47b00652ac66039aafe886780e86961bfc5b466e", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "79443bf3123170da44396b0481364552186abb91", "predicted_answer": "sequence classification, sequence labeling", "predicted_evidence": []}
{"question_id": "2a46db1b91de4b583d4a5302b2784c091f9478cc", "predicted_answer": "1. around 388k examples, 194k from tst2013 (in-domain) and 194k from newstest2014 (out-of-domain)", "predicted_evidence": []}
{"question_id": "48fa2ccc236e217fcf0e5aab0e7a146faf439b02", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "2b52d481b30185d2c6e7b403d37277f70337d6ca", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "0fa81adf00662694e1dc74475ae2b9283c50748c", "predicted_answer": "1. parameter sharing", "predicted_evidence": []}
{"question_id": "4ade72bfa28bd1f6b75cc7fa687fa634717782f2", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "fb381a59732474dc71a413e25cac37e239547b55", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "a9b10e3db5902c6142e7d6a83253ad2a6cee77fc", "predicted_answer": "unfortunately, i don't have enough information about \"their proposed word embeddings\" to provide a specific answer. however, based on general knowledge of word embeddings, here is my response:\n\n1. unanswerable", "predicted_evidence": []}
{"question_id": "54415efa91566d5d7135fa23bce3840d41a6389e", "predicted_answer": "1. 300-dimensional vectors", "predicted_evidence": []}
{"question_id": "dcd22abfc9e7211925c0393adc30dbd4711a9f88", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "05238d1fad2128403577822aa4822ef8ca9570ac", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "6ee27ab55b1f64783a9e72e3f83b7c9ec5cc8073", "predicted_answer": "1. the cmu arctic database bibref33,  the m-ailabs speech dataset bibref34", "predicted_evidence": []}
{"question_id": "bb4de896c0fa4bf3c8c43137255a4895f52abeef", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "d9eacd965bbdc468da522e5e6fe7491adc34b93b", "predicted_answer": "1. support vector machines (svm), gaussian naive bayes, multinomial naive bayes, decision trees, random forests and a maximum entropy classifier", "predicted_evidence": []}
{"question_id": "ebae0cd1fe0e7ba877d4b3055190e8b1dfcaeb53", "predicted_answer": "1. user location (uloc), 2. user language (ulang), 3. timezone (tz), 4. tweet language (tlang), 5. offset (offset), 6. user name (name), 7. user description (description), 8. tweet content (content)", "predicted_evidence": []}
{"question_id": "8e630c5a4a8ba0a4f5d8c483a2bf09c4ac8020ce", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "0b24b5a652d674d4694668d889643bc1accf18ef", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "1fb73176394ef59adfaa8fc7827395525f9a5af7", "predicted_answer": "1. amazonqa and conciergeqa datasets", "predicted_evidence": []}
{"question_id": "3a3a65c65cebc2b8c267c334e154517d208adc7d", "predicted_answer": "1. multi-encoder, constrained-decoder model", "predicted_evidence": []}
{"question_id": "d70ba6053e245ee4179c26a5dabcad37561c6af0", "predicted_answer": "1. conciergeqa and amazonqa", "predicted_evidence": []}
{"question_id": "802687121a98ba4d7df1f8040ea0dc1cc9565b69", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "f1bd66bb354e3dabf5dc4a71e6f08b17d472ecc9", "predicted_answer": "1.", "predicted_evidence": []}
{"question_id": "25fd61bb20f71051fe2bd866d221f87367e81027", "predicted_answer": "1. ndm, lidm, kvrn, and tscp/rl", "predicted_evidence": []}
{"question_id": "a1c5b95e407127c6bb2f9a19b7d9b1f1bcd4a7a5", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "5b99f74bb25bc88677621443bf065d96d84895ab", "predicted_answer": "none of the above options are correct. the correct answer is not provided in the options list.\n\nhowever, i can tell you that hard parameter sharing is a technique used in multi-task learning where the same set of model parameters (weights) are shared across multiple tasks, with some task-specific layers or adapters added on top.", "predicted_evidence": []}
{"question_id": "70e596dd4334a94844454fa7b565889556e2358d", "predicted_answer": "1. 180221 of 231162 author names could be matched successfully", "predicted_evidence": []}
{"question_id": "18dab362ae4587408a291a55299f347f8870e9f1", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "9c2de35d07f0d536bfdefe4828d66dd450de2b61", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "8d793bda51a53a4605c1c33e7fd20ba35581a518", "predicted_answer": "1. confusion in recognizing the words that are active at a given node by a speech recognition solution developed for indian railway inquiry system.", "predicted_evidence": []}
{"question_id": "8f838ec579f2609b01227da3d8c77860ac1b39d2", "predicted_answer": "grounded language understanding refers to a subfield of natural language processing (nlp) that focuses on developing ai models capable of understanding and generating human-like language by grounding their representations in real-world experiences, sensory information, or concrete objects.", "predicted_evidence": []}
{"question_id": "1835f65694698a9153857e33cd9b86a96772fff5", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "a61732774faf30bab15bf944b2360ec4710870c1", "predicted_answer": "unfortunately, i don't have enough information to provide a specific answer. however, based on my training data, i can suggest that the correct answer is likely not among the options provided.\n\nsince there's only one option available, which is \"unanswerable\", i'll go with that:\n\n1. unanswerable", "predicted_evidence": []}
{"question_id": "994ac7aa662d16ea64b86510fcf9efa13d17b478", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "9282cf80265a914a13053ab23b77d1a8ed71db1b", "predicted_answer": "1. english, russian", "predicted_evidence": []}
{"question_id": "41bff17f7d7e899c03b051e20ef01f0ebc5c8bb1", "predicted_answer": "1. rouge and meteor", "predicted_evidence": []}
{"question_id": "b03e8e9a0cd2a44a215082773c7338f2f3be412a", "predicted_answer": "1. a two layer recurrent neural language model with gru cells of hidden size 512, a two layer neural sequence to sequence model equipped with bi-linear attention function with gru cells of hidden size 512, a linear dynamical system, semi-supervised slds models with varying amount of labelled sentiment tags", "predicted_evidence": []}
{"question_id": "f608fbc7a4a10a79698f340e2948c4c7034642d5", "predicted_answer": "1. bi-directional lstm, self-attention", "predicted_evidence": []}
{"question_id": "9439430ff97c6e927d919860b1cb86a0dcff0038", "predicted_answer": "1. 10-fold cross validation", "predicted_evidence": []}
{"question_id": "00d6228bcd6b839529e52d0d622bf787a9356158", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "c3d50f1e6942c9894f9a344e7cbc411af01e419c", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "602396d1f5a3c172e60a10c7022bcfa08fa6cbc9", "predicted_answer": "1. proposed rcrn outperforms ablative baselines bilstm by +2.9% and 3l-bilstm by +1.1% on average across 16 datasets.", "predicted_evidence": []}
{"question_id": "b984612ceac5b4cf5efd841af2afddd244ee497a", "predicted_answer": "approximately equal parameterization", "predicted_evidence": []}
{"question_id": "bde6fa2057fa21b38a91eeb2bb6a3ae7fb3a2c62", "predicted_answer": "1. 51.5", "predicted_evidence": []}
{"question_id": "a381ba83a08148ce0324b48b8ff35128e66f580a", "predicted_answer": "1. high-order cnn, tree-lstm, drnn, dcnn, cnn-mc, nbow and svm", "predicted_evidence": []}
{"question_id": "edb068df4ffbd73b379590762125990fcd317862", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "8ea664a72e6d6eca73c1b3e1f75a72a677474ab1", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "5e41516a27c587aa2f80dba8cf4c3f616174099b", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "edc43e1b75c0970b7003deeabfe3ad247cb1ed83", "predicted_answer": "1. akkadian.", "predicted_evidence": []}
{"question_id": "0c3924214572579ddbc1b4a87c7f7842ef20ff1b", "predicted_answer": "1. cuneiform", "predicted_evidence": []}
{"question_id": "4519afe91b1042876d7c021487d98e2d72a09861", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "0cfaca6f3f33ebdb338c5f991f6a7a33ff33844d", "predicted_answer": "deepdive", "predicted_evidence": []}
{"question_id": "70c2dc170a73185c9d1a16953f85aca834ead6d3", "predicted_answer": "1. mean average precision", "predicted_evidence": []}
{"question_id": "38854255dbdf2f36eebefc0d9826aa76df9637c6", "predicted_answer": "farsnet", "predicted_evidence": []}
{"question_id": "2a0f14740ee14224d116d4f51dacde6863bcdc1e", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "82c7d9e92c7d7b784de2cae87fb7293034c551f4", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "6d623c96cd3898c3758338e337e9157565f34185", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "827b5bd215599623a3125afe331b56b89b42bf09", "predicted_answer": "the de7 database", "predicted_evidence": []}
{"question_id": "2159062595f24ec29826d517429e1b809ba068b3", "predicted_answer": "i'm ready to help. what is the utterance in question?", "predicted_evidence": []}
{"question_id": "9ebb2adf92a0f8db99efddcade02a20a219ca7d9", "predicted_answer": "1. they used 6 indicators for proficiency (same for written and spoken) each marked by bad, medium or good by one expert.", "predicted_evidence": []}
{"question_id": "973f6284664675654cc9881745880a0e88f3280e", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "0a3a8d1b0cbac559f7de845d845ebbfefb91135e", "predicted_answer": "1. accuracy not available: wer results are reported 42.6 german, 35.9 english", "predicted_evidence": []}
{"question_id": "ec2b8c43f14227cf74f9b49573cceb137dd336e7", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "5e5460ea955d8bce89526647dd7c4f19b173ab34", "predicted_answer": "1. total number of transcribed utterances including train and test for both eng and ger language is 5562 (2188 cleaned)", "predicted_evidence": []}
{"question_id": "d7d611f622552142723e064f330d071f985e805c", "predicted_answer": "70607", "predicted_evidence": []}
{"question_id": "9555aa8de322396a16a07a5423e6a79dcd76816a", "predicted_answer": "1. w.r.t rouge-1 their model outperforms by 0.98% and w.r.t rouge-l their model outperforms by 0.45%", "predicted_evidence": []}
{"question_id": "81e8d42dad08a58fe27eea838f060ec8f314465e", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "482b4cc7676cf13912e27899c718f4dc5d92846d", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "0c09ffb337be0feb25e2fd14164b35a0969d7b4c", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "385dc96604e077611fbd877c7f39d3c17cd63bf2", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "551a17fc1d5b5c3d18bdc4923363cbbda7eb2516", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "62a3dc90ba427c5985789001a02825c9434ce67d", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "b4f5bf3b7b37e2f22d13b724ca8fe7d0888e04a2", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "fa3312ae4bbed11a5bebd77caf15d651962e0b26", "predicted_answer": "1. f1 scores of 86.16 on slot filling and 94.56 on intent detection", "predicted_evidence": []}
{"question_id": "26c290584c97e22b25035f5458625944db181552", "predicted_answer": "1. 10,001 utterances", "predicted_evidence": []}
{"question_id": "d71772bfbc27ff1682e552484bc7c71818be50cf", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "b6858c505936d981747962eae755a81489f62858", "predicted_answer": "1. bilstms + crf architecture bibref36, sententce-state lstm bibref21", "predicted_evidence": []}
{"question_id": "defc17986d3c4aed9eccdbaebda5eb202fbcb6cf", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "03895bc75e4d01c359cd269a9eb3b6ea57039817", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "6bcff3ef61aad6bf1280ea26ed79585e1b838e64", "predicted_answer": "1. no", "predicted_evidence": []}
{"question_id": "6dfad97356b6e82009ee442d7fd2b97b5dcabfe2", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "59a5959a6abfb81b114e7bfaa945301349d20f0f", "predicted_answer": "i'm happy to help! however, i notice that there is only one option provided, and it's not clear what \"their lexicon\" refers to. could you please provide more context or clarify what you are asking about?\n\nif i had to make a guess based on the limited information, my response would be:\n\n1. depechemood", "predicted_evidence": []}
{"question_id": "e2e31ab279d3092418159dfd24760f0f0566e9d3", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "6407dae0c095c2c8e15e6769f03925aa4f0e902e", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "5a2f7e27efdedf3c43498ff0c32f808d406c42ec", "predicted_answer": "glove", "predicted_evidence": []}
{"question_id": "5871d258f66b00fb716065086f757ef745645bfe", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "c554a453b6b99d8b59e4ef1511b1b506ff6e5aa4", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "10210d5c31dc937e765051ee066b971b6f04d3af", "predicted_answer": "1.  16k questions", "predicted_evidence": []}
{"question_id": "5d9b088bb066750b60debfb0b9439049b5a5c0ce", "predicted_answer": "1. remove numbers and interjections", "predicted_evidence": []}
{"question_id": "4c1847f0f3e6f9cc6ac3dfbac9e135d34641a854", "predicted_answer": "1. javascript", "predicted_evidence": []}
{"question_id": "7f9bc06cfa81a4e3f7df4c69a1afef146ed5a1cf", "predicted_answer": "1. 10 epochs: pearson-spearman correlation  drops  60 points when error increase by 20%", "predicted_evidence": []}
{"question_id": "58a340c338e41002c8555202ef9adbf51ddbb7a1", "predicted_answer": "i can only choose from one option, so i'll go with:\n\n1. sst-2 dataset", "predicted_evidence": []}
{"question_id": "0ca02893bda50007f7a76e7c8804101718fbb01c", "predicted_answer": "none of the above.", "predicted_evidence": []}
{"question_id": "751aa2b1531a17496536887288699cc8d5c3cec9", "predicted_answer": "1.", "predicted_evidence": []}
{"question_id": "dc4096b8bab0afcbbd4fbb015da2bea5d38251cd", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "c4c9c7900a0480743acc7599efb359bc81cf3a4d", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "0a4e82dc3728be0bd0325bfe944e7e7de0b98b22", "predicted_answer": "1. human representative to review the iva chat history and resume the failed task", "predicted_evidence": []}
{"question_id": "c635dc8013e63505084b9daaa9ddb021a2d24543", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "61aac406b648865f007a400dcd69f28e44efc636", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "762f2527f85c3ae6bbdf1f331311930ef1e1fa51", "predicted_answer": "1. unanswerable", "predicted_evidence": []}
{"question_id": "e414d819f10c443cbefa8bdb9bd486ffc6d1fc6a", "predicted_answer": "1. 40 minutes", "predicted_evidence": []}
{"question_id": "2e73006e5d007aa08c62030a4d5a7e2e7e0eaf6c", "predicted_answer": "1. 321 videos", "predicted_evidence": []}
{"question_id": "1a8b7d3d126935c09306cacca7ddb4b953ef68ab", "predicted_answer": "1. best model achieved f-score 74.7 on nalcs and f-score of 70.0 on lms on test set", "predicted_evidence": []}
{"question_id": "07c9863e1e86c31b740b5b5a77fe8000be00c273", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "bf7cb53f4105f2e6a413d1adef5349ff1e673500", "predicted_answer": "1. wikitablequestions", "predicted_evidence": []}
{"question_id": "a6419207d2299f25e2688517d1580b7ba07c8e4b", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "b34f6e2cf6b1984afdf18dda2a502db6c2c5224b", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "5c0b8c1b649df1b07d9af3aa9154ac340ec8b81c", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "2e1ededb7c8460169cf3c38e6cde6de402c1e720", "predicted_answer": "1. mean prediction accuracy 0.99582651", "predicted_evidence": []}
{"question_id": "3b391cd58cf6a61fe8c8eff2095e33794e80f0e3", "predicted_answer": "historical s&p 500 component stocks and 306242 news articles", "predicted_evidence": []}
{"question_id": "4d8ca3f7aa65dcb42eba72acf3584d37b416b19c", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "7182f6ed12fa990835317c57ad1ff486282594ee", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "cac0119681f311b2efd14b3251a2a5b69ad5d0cd", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "af75ad21dda25ec72311c2be4589efed9df2f482", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "de12e059088e4800d7d89e4214a3997994dbc0d9", "predicted_answer": "1. the system is compared to baseline models: lstm, rl-spinn and gumbel tree-lstm", "predicted_evidence": []}
{"question_id": "3241f90a03853fa85d287007d2d51e7843ee3d9b", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "52e8f79814736fea96fd9b642881b476243e1698", "predicted_answer": "bulats i-vector/plda", "predicted_evidence": []}
{"question_id": "2af66730a85b29ff28dbfa58342e0ae6265d2963", "predicted_answer": "1. 78,976", "predicted_evidence": []}
{"question_id": "146fe3e97d8080f04222ed20903dd0d5fd2f551c", "predicted_answer": "3,806", "predicted_evidence": []}
{"question_id": "0fc17e51a17efce17577e2db89a24abd6607bb2b", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "e86d381322c8db2b74a13a8e23082ddb010c1e40", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "5712a0b1e33484ebc6d71c70ae222109c08dede2", "predicted_answer": "1. vqa and geoqa", "predicted_evidence": []}
{"question_id": "aee1af55d39145f609da95116ab1b154adb5fa7e", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "feedddb7ae4998b6a3eaa2d6323017ba278748cc", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "be1c0816793a4549c811480170f30fab52a7a157", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "2b5dc3595dfc3d52a1525783d943b3dd0cc62473", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "ee27e5b56e439546d710ce113c9be76e1bfa1a3d", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "4688534a07a3cbd8afa738eea02cc6981a4fd285", "predicted_answer": "1. they use monalog for data-augmentation to fine-tune bert on this task", "predicted_evidence": []}
{"question_id": "45893f31ef07f0cca5783bd39c4e60630d6b93b3", "predicted_answer": "1. they derive it from wordnet", "predicted_evidence": []}
{"question_id": "182c7919329bc5678cf0c79687a66c0f7782577e", "predicted_answer": "1. gating function, dynamic memory", "predicted_evidence": []}
{"question_id": "0747cecb3c72594c5d15ba18490566be1ffdbfad", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "0e9c08b635c1ebfd36472550d619095541bb5af1", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "b13902af1bcf0e199a3ea42bbc8fcd8e696a381a", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "b84bce289c6c81d0a7507ae183b94982533576b3", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "9fd137bf7eabaf8bc234a18b6ea34471cf4a3b95", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "249f2a9bd9d59679cbe82b3fa01572fc7a04f81b", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "fb1c2ff0872084241b9725b4f07750bd3e1df793", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "9d9f6cc0f026f7168fcea461baff4b8a925a185f", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "3d6015d722de6e6297ba7bfe7cb0f8a67f660636", "predicted_answer": "1. economics, genocide, geography, history, human rights, kurdish, kurdology, philosophy, physics, theology, sociology, social study", "predicted_evidence": []}
{"question_id": "2cc63f42410eff3bcb15cfddc593d8aab9413eea", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "0a9ced54324e70973354978cccef1c70dee5a543", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "626873982852ec83c59193dd2cf73769bf77b3ed", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "b3a09d2e3156c51bd5fdc110a2a00a67bb8c0e42", "predicted_answer": "textcat, chromecld, langdetect, langid.py, whatlang, whatthelang, yali, ldig, polyglot 3000, lextek language identifier and open xerox language identifier.", "predicted_evidence": []}
{"question_id": "4c026715ee365c709381c5da770bdc8297eed19f", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "4ef3bfebabda83a6d5ca55d30de0e05893f241e3", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "db264e363f3b3aa83526952bef02f826dff70042", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "e8e6986365f899dead0768ecf7b1eca8a2699f2f", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "f63519bb5e116671cebd65cc78880c5cb573c570", "predicted_answer": "unfortunately, i don't have enough information to determine which low-resource languages were used in this work. therefore, my response is:\n\n1. unanswerable", "predicted_evidence": []}
{"question_id": "ffa4d4bfb226382ca4ecde65ecdc44a3d9e0ce81", "predicted_answer": "1. paraphrase identification", "predicted_evidence": []}
{"question_id": "a779d452d11f368c66f7b51f7190d0fe9402f505", "predicted_answer": "1,058,000", "predicted_evidence": []}
{"question_id": "cdc5a998cb73262594cdae1dda49576044da3d3d", "predicted_answer": "1. we evaluate the false-reject (fr) and false-accept (fa) tradeoff across several end-to-end models of distinct sizes and computational complexities.", "predicted_evidence": []}
{"question_id": "1383ddd4619cf81227c72f3d9f30c10c47a0cdad", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "d7aed39c359fd381495b12996c4dfc1d3da38ed5", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "9c423e3b44e3acc2d4b0606688d4ac9d6285ed0f", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "b6fb72437e3779b0e523b9710e36b966c23a2a40", "predicted_answer": "wikisql - 2 rules", "predicted_evidence": []}
{"question_id": "e6469135e0273481cf11a6c737923630bc7ccfca", "predicted_answer": "sequentialqa", "predicted_evidence": []}
{"question_id": "06202ab8b28dcf3991523cf163b8844b42b9fc99", "predicted_answer": "1. 10k training and 1k test, 1,101 sentences (26k tokens)", "predicted_evidence": []}
{"question_id": "271019168ed3a2b0ef5e3780b48a1ebefc562b57", "predicted_answer": "bi-lstm: for low resource <17k clean data: using distant supervision resulted in huge boost of f1 score (1k eg. ~9 to ~36 wit distant supervision)\nbert: <5k clean data boost of f1 (1k eg. ~32 to ~47 with distant supervision)", "predicted_evidence": []}
{"question_id": "288613077787159e512e46b79190c91cd4e5b04d", "predicted_answer": "bi-lstm, bert", "predicted_evidence": []}
{"question_id": "cf74ff49dfcdda2cd67a896b4b982a1c3ee51531", "predicted_answer": "nigeria, benin, ghana, cameroon, togo, c\u00f4te d'ivoire, chad, burkina faso, and sudan", "predicted_evidence": []}
{"question_id": "827c58f6cab6c6fe7a6c43bdc71150b61ba0eed4", "predicted_answer": "the agreement scores of their annotated dataset are: \n- relevance categorization: $\\alpha = 0.27$\n- subject categorization: $\\alpha = 0.29$\n- stance and sentiment: $\\alpha = 0.35$ and $\\alpha = 0.34$", "predicted_evidence": []}
{"question_id": "58ad7e8f7190e2a4f1588cae9a7842c56b37694d", "predicted_answer": "1. 27,534 messages", "predicted_evidence": []}
{"question_id": "12eba1598dca14db64dbc8b73484639363a4618e", "predicted_answer": "1. word unigrams, bigrams, and trigrams", "predicted_evidence": []}
{"question_id": "4e468ce13b7f6ac05371c62c08c3cec1cd760517", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "3fb4334e5a4702acd44bd24eb1831bb7e9b98d31", "predicted_answer": "1. evaluation datasets used: \ncmrc 2018 - 18939 questions, 10 answers \ndrcd - 33953 questions, 5 answers", "predicted_evidence": []}
{"question_id": "a9acd1af4a869c17b95ec489cdb1ba7d76715ea4", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "afa94772fca7978f30973c43274ed826c40369eb", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "6f2118a0c64d5d2f49eee004d35b956cb330a10e", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "8a0a51382d186e8d92bf7e78277a1d48958758da", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "b8dea4a98b4da4ef1b9c98a211210e31d6630cf3", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "4146e1d8f79902c0bc034695998b724515b6ac81", "predicted_answer": "1. conll-2012 shared task bibref21 corpus", "predicted_evidence": []}
{"question_id": "42394c54a950bae8cebecda9de68ee78de69dc0d", "predicted_answer": "1. counts of predicate-argument tuples from english wikipedia", "predicted_evidence": []}
{"question_id": "e9d882775a132e172eea68ab6ab4621a924bb6b8", "predicted_answer": "i'm happy to help! however, i don't see multiple options provided for the question. could you please provide more options or clarify which attention methods are being referred to? i'll do my best to provide an answer based on the information given.\n\nif i had to make a guess with only one option available:\n\n1. attention parsing", "predicted_evidence": []}
{"question_id": "6367877c05beebfdbb31e83c1f25dfddf925b6b6", "predicted_answer": "cora", "predicted_evidence": []}
{"question_id": "d151327c93b67928313f8fad8079a4ff9ef89314", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "70f9358dc01fd2db01a6b165e0b4e83e4a9141a7", "predicted_answer": "1. mmb, deepwalk, line,  node2vec, tadw, cene, cane, wane, dmte", "predicted_evidence": []}
{"question_id": "4a4616e1a9807f32cca9b92ab05e65b05c2a1bf5", "predicted_answer": "1. test set 1 contained 57 drug labels and 8208 sentences and test set 2 contained 66 drug labels and 4224 sentences", "predicted_evidence": []}
{"question_id": "3752bbc5367973ab5b839ded08c57f51336b5c3d", "predicted_answer": "1. training-22, nlm-180", "predicted_evidence": []}
{"question_id": "30db81df46474363d5749d7f6a94b7ef95cd3e01", "predicted_answer": "1. twitter, yelp reviews and movie reviews", "predicted_evidence": []}
{"question_id": "5c26388a2c0b0452d529d5dd565a5375fdabdb70", "predicted_answer": "textworld games", "predicted_evidence": []}
{"question_id": "184e1f28f96babf468f2bb4e1734f69646590cda", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "71fca845edd33f6e227eccde10db73b99a7e157b", "predicted_answer": "2", "predicted_evidence": []}
{"question_id": "93b299acfb6fad104b9ebf4d0585d42de4047051", "predicted_answer": "absa semeval 2014-2016 datasets", "predicted_evidence": []}
{"question_id": "e755fb599690d0d0c12ddb851ac731a0a7965797", "predicted_answer": "dutch, french, russian, spanish, turkish, english", "predicted_evidence": []}
{"question_id": "7e51490a362135267e75b2817de3c38dfe846e21", "predicted_answer": "1.  local, shallow features based mostly on orthographic, word shape and n-gram features plus their context", "predicted_evidence": []}
{"question_id": "e98d331faacd50f8ec588d2466b5a85da1f37e6f", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "fbe22e133fa919f06abd8afbed3395af51d2bfef", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "f319f2c3f9339b0ce47478f5aa0c32da387a156e", "predicted_answer": "1. penn treebank, text8", "predicted_evidence": []}
{"question_id": "02417455c05f09d89c2658f39705ac1df1daa0cd", "predicted_answer": "$1,728", "predicted_evidence": []}
{"question_id": "6ce057d3b88addf97a30cb188795806239491154", "predicted_answer": "1. bert, xlnet roberta, albert, distilbert", "predicted_evidence": []}
{"question_id": "4cab33c8dd46002e0ccafda3916b37366a24a394", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "9dd65dca9dffd2bf78ecc22b17824edc885d1fa2", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "e91692136033bbc3f19743d0ee5784365746a820", "predicted_answer": "2 is not an option so i will choose 1: using multiple pivot sentences", "predicted_evidence": []}
{"question_id": "94e17980435aaa9fc3b5328f16f3368dc8a736bd", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "4d8b3928f89d73895a7655850a227fbac08cdae9", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "b6e4b98fad3681691bcce13f57fb173aee30c592", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "af7a9b56596f90c84f962098f7e836309161badf", "predicted_answer": "1. 1338 pairs for training", "predicted_evidence": []}
{"question_id": "ba61ed892b4f7930430389e80a0c8e3b701c8e5d", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "6a566095e25cbb56330456d7a1f3471693817712", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "56c6ff65c64ca85951fdea54d6b096f28393c128", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "356e462f7966e30665a387ed7a9ad2e830479da6", "predicted_answer": "tatoeba and opensubtitles", "predicted_evidence": []}
{"question_id": "572458399a45fd392c3a4e07ce26dcff2ad5a07d", "predicted_answer": "for the oshiete-goo dataset: rouge-l score is higher by 0.021 and bleu-4 score is higher by 0.037. for the nfl6 dataset: rouge-l score is higher by 0.028 and bleu-4 score is higher by 0.040.", "predicted_evidence": []}
{"question_id": "cb4727cd5643dabc3f5c95e851d5313f5d979bdc", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "33d864153822bd378a98a732ace720e2c06a6bc6", "predicted_answer": "1.", "predicted_evidence": []}
{"question_id": "b13cf4205f3952c3066b9fb81bd5c4277e2bc7f5", "predicted_answer": "unfortunately, i couldn't find a specific answer to the size of the conll-2009 dataset. therefore, my response is:\n\n1. unanswerable", "predicted_evidence": []}
{"question_id": "86f24ecc89e743bb1534ac160d08859493afafe9", "predicted_answer": "1. dependency head and dependency relation label, denoted as dep and rel for short, tree-based position feature (tpf) as dependency path (deppath), shortest dependency path (sdp) as relation path (relpath)", "predicted_evidence": []}
{"question_id": "bab8c69e183bae6e30fc362009db9b46e720225e", "predicted_answer": "marcheggiani and titov (2017) and cai et al. (2018)", "predicted_evidence": []}
{"question_id": "ead5dc1f3994b2031a1852ecc4f97ac5760ea977", "predicted_answer": "1. 14 categories", "predicted_evidence": []}
{"question_id": "86cd1228374721db67c0653f2052b1ada6009641", "predicted_answer": "1. youtube videos", "predicted_evidence": []}
{"question_id": "7011b26ffc54769897e4859e4932aeddfab82c9f", "predicted_answer": "1. youtube asr system", "predicted_evidence": []}
{"question_id": "3a6559dc6eba7f5abddf3ac27376ba0b9643a908", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "5cd5864077e4074bed01e3a611b747a2180088a0", "predicted_answer": "unfortunately, i don't have enough information to give a specific answer. the size of datasets used in experiments can vary greatly depending on the field, research question, and methodology.\n\nhowever, based on common practices in machine learning and computer vision, here are some possible answers:\n\n* for small-scale experiments or proof-of-concept studies: 200-1000 images\n* for medium-scale experiments: 1,000-10,000 images\n* for large-scale experiments: 10,000-100,000 images or more\n\nplease note that these are rough estimates and can vary greatly depending on the specific context.\n\nif i had to choose from your options, i would say:\n\n1. 2000 images", "predicted_evidence": []}
{"question_id": "d664054c8d1f8e84169d4ab790f2754274353685", "predicted_answer": "1. the ubc database bibref14", "predicted_evidence": []}
{"question_id": "03fb4b31742820df58504575c562bee672e016be", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "691cba5713c76a6870e35bc248ce1d29c0550bc7", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "4542a4e7eabb8006fb7bcff2ca6347cfb3fbc56b", "predicted_answer": "1. no", "predicted_evidence": []}
{"question_id": "af8d3ee6a282aaa885e9126aa4bcb08ac68837e0", "predicted_answer": "1. over 41,250 videos and 825,000 captions in both english and chinese., over 206,000 english-chinese parallel translation pairs", "predicted_evidence": []}
{"question_id": "0e510d918456f3d2b390b501a145d92c4f125835", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "7ac0cec79c8c2b1909b0a1cc0d4646fce09884ee", "predicted_answer": "no, there isn't a direct way of converting existing convolution layers into self-attention to perform very same convolution.", "predicted_evidence": []}
{"question_id": "6fd07f4dc037a82c8fa0ed80469eb4171dcebf12", "predicted_answer": "i'm happy to help! however, i don't see a clear question about authors and \"sufficient number of heads.\" could you please rephrase or provide more context for your question?", "predicted_evidence": []}
{"question_id": "2caa8726222237af482e170c51c88099cefef6fc", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "5367f8979488aaa420d8a69fec656851095ecacb", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "3cca26a9474d3b0d278e4dd57e24b227e7c2cd41", "predicted_answer": "penn chinese treebank", "predicted_evidence": []}
{"question_id": "8f8f2b0046e1a78bd34c0c3d6b6cb24463a8ed7f", "predicted_answer": "english, chinese", "predicted_evidence": []}
{"question_id": "e37c32fce68759b2272adc1e44ea91c1a7c47059", "predicted_answer": "1. movies , restaurants, english , korean", "predicted_evidence": []}
{"question_id": "280f863cfd63b711980ca6c7f1409c0306473de7", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "b5a2b03cfc5a64ad4542773d38372fffc6d3eac7", "predicted_answer": "1. qualitatively through efficiency, effectiveness and satisfaction aspects and quantitatively through metrics such as precision, recall, accuracy, bleu score and even human judgement.", "predicted_evidence": []}
{"question_id": "b093b440ae3cd03555237791550f3224d159d85b", "predicted_answer": "1. empatheticdialogues dataset", "predicted_evidence": []}
{"question_id": "ad16c8261c3a0b88c685907387e1a6904eb15066", "predicted_answer": "1. how to incorporate affective information into chatbots, what are resources that available and can be used to build eac, and how to evaluate eac performance", "predicted_evidence": []}
{"question_id": "d3014683dff9976b7c56b72203df99f0e27e9989", "predicted_answer": "1. p@1 (equivalent to accuracy), p@5, and p@10", "predicted_evidence": []}
{"question_id": "ed522090941f61e97ec3a39f52d7599b573492dd", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "5d164651a4aed7cf24d53ba9685b4bee8c965933", "predicted_answer": "unfortunately, i don't have enough information about the paper in question. therefore, my response is:\n\n1. unanswerable", "predicted_evidence": []}
{"question_id": "4670e1be9d6a260140d055c7685bce365781d82b", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "c2da598346b74541c78ecff5c9586b3857dd01b5", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "013a8525dbf7a9e1e69acc1cff18bb7b8261cbad", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "5efed109940bf74ed0a9d4a5e97a535502b23d27", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "b8137eb0fa0b41f871c899a54154f640f0e9aca1", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "38b527783330468bf6c4829f7d998e6f17c615f0", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "6b2fbc1c083491a774233f9edf8f76bd879418df", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "fb56743e942883d7e74a73c70bd11016acddc348", "predicted_answer": "babel speech corpus", "predicted_evidence": []}
{"question_id": "093dd1e403eac146bcd19b51a2ace316b36c6264", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "1adbdb5f08d67d8b05328ccc86d297ac01bf076c", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "da82b6dad2edd4911db1dc59e4ccd7f66c5fd79c", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "cf15c4652e23829d8fb4cf2a25e64408c18734c1", "predicted_answer": "1.", "predicted_evidence": []}
{"question_id": "439af1232a012fc4d94ef2ffe305dd405bee3888", "predicted_answer": "baseline is used in option: base", "predicted_evidence": []}
{"question_id": "b6a6bdca6dee70f8fe6dd1cfe3bb2c5ff03b1605", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "8951fde01b1643fcb4b91e51f84e074ce3b69743", "predicted_answer": "1. they  evaluate newly proposed models in several low-resource settings across different languages with real, distantly supervised data with non-synthetic noise", "predicted_evidence": []}
{"question_id": "38c74ab8292a94fc5a82999400ee9c06be19f791", "predicted_answer": "1. it contains 106,350 documents", "predicted_evidence": []}
{"question_id": "ff307b10e56f75de6a32e68e25a69899478a13e4", "predicted_answer": "1. logistic regression (lr), recurrent neural network (rnn) bibref35, convolutional neural network (cnn) bibref36 and google bert bibref37", "predicted_evidence": []}
{"question_id": "16af38f7c4774637cf8e04d4b239d6d72f0b0a3a", "predicted_answer": "over 104k documents", "predicted_evidence": []}
{"question_id": "e9209ebf38c4ae4d93884f68c7b5b3444e0604f3", "predicted_answer": "i'm happy to help! however, i don't see a list of options provided for the question \"what evaluation metrics are used to measure diversity?\" could you please provide the complete list of options? i'll do my best to select the correct answer.", "predicted_evidence": []}
{"question_id": "4319a13a6c4a9494ccb465509c9d4265f63dc9b5", "predicted_answer": "1.", "predicted_evidence": []}
{"question_id": "5be62428f973a08c303c66018b081ad140c559c8", "predicted_answer": "0.657 hr@10 and 0.410 ndcg@10", "predicted_evidence": []}
{"question_id": "8b11bc3a23932afe7d52c19deffd9dec4830f2e9", "predicted_answer": "unfortunately, i don't have enough information to provide an accurate answer. the provided text doesn't contain a definition of \"fake news\" by the authors.\n\nhowever, since there's only one option available, i'll choose:\n\n1. unanswerable", "predicted_evidence": []}
{"question_id": "64b65687b82ddb17c3d068381aaee56eb7fc02cd", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "9257c578ee19a7d93e2fba866be7b0bf1142c393", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "657edbf39c500b2446edb9cca18de2912c628b7d", "predicted_answer": "perplexity score 142.84 on dev and 138.91 on test", "predicted_evidence": []}
{"question_id": "235c156d9c2adc895c9113f53c60f2dd8df45834", "predicted_answer": "1. mandarin, english", "predicted_evidence": []}
{"question_id": "fa2ffc6b4b046e17bc41e199855c4941673e2caf", "predicted_answer": "1. parallel monolingual corpus in english and mandarin", "predicted_evidence": []}
{"question_id": "ad7b13579823cbc7825421c84d16f23ed863f6ee", "predicted_answer": "1. vatex, wmt 2014 english-to-german, and vqa-v2 datasets", "predicted_evidence": []}
{"question_id": "0c7823b27326b3f5dff51f32f45fc69c91a4e06d", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "84a4a1f4695eba599d447e030c94f51e5f2f03bb", "predicted_answer": "1. our method still can improve the state-of-the-art accuracy bibref7 from 60.32% to 60.34%", "predicted_evidence": []}
{"question_id": "785eb3c7c5a5c27db14006ac357299ed1216313a", "predicted_answer": "lasso optimization problem", "predicted_evidence": []}
{"question_id": "bf6c14e9c5f476062cbaaf9179b0c9b751222c8f", "predicted_answer": "1. the basic question generation module (module 1) and co-attention visual question answering module (module 2)", "predicted_evidence": []}
{"question_id": "06c340c7c2ad57d7621c3e8baba6a3d0ed9f4696", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "4c88441f8a1b5fce0ca55a6fced34f97260206ae", "predicted_answer": "biaffine attention", "predicted_evidence": []}
{"question_id": "7486c9d9e6c407c0c3bc012405d689dbee072327", "predicted_answer": "german", "predicted_evidence": []}
{"question_id": "0f2403fa77738bf05534d7f9d83c9dbb0a0d6140", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "21df76462c76d6e2d52fb7dce573ee5336627cb5", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "45be26c01e82835d9949529003c6b64f90db3d1a", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "e28019afcb55c01516998554503bc1b56f923995", "predicted_answer": "1. personal thought of the annotator.", "predicted_evidence": []}
{"question_id": "551cc0401674f7c363e0018b8186a125f7b17e99", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "ad5898fa0063c8a943452f79df2f55a5531035c7", "predicted_answer": "word embeddings trained on googlenews", "predicted_evidence": []}
{"question_id": "601f96770726a0063faf9bacd5db01c4af5add1f", "predicted_answer": "1. rule-based and dictionary-based methods", "predicted_evidence": []}
{"question_id": "1c68d18b4b65c4d75dc199d2043079490f6310f8", "predicted_answer": "entity recognition and normalization (ner) and entity disambiguation (ed).", "predicted_evidence": []}
{"question_id": "818c89b11471a6ca4f13c838713864fdf282c2ca", "predicted_answer": "there are many other neural language models that have been explored in addition to lstm-lm. some examples include:\n\n* transformer-xl\n* bert\n* roberta\n* xlnet\n* elmo\n* gru-lm\n* cnn-lm\n* attention-based models", "predicted_evidence": []}
{"question_id": "7994b4001925798dfb381f9aa5c0545cdbd77220", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "87159024d4b6dac8c456bb74a91044df292f6b99", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "0d755ff58a7e22eb4d02fca45d4a7a3920f4e725", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "ff2bcf2d8ffee586751ce91cf15176301267b779", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "55588ae77496e7753bff18763a21ca07d9f93240", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "4e9d1c73a2d032ec4e04e04921897b7cf928bda8", "predicted_answer": "1. simple linear model with rank constraint, hierarchical softmax, n-gram features", "predicted_evidence": []}
{"question_id": "69e627942dfa7018d2933a88cea9543641d12d0d", "predicted_answer": "1. unanswerable", "predicted_evidence": []}
{"question_id": "4d5f112874250d48eb49649c4abe31d6c9236700", "predicted_answer": "i need more options to choose from. however, based on the single option provided:\n\n1. gpt-2", "predicted_evidence": []}
{"question_id": "8985ead714236458a7496075bc15054df0e3234e", "predicted_answer": "the overall accuracy per model is: 5-gram (60.5), lstm (68.9), txl (68.7), gpt-2 (80.1)", "predicted_evidence": []}
{"question_id": "49aecc50823a60c852165e121dbc0ca54304e40f", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "0153f563f5e2680c2de1a5f6d0e443454dc1ef2a", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "670c464a5dba78e0be7ec168fe36db604e172ea7", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "94ec0e205790ec663a5353f3c68c8d77701573c7", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "a91878129583fcb6d16067ba8ba3600e39d70021", "predicted_answer": "1. k-means, hierarchical clustering with ward's method for merging clusters", "predicted_evidence": []}
{"question_id": "ff9495982b8821240b8a65eafcc9bb8ed8b8e084", "predicted_answer": "1. estimated test accuracy is highly correlated with actual test accuracy for various datasets, appropriateness of the proposed function for modeling the complex error landscape", "predicted_evidence": []}
{"question_id": "dcd8138f0cba0dcd109ccb21c228da5c110a68eb", "predicted_answer": "unfortunately, i don't have enough information about the specific model you are referring to. however, based on general knowledge of modeling and statistical analysis, here is a possible answer:\n\nthe proposed functional form for some model can be constructed through various methods such as:\n\n* literature review: reviewing existing research and studies related to the model to identify commonly used functional forms.\n* theoretical considerations: using theoretical knowledge about the underlying relationships between variables to propose a functional form.\n* data exploration: exploring the data to identify patterns and relationships that can inform the choice of functional form.\n* model comparison: comparing different functional forms using statistical criteria such as goodness-of-fit, akaike information criterion (aic), or bayesian information criterion (bic).\n\nhowever, without more specific information about the model, it is difficult to provide a definitive answer.\n\ngiven the options provided, i would choose:\n\n1. unanswerable", "predicted_evidence": []}
{"question_id": "2df2f6e4efd19023434c84f5b4f29a2f00bfc9fb", "predicted_answer": "bag of words, tf-idf, bag-of-means", "predicted_evidence": []}
{"question_id": "ba5d4301b88de057574120986641a66e439c9af5", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "d7109cf68bcefc2f8c996c9492dedb8b6b1e1149", "predicted_answer": "imitation learning environment", "predicted_evidence": []}
{"question_id": "95c7b27d192ab0edcdf203a74ce24f4a9a814e6c", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "991a6650abe8eeba068b2a16db33172090f19614", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "48cf360a7753a23342f53f116eeccc2014bcc8eb", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "384d571e4017628ebb72f3debb2846efaf0cb0cb", "predicted_answer": "aristo corpus", "predicted_evidence": []}
{"question_id": "33d1f53cf25a7701db605b6b7ac36946af588bb7", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "0aa46c132515d8830a72f263812cdf7cbd5627c6", "predicted_answer": "1. rs-average , rs-linear, rs-item, rs-mf, sum-opinosis, sum-lstm-att", "predicted_evidence": []}
{"question_id": "56a3c9bd74c6573abce3805177cdebf941db0b71", "predicted_answer": "1. manually reviewed", "predicted_evidence": []}
{"question_id": "73cd785d474bae7af974802715ef7ba5468d9139", "predicted_answer": "1. manually inspect", "predicted_evidence": []}
{"question_id": "65461516098ed63c45a567648e8e47c38ea7e58a", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "92d09654011d424cfef5691eec28ee934f88d954", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "8a94766f8251fa0bce0e09e5c69ce05761811a62", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "92cfac12d9583747bd9be8604275b4a9ddd8afe6", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "2e6b7afaf14871ed6db674782b93709910020b06", "predicted_answer": "1. original models were better in some tasks (cr, mpqa, mrpc), utilizing self-attentive sentence representation further improves performances in 5 out of 8 tasks", "predicted_evidence": []}
{"question_id": "d2e409031f4512375dd5cecec639c7373025f277", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "5d22746b3004c5e90ea714b24bf8bc7b4d15bd88", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "0c09a0e8f9c5bdb678563be49f912ab6e3f97619", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "50716cc7f589b9b9f3aca806214228b063e9695b", "predicted_answer": "1, 2, 3, 4, 5, 6, 7, 8, 9, 10", "predicted_evidence": []}
{"question_id": "80b9600e51a823f32bbce12fc52cba9700e2b8d2", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "8aeaa3ccb8e062a01007c25a510b0dc1747ce66c", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "39cfb8473c8be4e5d8ecc3227b800a10477c5f80", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "f981781021d4bacbaf3d076c895dc42d7fa108ba", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "d5105a6a6d5d1931b0729dcf15ca862d6eac770f", "predicted_answer": "1. 62", "predicted_evidence": []}
{"question_id": "be7b375b22d95d1f6c68c48f57ea87bf82c72123", "predicted_answer": "rouge f1, meteor", "predicted_evidence": []}
{"question_id": "c4b5cc2988a2b91534394a3a0665b0c769b598bb", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "ef07ec34433221d4da79d5923fb00d8ac446b92c", "predicted_answer": "1. median cosine similarity", "predicted_evidence": []}
{"question_id": "5cb3d69607f60e1c5be2120462726a477ead9570", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "3b7798a6bce1a5faf411bb12e2e011dbab1e279d", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "65ebed1971dca992c3751ed985fbe294cbe140d7", "predicted_answer": "1. a reliability study for the proposed scheme", "predicted_evidence": []}
{"question_id": "b24b56ccc5d4b04fee85579b2dee77306ec829b2", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "3bfdbf2d4d68e01bef39dc3371960e25489e510e", "predicted_answer": "1.", "predicted_evidence": []}
{"question_id": "9378b41f7e888e78d667e9763883dd64ddb48728", "predicted_answer": "i don't have enough information to determine if they use a crowdsourcing platform. can you please provide more context or clarify who \"they\" are?", "predicted_evidence": []}
{"question_id": "73bbe0b6457423f08d9297a0951381098bd89a2b", "predicted_answer": "2009 zhao et al. + me", "predicted_evidence": []}
{"question_id": "e292676c8c75dd3711efd0e008423c11077938b1", "predicted_answer": "lstm and bert", "predicted_evidence": []}
{"question_id": "1afd550cbee15b753db45d7db2c969fc3d12a7d9", "predicted_answer": "1. no", "predicted_evidence": []}
{"question_id": "2a7c40a72b6380e76511e722b4b02b3a1e5078fd", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "f95097cf4a0dc036fd8b80c007cd8d7a157b7816", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "bb8a0035b767688a98602c33f4714f8ac8ae60db", "predicted_answer": "1. rouge-1, rouge-2 and rouge-l, f-measure rouge on xsum and cnn/dailymail, and use limited-length recall-measure rouge on nyt and duc", "predicted_evidence": []}
{"question_id": "2a0a44f169ad61774d77df65f8846bd57685bfcf", "predicted_answer": "1. three years of online news articles from june 2016 to june 2019", "predicted_evidence": []}
{"question_id": "fd6c194632230e392088fc1f574c8626c6a2fa96", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "487dc65bf8a8ecbf052cf05641caf1b90a502853", "predicted_answer": "1. three years of online news articles from june 2016 to june 2019", "predicted_evidence": []}
{"question_id": "ce6f6cd55ada011233a9dab4d99a94d7944d5388", "predicted_answer": "unfortunately, i don't have enough information to provide a specific answer. therefore, my response is:\n\n1. unanswerable", "predicted_evidence": []}
{"question_id": "d4ce220dcdabcf9ebf4da9bdd3ad778e2d79fc07", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "c806e891324af5d10a72c3b4b9b91177ae6446fb", "predicted_answer": "textcnn, textrnn, sase, dpcnn, and bert", "predicted_evidence": []}
{"question_id": "e1132564b0dd916a522e7690bc7719d2bba3fe68", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "25c4fa78299481788a19d0c25ae07dfd8cb6315c", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "dcdcd977f18206da3ff8ad0ffb14f7bc5e126c7d", "predicted_answer": "1. we use the context of the word to predict its label and by doing so our model learns label-aware context for each word in the sentence", "predicted_evidence": []}
{"question_id": "5efa19058f815494b72c44d746c157e9403f726e", "predicted_answer": "1. micro-averaged f1 score", "predicted_evidence": []}
{"question_id": "71f135be79341e61c28c3150b1822d0c4d0ca8d6", "predicted_answer": "1. improves the f1 score by almost 2%, which corresponds to a 12.3% error rate reduction", "predicted_evidence": []}
{"question_id": "cb8e2069218e30c643013c20e93ebe23525d9f55", "predicted_answer": "pytext", "predicted_evidence": []}
{"question_id": "2d47cdf2c1e0c64c73518aead1b94e0ee594b7a5", "predicted_answer": "1. dataset has 1737 train, 497 dev and 559 test sentences.", "predicted_evidence": []}
{"question_id": "7633be56ae46c163fb21cd1afd018f989eb6b524", "predicted_answer": "1. conditional random field model, seq2seq attention model", "predicted_evidence": []}
{"question_id": "dafa760e1466e9eaa73ad8cb39b229abd5babbda", "predicted_answer": "1. 4.756 million sentences", "predicted_evidence": []}
{"question_id": "649d6dc076251547aece6532f75d00fc99081d2b", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "92412a449c28b9121a4a4f4acca996563f107131", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "76405b76b930a5bbe895e9e96ce4a3cff1b0b1a1", "predicted_answer": "1. pre-trained text representations, transformer-based encoders together with gru models, attention mechanisms are paramount for learning top performing networks, top-down is the preferred attention method", "predicted_evidence": []}
{"question_id": "f08502e952e711c629d40b22ee3f5ff626d62ba8", "predicted_answer": "1. mt metrics, readability metrics and other sentence-level features, metrics based on the baseline quest features, metrics based on other features", "predicted_evidence": []}
{"question_id": "8e5e03a5f35f0820a3a1651e148dd6faf646fb67", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "090fd9ce9a21438cdec1ea51ed216941d52eb3b6", "predicted_answer": "hierarchical disentangled self-attention", "predicted_evidence": []}
{"question_id": "d13efa7dee280c7c2f6dc451c4fbbf0240fc2efa", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "6cd01609c8afb425fbed941441a2528123352940", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "7a70fb11cb3449749f0c2c06101965bf5d02c54a", "predicted_answer": "i couldn't find any information on what kind of representation exploration infodens provides. therefore, i'll choose:\n\n1. unanswerable", "predicted_evidence": []}
{"question_id": "03b939ad70593f6475c56e9be73ba409d33faa62", "predicted_answer": "they compare to: 1. lead, query_sim, multimr, svr, docemb, isolation", "predicted_evidence": []}
{"question_id": "940873658ee64e131cafcf9b3d26a45a98920cc2", "predicted_answer": "unfortunately, i must choose:\n\n1. unanswerable", "predicted_evidence": []}
{"question_id": "3d39e57e90903b776389f1b01ca238a6feb877f3", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "69ef007fc131b04b5b71b0b446db2f77f434f1b3", "predicted_answer": "none of the above options directly answers the question about which tweets are used to output the daily sentiment signal. however, based on the provided option:\n\n1. tesla and ford are investigated on how twitter sentiment could impact the stock price.\n\nthis is my best guess for an answer given the context, but it does not directly address the question asked.", "predicted_evidence": []}
{"question_id": "20df24165b881f97dc1ac32f343939554dd68011", "predicted_answer": "1. linear logistic regression to a set of stock technical signals", "predicted_evidence": []}
{"question_id": "551f77b58c48ee826d78b4bf622bb42b039eca8c", "predicted_answer": "1. can be biased by dataset used and may generate categories which are suboptimal compared to human designed categories", "predicted_evidence": []}
{"question_id": "74cd51a5528c6c8e0b634f3ad7a9ce366dfa5706", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "4bf4374135c39d10dafece4bed8ef547dc3bf9f0", "predicted_answer": "unfortunately, i don't have enough information to provide a specific answer. however, based on my training data, i can suggest that this is likely related to database query visualization.\n\nin that case, i'll take a guess and say that the correct answer is not among the options provided. if i had to choose from a broader set of options, i would say something like \"query parsing and rendering algorithms\" or \"visualization libraries and tools\". however, since only one option is available, my response will be:\n\n1. unanswerable", "predicted_evidence": []}
{"question_id": "e2a637f1d93e1ea9f29c96ff0fc6bc017209065b", "predicted_answer": "1. hand crafted by users", "predicted_evidence": []}
{"question_id": "b3bd217287b8c765b0d461dc283afec779dbf039", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "e8647f9dc0986048694c34ab9ce763b3167c3deb", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "a0876fcbcb5a5944b412613e885703f14732676c", "predicted_answer": "unfortunately, i don't have enough information to provide a specific answer from the options given, as there is only one option and it's \"unanswerable\". however, based on general knowledge, here is my response:\n\nthere are no other options provided, so i will respond with a guess. in user studies for natural language (nl) interfaces, users typically evaluate reliability by assessing factors such as accuracy, consistency, and responsiveness of the system to their inputs.\n\nhowever, since there's only one option available, i'll choose that:\n\n1. unanswerable", "predicted_evidence": []}
{"question_id": "84d36bca06786070e49d3db784e42a51dd573d36", "predicted_answer": "1. conceptualization task", "predicted_evidence": []}
{"question_id": "7af01e2580c332e2b5e8094908df4e43a29c8792", "predicted_answer": "1. by computing number of unique responses and number of responses divided by the number of unique responses to that question for each of the questions", "predicted_evidence": []}
{"question_id": "c78f18606524539e4c573481e5bf1e0a242cc33c", "predicted_answer": "1001", "predicted_evidence": []}
{"question_id": "0cf6d52d7eafd43ff961377572bccefc29caf612", "predicted_answer": "1. amt", "predicted_evidence": []}
{"question_id": "ddd6ba43c4e1138156dd2ef03c25a4c4a47adad0", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "bd99aba3309da96e96eab3e0f4c4c8c70b51980a", "predicted_answer": "rnn-context, srb, copynet, rnn-distract, drgd", "predicted_evidence": []}
{"question_id": "73bb8b7d7e98ccb88bb19ecd2215d91dd212f50d", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "86e3136271a7b93991c8de5d310ab15a6ac5ab8c", "predicted_answer": "(1) good (3 points), (2) acceptable (2 points), (3) failed (1 point)", "predicted_evidence": []}
{"question_id": "b48cd91219429f910b1ea6fcd6f4bd143ddf096f", "predicted_answer": "1. bleu, distinct-1 & distinct-2", "predicted_evidence": []}
{"question_id": "4f1a5eed730fdcf0e570f9118fc09ef2173c6a1b", "predicted_answer": "1. seq2seq, cvae, hierarchical gated fusion unit (hgfu), mechanism-aware neural machine (manm)", "predicted_evidence": []}
{"question_id": "4bdad5a20750c878d1a891ef255621f6172b6a79", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "2e3265d83d2a595293ed458152d3ee76ad19e244", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "c2432884287dca4af355698a543bc0db67a8c091", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "226ae469a65611f041de3ae545be0e386dba7d19", "predicted_answer": "1. wikipedia corpus and bookcorpus", "predicted_evidence": []}
{"question_id": "8ad815b29cc32c1861b77de938c7269c9259a064", "predicted_answer": "en, ja, es, ar, pt, ko, th, fr, tr, ru, it, de, pl, nl, el, sv, fa, vi, fi, cs, uk, hi, da, hu, no, ro, sr, lv, bg, ur, ta, mr, bn, in, kn, et, sl, gu, cy, zh, ckb, is, lt, ml, si, iw, ne, km, my, tl, ka, bo", "predicted_evidence": []}
{"question_id": "3f9ef59ac06db3f99b8b6f082308610eb2d3626a", "predicted_answer": "1. langid.py library, encoder-decoder equilid system, gru neural network lanidenn system, cld2, cld3", "predicted_evidence": []}
{"question_id": "203d322743353aac8a3369220e1d023a78c2cae3", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "557d1874f736d9d487eb823fe8f6dab4b17c3c42", "predicted_answer": "1. bantu", "predicted_evidence": []}
{"question_id": "f41c401a4c6e1be768f8e68f774af3661c890ffd", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "09cd7ae01fe97bba230c109d0234fee80a1f013b", "predicted_answer": "1. french-mboshi 5k corpus", "predicted_evidence": []}
{"question_id": "be3e020ba84bc53dfb90b8acaf549004b66e31e2", "predicted_answer": "1. precision, recall, and f-measure on boundaries (bp, br, bf), and tokens (wp, wr, wf),  exact-match (x) metric", "predicted_evidence": []}
{"question_id": "24014a040447013a8cf0c0f196274667320db79f", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "9aa52b898d029af615b95b18b79078e9bed3d766", "predicted_answer": "the proposed model is slightly faster in decoding (8541 tokens/sec vs 8532 tokens/sec) and has similar training time (8h vs 8h).", "predicted_evidence": []}
{"question_id": "c431c142f5b82374746a2b2f18b40c6874f7131d", "predicted_answer": "wmt18 ende bitext, wmt16 enro bitext, and wmt15 enfr bitext.", "predicted_evidence": []}
{"question_id": "7835d8f578386834c02e2c9aba78a345059d56ca", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "32e78ca99ba8b8423d4b21c54cd5309cb92191fc", "predicted_answer": "1. 14 volunteers", "predicted_evidence": []}
{"question_id": "ffc5ad48b69a71e92295a66a9a0ff39548ab3cf1", "predicted_answer": "1. glove embeddings trained by bibref10 on wikipedia and gigaword 5 (vocab: 400k, dim: 300), w2v-gn, word2vec bibref5 trained on the google news dataset (vocab: 3m, dim: 300), deepwalk , node2vec", "predicted_evidence": []}
{"question_id": "1024f22110c436aa7a62a1022819bfe62dc0d336", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "f062723bda695716aa7cb0f27675b7fc0d302d4d", "predicted_answer": "1. judged by 10 raters on a [0,10] scale", "predicted_evidence": []}
{"question_id": "b13d0e463d5eb6028cdaa0c36ac7de3b76b5e933", "predicted_answer": "wn18 and fb15k", "predicted_evidence": []}
{"question_id": "50e3fd6778dadf8ec0ff589aa8b18c61bdcacd41", "predicted_answer": "1. wikitext-tl-39", "predicted_evidence": []}
{"question_id": "c5980fe1a0c53bce1502cc674c8a2ed8c311f936", "predicted_answer": "1. 3,206", "predicted_evidence": []}
{"question_id": "7d3c036ec514d9c09c612a214498fc99bf163752", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "ef7b62a705f887326b7ebacbd62567ee1f2129b3", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "23d0637f8ae72ae343556ab135eedc7f4cb58032", "predicted_answer": "none of the above options directly answers the question. however, i will choose option 1 as it seems to be related to speech recognition and word segmentation which might indirectly relate to acquiring names of places for self-localization.\n\nso, my best guess is: \n1", "predicted_evidence": []}
{"question_id": "21c104d14ba3db7fe2cd804a191f9e6258208235", "predicted_answer": "1. par score", "predicted_evidence": []}
{"question_id": "d557752c4706b65dcdb7718272180c59d77fb7a7", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "1bdf7e9f3f804930b2933ebd9207a3e000b27742", "predicted_answer": "1. no", "predicted_evidence": []}
{"question_id": "a74886d789a5d7ebcf7f151bdfb862c79b6b8a12", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "e9ccc74b1f1b172224cf9f01e66b1fa9e34d2593", "predicted_answer": "1. besides claim, label and claim url, it also includes a claim id, reason, category, speaker, checker, tags, claim entities, article title, publish data and claim date", "predicted_evidence": []}
{"question_id": "2948015c2a5cd6a7f2ad99b4622f7e4278ceb0d4", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "c33d0bc5484c38de0119c8738ffa985d1bd64424", "predicted_answer": "monolingual", "predicted_evidence": []}
{"question_id": "93b1b94b301a46251695db8194a2536639a22a88", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "e8029ec69b0b273954b4249873a5070c2a0edb8a", "predicted_answer": "1.", "predicted_evidence": []}
{"question_id": "f4e17b14318b9f67d60a8a2dad1f6b506a10ab36", "predicted_answer": "1. comparing bleu score of model with and without attention", "predicted_evidence": []}
{"question_id": "fac052c4ad6b19a64d7db32fd08df38ad2e22118", "predicted_answer": "1. calinski-harabasz score, t-sne, umap", "predicted_evidence": []}
{"question_id": "aa54e12ff71c25b7cff1e44783d07806e89f8e54", "predicted_answer": "1. the health benefits of alcohol consumption are more limited than previously thought, researchers say", "predicted_evidence": []}
{"question_id": "1405824a6845082eae0458c94c4affd7456ad0f7", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "5be94c7c54593144ba2ac79729d7545f27c79d37", "predicted_answer": "1. not researched as much as english", "predicted_evidence": []}
{"question_id": "32e8eda2183bcafbd79b22f757f8f55895a0b7b2", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "b69f0438c1af4b9ed89e531c056d9812d4994016", "predicted_answer": "1. 3600 user-generated comments", "predicted_evidence": []}
{"question_id": "2e9c6e01909503020070ec4faa6c8bf2d6c0af42", "predicted_answer": "1. the author and the supervisor", "predicted_evidence": []}
{"question_id": "fc65f19a30150a0e981fb69c1f5720f0136325b0", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "5067e5eb2cddbb34b71e8b74ab9210cd46bb09c5", "predicted_answer": "1.", "predicted_evidence": []}
{"question_id": "b974523a6cbd3cdc1fa924243ccc9711bbc7070d", "predicted_answer": "i'm happy to help! however, i must point out that there is only one option provided, and it's not a clear answer to the question.\n\nif i had to choose from the given options, my response would be:\n\n1 (although this doesn't seem like a direct answer to the question)", "predicted_evidence": []}
{"question_id": "03502826f4919e251edba1525f84dd42f21b0253", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "9368471073c66fefebc04f1820209f563a840240", "predicted_answer": "the jensen-shannon distance measures the similarity between two probability distributions.", "predicted_evidence": []}
{"question_id": "981443fce6167b3f6cadf44f9f108d68c1a3f4ab", "predicted_answer": "germany", "predicted_evidence": []}
{"question_id": "6d0f2cce46bc962c6527f7b4a77721799f2455c6", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "5816ebf15e31bdf70e1de8234132e146d64e31eb", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "5a9f94ae296dda06c8aec0fb389ce2f68940ea88", "predicted_answer": "1. their average improvement in character error rate over the best mha model was 0.33 percent points.", "predicted_evidence": []}
{"question_id": "85912b87b16b45cde79039447a70bd1f6f1f8361", "predicted_answer": "1. 449050", "predicted_evidence": []}
{"question_id": "948327d7aa9f85943aac59e3f8613765861f97ff", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "cdf7e60150a166d41baed9dad539e3b93b544624", "predicted_answer": "1. weedsprec bibref8, invcl bibref11, slqs model, cosine similarity", "predicted_evidence": []}
{"question_id": "c06b5623c35b6fa7938340fa340269dc81d061e1", "predicted_answer": "1. noun-noun subset of bless, leds bibref13, bless, wbless, bibless, hyperlex bibref20", "predicted_evidence": []}
{"question_id": "d325a3c21660dbc481b4e839ff1a2d37dcc7ca46", "predicted_answer": "1. detection, direction, graded entailment", "predicted_evidence": []}
{"question_id": "eae13c9693ace504eab1f96c91b16a0627cd1f75", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "bcec22a75c1f899e9fcea4996457cf177c50c4c5", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "58f50397a075f128b45c6b824edb7a955ee8cba1", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "9adcc8c4a10fa0d58f235b740d8d495ee622d596", "predicted_answer": "1. 2 for the ade dataset and 3 for the conll04 dataset", "predicted_evidence": []}
{"question_id": "91c81807374f2459990e5f9f8103906401abc5c2", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "2cc42d14c8c927939a6b8d06f4fdee0913042416", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "b546f14feaa639e43aa64c799dc61b8ef480fb3d", "predicted_answer": "unfortunately, i don't have enough information about the biases being referred to in order to provide an accurate answer. however, based on general knowledge, i can try to make a guess.\n\nsince there is only one option available (\"unanswerable\"), and it's not possible for me to determine how specific biases are found without more context, my response would be:\n\n1", "predicted_evidence": []}
{"question_id": "8568c82078495ab421ecbae38ddd692c867eac09", "predicted_answer": "6", "predicted_evidence": []}
{"question_id": "2ea382c676e418edd5327998e076a8c445d007a5", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "bd7a95b961af7caebf0430a7c9f675816c9c527f", "predicted_answer": "1. dstc2, m2m-sim-m, m2m-sim-r", "predicted_evidence": []}
{"question_id": "f011d6d5287339a35d00cd9ce1dfeabb1f3c0563", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "2ba0c7576eb5b84463a59ff190d4793b67f40ccc", "predicted_answer": "1. attention probes, using visualizations of the activations created by different pieces of text", "predicted_evidence": []}
{"question_id": "c58e60b99a6590e6b9a34de96c7606b004a4f169", "predicted_answer": "1. dependency relation between two words, word sense", "predicted_evidence": []}
{"question_id": "6a099dfe354a79936b59d651ba0887d9f586eaaf", "predicted_answer": "no information is provided about the paper in your query. however, i can only select from the options given. since there's only one option available:\n\n1. yes", "predicted_evidence": []}
{"question_id": "f748cb05becc60e7d47d34f4c5f94189bc184d33", "predicted_answer": "1.", "predicted_evidence": []}
{"question_id": "1a06b7a2097ebbad0afc787ea0756db6af3dadf4", "predicted_answer": "bulgarian, czech, french, german, korean, polish, portuguese, russian, thai, vietnamese", "predicted_evidence": []}
{"question_id": "390aa2d733bd73699899a37e65c0dee4668d2cd8", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "86083a02cc9a80b31cac912c42c710de2ef4adfd", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "29e5e055e01fdbf7b90d5907158676dd3169732d", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "6c4d121d40ce6318ecdc141395cdd2982ba46cff", "predicted_answer": "bibref7, bibref26", "predicted_evidence": []}
{"question_id": "b1457feb6cdbf4fb19c8e87e1cd43981bc991c4c", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "46bca122a87269b20e252838407a2f88f644ded8", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "7c792cda220916df40edb3107e405c86455822ed", "predicted_answer": "meteor", "predicted_evidence": []}
{"question_id": "b3fcab006a9e51a0178a1f64d1d084a895bd8d5c", "predicted_answer": "1. s2vt, rgb (vgg), rgb (vgg)+flow (alexnet), lstm-e (vgg), lstm-e (c3d) and yao et al.", "predicted_evidence": []}
{"question_id": "1192e9a265956aa08177caea7d3c38d501707809", "predicted_answer": "1. viet treebank corpus for pos tagging and chunking tasks, and on vlsp shared task 2016 corpus for ner task", "predicted_evidence": []}
{"question_id": "864b5c1fe8c744f80a55e87421b29d6485b7efd0", "predicted_answer": "1. precision, recall and f1 score", "predicted_evidence": []}
{"question_id": "d469c7de5c9e6dd8a901190e95688c446f12118f", "predicted_answer": "1. unanswerable", "predicted_evidence": []}
{"question_id": "0a050658d09f3c6e21e9ab828dc18e59b147cf7c", "predicted_answer": "i'm happy to help! however, i don't see a specific context for the question \"do they use bert?\". could you please provide more information about who \"they\" are and what bert refers to in this context?\n\nif not, my best guess would be:\n\n1. no", "predicted_evidence": []}
{"question_id": "fd80a7162fde83077ed82ae41d521d774f74340a", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "4d4739682d540878a94d8227412e9e1ec1bb3d39", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "6baf5d7739758bdd79326ce8f50731c785029802", "predicted_answer": "german, english, italian, chinese", "predicted_evidence": []}
{"question_id": "5c4c8e91d28935e1655a582568cc9d94149da2b2", "predicted_answer": "about the same performance", "predicted_evidence": []}
{"question_id": "e4024db40f4b8c1ce593f53b28718e52d5007cd2", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "3f326c003be29c8eac76b24d6bba9608c75aa7ea", "predicted_answer": "1. f1 and weighted-f1", "predicted_evidence": []}
{"question_id": "c84590ba32df470a7c5343d8b99e541b217f10cf", "predicted_answer": "1. the wikipedia toxic comments dataset", "predicted_evidence": []}
{"question_id": "88e9e5ad0e4c369b15d81a4e18f7d12ff8fa9f1b", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "14e259a312e653f8fc0d52ca5325b43c3bdfb968", "predicted_answer": "1. yes, transformer based seq2seq is evaluated with average bleu 0.519, meteor 0.388, rouge 0.631 cider 2.531 and ser 2.55%.", "predicted_evidence": []}
{"question_id": "e93b4a15b54d139b768d5913fb5fd1aed8ab25da", "predicted_answer": "1. manually cleaned human-produced utterances", "predicted_evidence": []}
{"question_id": "993ee7de848ab6adfe02fa728b3a2c896238859b", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "43ee69902a5fc1e3c7bacc4456d3f779c45a911d", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "702e2d02c25a2f3f6b1be8ad3d448b502b8ced9c", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "a83a351539fb0b6acb5bdee32323dd924f4fd1e7", "predicted_answer": "1. 100", "predicted_evidence": []}
{"question_id": "b8ffb81e74c1c1ad552051aca8741b0141ae6e97", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "21f615bf19253fc27ea838012bc088f4d10cdafd", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "1ed006dde28f6946ad2f8bd204f61eda0059a515", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "29d917cc38a56a179395d0f3a2416fca41a01659", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "ad4658c64056b6eddda00d3cbc55944ae01eb437", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "89b9e298993dbedd3637189c3f37c0c4791041a1", "predicted_answer": "1. embedding of the claim, web evidence", "predicted_evidence": []}
{"question_id": "75773ee868c0429ccb913eceb367ff0782eeda8a", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "11ed8c4d98a4e8994990edba54319efe9c6745f2", "predicted_answer": "nell", "predicted_evidence": []}
{"question_id": "08cbc9b8a8df56ec7be626f89285a621e1350f63", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "6b4de7fef3a543215f16042ce6a29186bf84fea4", "predicted_answer": "1. bert, ernie, and bert-wwm", "predicted_evidence": []}
{"question_id": "3a62dd5fece70f8bf876dcbb131223682e3c54b7", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "34fab25d9ceb9c5942daf4ebdab6c5dd4ff9d3db", "predicted_answer": "1. weibo-100k, ontonotes, lcqmc and xnli", "predicted_evidence": []}
{"question_id": "2c20426c003f7e3053f8e6c333f8bb744f6f31f8", "predicted_answer": "1. emotion classification (ec), named entity recognition (ner), sentence pair matching (spm), natural language inference (nli)", "predicted_evidence": []}
{"question_id": "d1909ce77d09983aa1b3ab5c56e2458caefbd442", "predicted_answer": "1. entity match rate, bleu score, success f1 score", "predicted_evidence": []}
{"question_id": "fc3f0eb297b2308b99eb4661a510c9cdbb6ffba2", "predicted_answer": "1. 3029", "predicted_evidence": []}
{"question_id": "27c1c678d3862c7676320ca493537b03a9f0c77a", "predicted_answer": "kvret", "predicted_evidence": []}
{"question_id": "ccb3d21885250bdbfc4c320e99f25923896e70fa", "predicted_answer": "1. calendar, weather, navigation", "predicted_evidence": []}
{"question_id": "61b0db2b5718d409b07f83f912bad6a788bfee5a", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "b217d9730ba469f48426280945dbb77542b39183", "predicted_answer": "caravel", "predicted_evidence": []}
{"question_id": "8c0846879771c8f3915cc2e0718bee448f5cb007", "predicted_answer": "1. 80 excerpts from scientific works, collection of 1,645 chat conversations, collection of 200 aggregated postings", "predicted_evidence": []}
{"question_id": "3fae289ab1fc023bce2fa4f1ce4d9f828074f232", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "863d5c6305e5bb4b14882b85b6216fa11bcbf053", "predicted_answer": "1. mocc, occav, coav, aveer, glad, distav, unmasking, caravel, genim, impgi, spatium and nncd", "predicted_evidence": []}
{"question_id": "37c7c62c9216d6cf3d0858cf1deab6db4b815384", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "539eb559744641e6a4aefe267cbc4c79e2bcceae", "predicted_answer": "1. reddit", "predicted_evidence": []}
{"question_id": "d0444cbf01efdcc247b313c7487120a2f047f421", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "1f6666c2c1d1d5f66208a6fa7da3b3442a577dbc", "predicted_answer": "1. unigram, bigram and trigram", "predicted_evidence": []}
{"question_id": "a78a6fd6ca36413586836838e38f3fa9282646ee", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "c4a0c7b6f1a00f3233a5fe16240a98d9975701c0", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "2ec97cf890b537e393c2ce4c2b3bd05dfe46f683", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "41174d8b176cb8549c2d83429d94ba8218335c84", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "47ecaca8adc7306e3014e8c4358e306a5f0e1716", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "255fb6e20b95092c548ba47d8a295468e06698bd", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "01edeca7b902ae3fd66264366bf548acea1db364", "predicted_answer": "1. their model resulted in values of 0.476, 0.672 and 0.893 for recall at position 1,2 and 5 respectively in 10 candidates.", "predicted_evidence": []}
{"question_id": "496b4ae3c0e26ec95ff6ded5e6790f24c35f0f5b", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "281cb27cfa0eea12180fd82ae33035945476609e", "predicted_answer": "1. relations", "predicted_evidence": []}
{"question_id": "04a4b0c6c8bd4c170c93ea7ea1bf693965ef38f4", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "dbfce07613e6d0d7412165e14438d5f92ad4b004", "predicted_answer": "1. affective features provided by different emotion models such as emolex, emosenticnet, dictionary of affect in language, affective norms for english words and linguistics inquiry and word count", "predicted_evidence": []}
{"question_id": "b7e419d2c4e24c40b8ad0fae87036110297d6752", "predicted_answer": "1. text similarity to source tweet, text similarity to replied tweet, tweet depth", "predicted_evidence": []}
{"question_id": "be9cadaebfa0ff1a3c5a5ed56ff3aae76cf5e0a4", "predicted_answer": "1. average accuracy over each single-language model (avg), and accuracy obtained when training on the concatenation of all languages but the target one (all)", "predicted_evidence": []}
{"question_id": "aa979aed5a454b6705d0085ba2777859feb6fc62", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "2cfcc5864a30259fd35f1cc035fab956802c1c5b", "predicted_answer": "1. language modeling (lm), ptb bibref25 , wikitext-103 bibref26 and one-billion word benchmark bibref27 datasets, neural machine translation (nmt), wmt 2016 english-german dataset", "predicted_evidence": []}
{"question_id": "234ccc1afcae4890e618ff2a7b06fc1e513ea640", "predicted_answer": "3", "predicted_evidence": []}
{"question_id": "4bd894c365d85e20753d9d2cb6edebb8d6f422e9", "predicted_answer": "1. we devise a test set consisting of \u2018adversarial\u2019 examples, i.e, perturbed examples that can potentially change the base model's prediction. , we use two approaches described in literature: back-translation and noisy sequence autoencoder.", "predicted_evidence": []}
{"question_id": "5c4a2a3d6e02bcbeae784e439441524535916e85", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "4704cbb35762d0172f5ac6c26b67550921567a65", "predicted_answer": "in task 1: 4.4%, 3.3%. in task 2: 2.9%, 1.7%", "predicted_evidence": []}
{"question_id": "38a5cc790f66a7362f91d338f2f1d78f48c1e252", "predicted_answer": "svm", "predicted_evidence": []}
{"question_id": "0da6cfbc8cb134dc3d247e91262f5050a2200664", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "9003c7041d3d2addabc2c112fa2c7efe5fab493c", "predicted_answer": "1. inappropriate, discriminating", "predicted_evidence": []}
{"question_id": "e9d9bb87a5c4faa965ceddd98d8b80d4b99e339e", "predicted_answer": "1. on subtask 3: 3.6 \non subtask 4: 3, 5.9 and 5.7", "predicted_evidence": []}
{"question_id": "3554ac92d4f2d00dbf58f7b4ff2b36a852854e95", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "7b35593033e4c6b9dccba98f22a7eeaa3385df38", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "334972ba967444f98865dea4c2bc0eb9416f2ff7", "predicted_answer": "1. from 469 posts to 17 million", "predicted_evidence": []}
{"question_id": "4d4550533edb19c38cb876b1640e62e34e2b88e0", "predicted_answer": "hatespeechdata.com", "predicted_evidence": []}
{"question_id": "1a7d2ade16149630c0028339a816fcafa8192408", "predicted_answer": "1. 7,507", "predicted_evidence": []}
{"question_id": "df2839dbd68ed9d5d186e6c148fa42fce60de64f", "predicted_answer": "1.", "predicted_evidence": []}
{"question_id": "3996438cef34eb7bedaa6745b190c69553cf246b", "predicted_answer": "las stands for \"label smoothing\" but in the context of machine translation and natural language processing, las is a metric that measures the similarity between two sequences, typically used to evaluate the quality of machine translation outputs.\n\nhowever, i couldn't find any information on what las specifically stands for. \n\nso my answer would be: \n1", "predicted_evidence": []}
{"question_id": "97159b8b1ab360c34a1114cd81e8037474bd37db", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "cb20aebfedad1a306e82966d6e9e979129fcd9f9", "predicted_answer": "1. weighted f1-score", "predicted_evidence": []}
{"question_id": "45a2ce68b4a9fd4f04738085865fbefa36dd0727", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "9349acbfce95cb5d6b4d09ac626b55a9cb90e55e", "predicted_answer": "1.", "predicted_evidence": []}
{"question_id": "be7f52c4f2bad20e728785a357c383853d885d94", "predicted_answer": "1. includes 1,941 citation instances from 186 papers", "predicted_evidence": []}
{"question_id": "536e4a39b654b78228bf55fd09d1b433e0dae447", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "212495af630c16745d0fcb614119d75327952271", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "2d1c0618b6106a57777b8d6bbf897712d9db7abc", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "8e898bec123c70315db44f6c8002adc8bf4486ad", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "84aef81dae38e0dca0ad041141df60ab9ac29761", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "4c50f75b1302f749c1351de0782f2d658d4bea70", "predicted_answer": "1.", "predicted_evidence": []}
{"question_id": "a8e0796c1ac353d428d84f4506a92b51bce51b87", "predicted_answer": "1. d-imdb (derived from large scale imdb data snapshot), d-fb (derived from large scale freebase data snapshot)", "predicted_evidence": []}
{"question_id": "160e6d2fc6e04bb0b4ee8d59c06715355dec4a17", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "2c88b46c7e3a632cfa10b7574276d84ecec7a0af", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "6ff240d985bbe96b9d5042c9b372b4e8f498f264", "predicted_answer": "1. $0.3$ million records", "predicted_evidence": []}
{"question_id": "30dad5d9b4a03e56fa31f932c879aa56e11ed15b", "predicted_answer": "1. appreciation, satisfied, peripheral complaint, demanded inquiry, corruption, lagged response, unresponsive, medicine payment, adverse behavior, grievance ascribed and obnoxious/irrelevant", "predicted_evidence": []}
{"question_id": "4b2deaba40ae48672cdc6b452cf41d332531db11", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "54c9147ffd57f1f7238917b013444a9743f0deb8", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "16f71391335a5d574f01235a9c37631893cd3bb0", "predicted_answer": "1. across 4 datasets, the best performing proposed model (cnn) achieved an average of 363% improvement over the state of the art method (lr-cnn).", "predicted_evidence": []}
{"question_id": "33f72c8da22dd7d1378d004cbd8d2dcd814a5291", "predicted_answer": "1. error rate in a minimal pair abx discrimination task", "predicted_evidence": []}
{"question_id": "4e2e19a58e1f2cc5a7b1bc666c1577922454d8c8", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "69ca609e86888c7e4e2e3d33435a0a36f77601b5", "predicted_answer": "1. a standard beam search decoder bibref5 with several straightforward performance optimizations", "predicted_evidence": []}
{"question_id": "98eb245c727c0bd050d7686d133fa7cd9d25a0fb", "predicted_answer": "1. bleu scores", "predicted_evidence": []}
{"question_id": "537a786794604ecc473fb3ef6222e0c3cb81f772", "predicted_answer": "1. how2", "predicted_evidence": []}
{"question_id": "dc5ff2adbe1a504122e3800c9ca1d348de391c94", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "04b43deab0fd753e3419ed8741c10f652b893f02", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "515e10a71d78ccd9c7dc93cd942924a4c85d3a30", "predicted_answer": "1. perplexity of the models", "predicted_evidence": []}
{"question_id": "fbabde18ebec5852e3d46b1f8ce0afb42350ce62", "predicted_answer": "unfortunately, i don't have enough information to provide a specific answer. however, based on common practices in model evaluation, i'll take a guess:\n\n none of the above (implying that there might be other types of evaluations besides user studies)\n\nif you'd like, i can try to help you explore possible reasons why user studies are often used to evaluate models!", "predicted_evidence": []}
{"question_id": "52e8c9ed66ace1780e41815260af1309064d20de", "predicted_answer": "wn18 and fb15k", "predicted_evidence": []}
{"question_id": "3ee721c3531bf1b9a1356a40205d088c9a7a44fc", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "6dcbe941a3b0d5193f950acbdc574f1cfb007845", "predicted_answer": "1. alarm \n2. bank \n3. bus \n4. calendar \n5. event \n6. flight \n7. home \n8. hotel \n9. media \n10. movie \n11. music \n12. rentalcar \n13. restaurant \n14. rideshare \n15. service \n16. travel \n17. weather", "predicted_evidence": []}
{"question_id": "544b68f6f729e5a62c2461189682f9e4307a05c6", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "f887d5b7cf2bcc1412ef63bff4146f7208818184", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "ace60950ccd6076bf13e12ee2717e50bc038a175", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "2e1660405bde64fb6c211e8753e52299e269998f", "predicted_answer": "600000", "predicted_evidence": []}
{"question_id": "82a28c1ed7988513d5984f6dcacecb7e90f64792", "predicted_answer": "1. the negative effects were insignificant.", "predicted_evidence": []}
{"question_id": "d4a6f5034345036dbc2d4e634a8504f79d42ca69", "predicted_answer": "1. the wmt'14 english-french (en-fr) and english-german (en-de) datasets.", "predicted_evidence": []}
{"question_id": "54fa5196d0e6d5e84955548f4ef51bfd9b707a32", "predicted_answer": "1. english to french and english to german", "predicted_evidence": []}
{"question_id": "a997fc1a62442fd80d1873cd29a9092043f025ad", "predicted_answer": "1. transformer models in their base configuration bibref11, using 6 encoder and decoder layers, with model and hidden dimensions of 512 and 2048 respectively, and 8 heads for all attention layers", "predicted_evidence": []}
{"question_id": "9a4aa0e4096c73cd2c3b1eab437c1bf24ae7bf03", "predicted_answer": "1. abstracts, sentences", "predicted_evidence": []}
{"question_id": "1d1ab5d8a24dfd15d95a5a7506ac0456d1192209", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "09a993756d2781a89f7ec5d7992f812d60e24232", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "37eba8c3cfe23778498d95a7dfddf8dfb725f8e2", "predicted_answer": "paragraphvector", "predicted_evidence": []}
{"question_id": "cdf1bf4b202576c39e063921f6b63dc9e4d6b1ff", "predicted_answer": "1. accuracy and f1 score for supervised tasks, pearson's and spearman's correlation for unsupervised tasks", "predicted_evidence": []}
{"question_id": "03f4e5ac5a9010191098d6d66ed9bbdfafcbd013", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "9a9338d0e74fd315af643335e733445031bd7656", "predicted_answer": "1. ami ihm meeting corpus", "predicted_evidence": []}
{"question_id": "3103502cf07726d3eeda34f31c0bdf1fc0ae964e", "predicted_answer": "1.", "predicted_evidence": []}
{"question_id": "aaec98481defc4c230f84a64cdcf793d89081a76", "predicted_answer": "1. lead-3", "predicted_evidence": []}
{"question_id": "69b41524dc5820143e45f2f3545cd5c0a70e2922", "predicted_answer": "1. sumbasic, lsa, lexrank, textrank, bayes, hmm, maxent, neuralsum, lead-n", "predicted_evidence": []}
{"question_id": "72122e0bc5da1d07c0dadb3401aab2acd748424d", "predicted_answer": "1. 20k", "predicted_evidence": []}
{"question_id": "1af4d56eeaf74460ca2c621a2ad8a5d8dbac491c", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "3f5f74c39a560b5d916496e05641783c58af2c5d", "predicted_answer": "1.", "predicted_evidence": []}
{"question_id": "07f5e360e91b99aa2ed0284d7d6688335ed53778", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "11dde2be9a69a025f2fc29ce647201fb5a4df580", "predicted_answer": "0.2 uas and 0.2 las", "predicted_evidence": []}
{"question_id": "bcce5eef9ddc345177b3c39c469b4f8934700f80", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "d3092f78bdbe7e741932e3ddf997e8db42fa044c", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "e2427f182d7cda24eb7197f7998a02bc80550f15", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "0457242fb2ec33446799de229ff37eaad9932f2a", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "5e997d4499b18f1ee1ef6fa145cadbc018b8dd87", "predicted_answer": "google images, reddit memes dataset", "predicted_evidence": []}
{"question_id": "12c7d79d2a26af2d445229d0c8ba3ba1aab3f5b5", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "98daaa9eaa1e1e574be336b8933b861bfd242e5e", "predicted_answer": "1. weakly labeled into hate or non-hate memes, depending on their source", "predicted_evidence": []}
{"question_id": "a93196fb0fb5f8202912971e14552fd7828976db", "predicted_answer": "1. penn treebank (ptb), end-to-end (e2e) text generation corpus", "predicted_evidence": []}
{"question_id": "983c2fe7bdbf471bb8b15db858fd2cbec86b96a5", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "a5418e4af99a2cbd6b7a2b8041388a2d01b8efb2", "predicted_answer": "1. loss analysis.", "predicted_evidence": []}
{"question_id": "9e9e9e0a52563b42e96b8c89ea12f5a916daa7f0", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "b540cd4fe9dc4394f64d5b76b0eaa4d9e30fb728", "predicted_answer": "1. blue utilizes different metrics for each of the tasks: pearson correlation coefficient, f-1 scores, micro-averaging, and accuracy", "predicted_evidence": []}
{"question_id": "41173179efa6186eef17c96f7cbd8acb29105b0e", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "0bd683c51a87a110b68b377e9a06f0a3e12c8da0", "predicted_answer": "1. bilingual dictionary induction, monolingual and cross-lingual word similarity, and cross-lingual hypernym discovery", "predicted_evidence": []}
{"question_id": "a979749e59e6e300a453d8a8b1627f97101799de", "predicted_answer": "1. because word pair similarity increases if the two words translate to similar parts of the cross-lingual embedding space", "predicted_evidence": []}
{"question_id": "b10632eaa0ca48f86522d8ec38b1d702cb0b8c01", "predicted_answer": "1. unanswerable", "predicted_evidence": []}
{"question_id": "8fa7011e7beaa9fb4083bf7dd75d1216f9c7b2eb", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "e0b7acf4292b71725b140f089c6850aebf2828d2", "predicted_answer": "1.", "predicted_evidence": []}
{"question_id": "b6ffa18d49e188c454188669987b0a4807ca3018", "predicted_answer": "sparql", "predicted_evidence": []}
{"question_id": "2b61893b22ac190c94c2cb129e86086888347079", "predicted_answer": "dbpedia", "predicted_evidence": []}
{"question_id": "a996b6aee9be88a3db3f4127f9f77a18ed10caba", "predicted_answer": "1. 0.8320 on semantic typing, 0.7194 on entity matching", "predicted_evidence": []}
{"question_id": "65e2f97f2fe8eb5c2fa41cb95c02b577e8d6e5ee", "predicted_answer": "1. number of dialogs that resulted in launching a skill divided by total number of dialogs", "predicted_evidence": []}
{"question_id": "83f14af3ccca4ab9deb4c6d208f624d1e79dc7eb", "predicted_answer": "concat ensemble", "predicted_evidence": []}
{"question_id": "0154d8be772193bfd70194110f125813057413a4", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "e737cfe0f6cfc6d3ac6bec32231d9c893bfc3fc9", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "42be49b883eba268e3dbc5c3ff4631442657dcbb", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "8d4f0815f8a23fe45c298c161fc7a27f3bb0d338", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "a6665074b067abb2676d5464f36b2cb07f6919d3", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "b0fbd4b0f02b877a0d3df1d8ccc47d90dd49147c", "predicted_answer": "1. token representation, self-attention encoder,, constituent parsing decoder,  dependency parsing decoder", "predicted_evidence": []}
{"question_id": "3288a50701a80303fd71c8c5ede81cbee14fa2c7", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "22b8836cb00472c9780226483b29771ae3ebdc87", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "540e9db5595009629b2af005e3c06610e1901b12", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "bd1a3c651ca2b27f283d3f36df507ed4eb24c2b0", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "5a2c0c55a43dcc0b9439d330d2cbe1d5d444bf36", "predicted_answer": "i'm happy to help! however, i don't see a list of options provided for this question. could you please provide the complete list of options so i can give you the best answer?", "predicted_evidence": []}
{"question_id": "0c78d2fe8bc5491b5fd8a2166190c59eba069ced", "predicted_answer": "i think there may be a misunderstanding here!\n\nthe provided options don't seem to match the question. the option \"1. yes\" doesn't make sense in this context.\n\nhowever, i'll try to provide an answer based on my knowledge. here it is:\n\nclusters related to security, violence, and crime are often identified through various methods, including:\n\n* geographic information systems (gis) analysis\n* crime mapping\n* hotspot analysis\n* spatial analysis\n* statistical modeling\n\nplease note that this answer might not be directly related to the provided options, but rather a general response to the question.", "predicted_evidence": []}
{"question_id": "d2473c039ab85f8e9e99066894658381ae852e16", "predicted_answer": "1. image feature, question feature, label vector for the user's answer", "predicted_evidence": []}
{"question_id": "5d6cc65b73f428ea2a499bcf91995ef5441f63d4", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "0a8bc204a76041a25cee7e9f8e2af332a17da67a", "predicted_answer": "1. bleu, self-bleu, n-gram based score, probability score", "predicted_evidence": []}
{"question_id": "81686454f215e28987c7ad00ddce5ffe84b37195", "predicted_answer": "1. unanswerable", "predicted_evidence": []}
{"question_id": "fc06502fa62803b62f6fd84265bfcfb207c1113b", "predicted_answer": "1.", "predicted_evidence": []}
{"question_id": "ce807a42370bfca10fa322d6fa772e4a58a8dca1", "predicted_answer": "1. darkode,  hack forums, blackhat and nulled.", "predicted_evidence": []}
{"question_id": "f91835f17c0086baec65ebd99d12326ae1ae87d2", "predicted_answer": "1. stanford corenlp", "predicted_evidence": []}
{"question_id": "14e78db206a8180ea637774aa572b073e3ffa219", "predicted_answer": "1. rnn encoders", "predicted_evidence": []}
{"question_id": "bc1e3f67d607bfc7c4c56d6b9763d3ae7f56ad5b", "predicted_answer": "i don't have enough information to determine the performance drop of their model when there is no parsed input. the provided option only mentions an improvement over a baseline, but it doesn't relate to the scenario of having no parsed input. \n\nmy best guess would be that the question cannot be answered with the given options.", "predicted_evidence": []}
{"question_id": "e8e00b4c0673af5ab02ec82563105e4157cc54bb", "predicted_answer": "1. transformer model achieves higher bleu score than both attention encoder-decoder and sequence-sequence model", "predicted_evidence": []}
{"question_id": "18ad60f97f53af64cb9db2123c0d8846c57bfa4a", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "87357448ce4cae3c59d4570a19c7a9df4c086bd8", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "1ccc4f63268aa7841cc6fd23535c9cbe85791007", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "afe34e553c3c784dbf02add675b15c27638cdd45", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "3f46d8082a753265ec2a88ae8f1beb6651e281b6", "predicted_answer": "1. cbt ne/cn, mr movie reviews, imdb movie reviews, subj", "predicted_evidence": []}
{"question_id": "63d9b12dc3ff3ceb1aed83ce11371bca8aac4e8f", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "0bd864f83626a0c60f5e96b73fb269607afc7c09", "predicted_answer": "1.", "predicted_evidence": []}
{"question_id": "c77d6061d260f627f2a29a63718243bab5a6ed5a", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "4c7b29f6e3cc1e902959a1985146ccc0b15fe521", "predicted_answer": "wikipedia", "predicted_evidence": []}
{"question_id": "b34c60eb4738e0439523bcc679fe0fe70ceb8bde", "predicted_answer": "1. in the openbookqa setup the open book part is much larger, the open book part is much larger (than a small paragraph) and is not complete as additional common knowledge may be required", "predicted_evidence": []}
{"question_id": "9623884915b125d26e13e8eeebe9a0f79d56954b", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "77db56fee07b01015a74413ca31f19bea7203f0b", "predicted_answer": "1. f$_1$, precision, and recall", "predicted_evidence": []}
{"question_id": "c309e87c9e08cf847f31e554577d6366faec1ea0", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "81cee2fc6edd9b7bc65bbf6b4aa35782339e6cff", "predicted_answer": "1. variety of formats supported (pdf, word...), user can define content elements of document", "predicted_evidence": []}
{"question_id": "79620a2b4b121b6d3edd0f7b1d4a8cc7ada0b516", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "2555ca85ff6b56bd09c3919aa6b277eb7a4d4631", "predicted_answer": "1. stanford sentiment treebank", "predicted_evidence": []}
{"question_id": "d028dcef22cdf0e86f62455d083581d025db1955", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "593e307d9a9d7361eba49484099c7a8147d3dade", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "6f8881e60fdaca7c1b35a5acc7125994bb1206a3", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "6a7370dd12682434248d006ffe0a72228c439693", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "a71ebd8dc907d470f6bd3829fa949b15b29a0631", "predicted_answer": "1. if it includes  negative utterances, negative generalizations and insults concerning ethnicity, nationality, religion and culture.", "predicted_evidence": []}
{"question_id": "1546356a8c5893dc2d298dcbd96d0307731dd54d", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "9f5507a8c835c4671020d7d310fff2930d44e75a", "predicted_answer": "1. danish/swedish (da/sv), russian/bulgarian (ru/bg), finnish/hungarian (fi/hu), spanish/portuguese (es/pt)", "predicted_evidence": []}
{"question_id": "96ee62407b1ca2a6538c218781e73e8fbf45094a", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "ad0a7fe75db5553652cd25555c6980f497e08113", "predicted_answer": "1. by treating logical forms as a latent variable and training a discriminative log-linear model over logical form y given x.", "predicted_evidence": []}
{"question_id": "f268b70b08bd0436de5310e390ca5f38f7636612", "predicted_answer": "giza++ bibref3 or fast_align bibref4", "predicted_evidence": []}
{"question_id": "7aae4533dbf097992f23fb2e0574ec5c891ca236", "predicted_answer": "1. btec corpus, the cstar03 and iwslt04 held out sets, the nist2008 open machine translation campaign", "predicted_evidence": []}
{"question_id": "c80669cb444a6ec6249b971213b0226f59940a82", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "10045d7dac063013a8447b5a4bc3a3c2f18f9e82", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "4e4946c023211712c782637fcca523deb126e519", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "144714fe0d5a2bb7e21a7bf50df39d790ff12916", "predicted_answer": "2", "predicted_evidence": []}
{"question_id": "f01aa192d97fa3cc36b6e316355dc5da0e9b97dc", "predicted_answer": "(i), (ii), (iii), (iv), and (v)", "predicted_evidence": []}
{"question_id": "3d583a0675ad34eb7a46767ef5eba5f0ea898aa9", "predicted_answer": "1. lstm", "predicted_evidence": []}
{"question_id": "d7d41a1b8bbb1baece89b28962d23ee4457b9c3a", "predicted_answer": "1. mandarin, english", "predicted_evidence": []}
{"question_id": "b458ebca72e3013da3b4064293a0a2b4b5ef1fa6", "predicted_answer": "bibref1", "predicted_evidence": []}
{"question_id": "1cbca15405632a2e9d0a7061855642d661e3b3a7", "predicted_answer": "1. their gtrs approach got an improvement of 3.89% compared to svm and 27.91% compared to pawlak.", "predicted_evidence": []}
{"question_id": "018ef092ffc356a2c0e970ae64ad3c2cf8443288", "predicted_answer": "1. 8757 news records", "predicted_evidence": []}
{"question_id": "de4e180f49ff187abc519d01eff14ebcd8149cad", "predicted_answer": "1. inconsistency in noun phrase structures,  inconsistency between clauses, inconsistency between named entities and noun phrases, word level feature using tf-idf", "predicted_evidence": []}
{"question_id": "bdc1f37c8b5e96e3c29cc02dae4ce80087d83284", "predicted_answer": "1. unweighted average recall (uar) metric", "predicted_evidence": []}
{"question_id": "c54de73b36ab86534d18a295f3711591ce9e1784", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "fdd9dea06550a2fd0df7a1e6a5109facf3601d76", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "3786164eaf3965c11c9969c4463b8c3223627067", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "2fd8688c8f475ab43edaf5d189567f8799b018e1", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "b68d2549431c524a86a46c63960b3b283f61f445", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "7f5059b4b5e84b7705835887f02a51d4d016316a", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "df79d04cc10a01d433bb558d5f8a51bfad29f46b", "predicted_answer": "1. kinyarwanda, lao, pashto, tok pisin, and a subset of english", "predicted_evidence": []}
{"question_id": "182b6d77b51fa83102719a81862891f49c23a025", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "441886f0497dc84f46ed8c32e8fa32983b5db42e", "predicted_answer": "1. partisan news detector", "predicted_evidence": []}
{"question_id": "62afbf8b1090e56fdd2a2fa2bdb687c3995477f6", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "d3341eefe4188ee8a68914a2e8c9047334997e84", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "770b4ec5c9a9706fef89a9aae45bb3e713d6b8ee", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "a379c380ac9f67f824506951444c873713405eed", "predicted_answer": "1. cnn, lstm, bert", "predicted_evidence": []}
{"question_id": "334f90bb715d8950ead1be0742d46a3b889744e7", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "53c8416f2983e07a7fa33bcb4c4281bbf49c8164", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "5b2480c6533696271ae6d91f2abe1e3a25c4ae73", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "a516b37ad9d977cb9d4da3897f942c1c494405fe", "predicted_answer": "docqa, san, qanet, asreader, lm, random guess", "predicted_evidence": []}
{"question_id": "7f5ab9a53aef7ea1a1c2221967057ee71abb27cb", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "7fbbe191f4d877cc6af89c00fcfd5b5774d2a2bb", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "f42e61f9ad06fb782d1574eb973c880add4f76d2", "predicted_answer": "1. type of recurrent unit, type of attention, choice of sequential vs. tree-based model structure", "predicted_evidence": []}
{"question_id": "f197e0f61f7980c64a76a3a9657762f1f0edb65b", "predicted_answer": "1. confirmation bias", "predicted_evidence": []}
{"question_id": "b5484a0f03d63d091398d3ce4f841a45062438a7", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "18d8b52b4409c718bf1cc90ce9e013206034bbd9", "predicted_answer": "1. average 12.8 min per recording", "predicted_evidence": []}
{"question_id": "43d8057ff0d3f0c745a7164aed7ed146674630e0", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "ebb7313eee2ea447abc83cb08b658b57c7eaa600", "predicted_answer": "1. automatic translator with moses", "predicted_evidence": []}
{"question_id": "df934aa1db09c14b3bf4bc617491264e2192390b", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "346f10ddb34503dfba72b0e49afcdf6a08ecacfa", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "2480dfe2d996afef840a81bd920aeb9c26e5b31d", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "0fec9da2bc80a12a7a6d6600b9ecf3e122732b60", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "5499527beadb7f5dd908bd659cad83d6a81119bd", "predicted_answer": "1. wiktionary, oxford dictionary of english idioms, usingenglish.com (ue), sporleder corpus, vnc dataset, semeval-2013 task 5 dataset", "predicted_evidence": []}
{"question_id": "191d4fe8a37611b2485e715bb55ff1a30038ad6a", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "6e76f114209f59b027ec3b3c8c9cdfc3e682589f", "predicted_answer": "english", "predicted_evidence": []}
{"question_id": "6583e8bfa7bcc3a792a90b30abb316e6d423f49b", "predicted_answer": "1. direct source$\\rightarrow $target", "predicted_evidence": []}
{"question_id": "9a5d02062fa7eec7097f1dc1c38b5e6d5c82acdf", "predicted_answer": "1. the cider-d, spice, bleu, meteor, and rouge-l metrics", "predicted_evidence": []}
{"question_id": "c38a48d65bb21c314194090d0cc3f1a45c549dd6", "predicted_answer": "conll, weblogs, newsgroups, reviews, answers", "predicted_evidence": []}
{"question_id": "5450f27ccc0406d3bffd08772d8b59004c2716da", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "12ac76b77f22ed3bcb6430bcd0b909441d79751b", "predicted_answer": "1. teacher forcing (tf), scheduled sampling (ss),  seqgan, rankgan, leakgan.", "predicted_evidence": []}
{"question_id": "0038b073b7cca847033177024f9719c971692042", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "ad6415f4351c44ffae237524696a3f76f383bfd5", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "e097c2ec6021b1c1195b953bf3e930374b74d8eb", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "320d72a9cd19b52c29dda9ddecd520c9938a717f", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "21cbcd24863211b02b436f21deaf02125f34da4c", "predicted_answer": "1. couples therapy corpus (coupther) bibref21", "predicted_evidence": []}
{"question_id": "37bc8763eb604c14871af71cba904b7b77b6e089", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "a81941f933907e4eb848f8aa896c78c1157bff20", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "252677c93feb2cb0379009b680f0b4562b064270", "predicted_answer": "6,127 scientific entities, including 2,112 process, 258 method, 2,099 material, and 1,658 data entities", "predicted_evidence": []}
{"question_id": "fe6bb55b28f14ed8ac82c122681905397e31279d", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "b3ac67232c8c7d5a759ae025aee85e9c838584eb", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "43878a6a8fc36aaae29d95815355aaa7d25c3b53", "predicted_answer": "1. the personalized babi dialog dataset", "predicted_evidence": []}
{"question_id": "68ff2a14e6f0e115ef12c213cf852a35a4d73863", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "0b54032508c96ff3320c3db613aeb25d42d00490", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "86be8241737dd8f7b656a3af2cd17c8d54bf1553", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "a4422019d19f9c3d95ce8dc1d529bf3da5edcfb1", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "bb169a0624aefe66d3b4b1116bbd152d54f9e31b", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "0d7de323fd191a793858386d7eb8692cc924b432", "predicted_answer": "1. current news, historical news, free time, sports, juridical news pieces, personal adverts, editorials.", "predicted_evidence": []}
{"question_id": "ca8e023d142d89557714d67739e1df54d7e5ce4b", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "3fddd9f6707b9e40e35518dae7f6da7c4cb77d16", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "676c874266ee0388fe5b9a75e1006796c68c3c13", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "fc54736e67f748f804e8f66b3aaaea7f5e55b209", "predicted_answer": "1.", "predicted_evidence": []}
{"question_id": "a53683d1a0647c80a4398ff8f4a03e11c0929be2", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "0fd7d12711dfe0e35467a7ee6525127378a1bacb", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "5dc2f79cd8078d5976f2df9ab128d4517e894257", "predicted_answer": "1. bbc and cnn", "predicted_evidence": []}
{"question_id": "4226a1830266ed5bde1b349205effafe7a0e2337", "predicted_answer": "high-order representation of a relation", "predicted_evidence": []}
{"question_id": "5fb348b2d7b012123de93e79fd46a7182fd062bd", "predicted_answer": "nell-one, wiki-one", "predicted_evidence": []}
{"question_id": "7ff48fe5b7bd6b56553caacc891ce3d7e0070440", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "54a2c08aa55c3db9b30ae2922c96528d3f4fc733", "predicted_answer": "n-grams model", "predicted_evidence": []}
{"question_id": "ecb680d79e847beb7c1aa590d288a7313908d64a", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "b622f57c4e429b458978cb8863978d7facab7cfe", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "f9c5799091e7e35a8133eee4d95004e1b35aea00", "predicted_answer": "1. exp. 5.1", "predicted_evidence": []}
{"question_id": "04012650a45d56c0013cf45fd9792f43916eaf83", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "7889ec45b996be0b8bf7360d08f84daf3644f115", "predicted_answer": "bibref11", "predicted_evidence": []}
{"question_id": "41e300acec35252e23f239772cecadc0ea986071", "predicted_answer": "1. multilingual neural machine translation models", "predicted_evidence": []}
{"question_id": "e70236c876c94dbecd9a665d9ba8cefe7301dcfd", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "aa1f605619b2487cc914fc2594c8efe2598d8555", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "9f2634c142dc4ad2c68135dbb393ecdfd23af13f", "predicted_answer": "1. we obtain 52,053 dialogues and 460,358 utterances", "predicted_evidence": []}
{"question_id": "77e57d19a0d48f46de8cbf857f5e5284bca0df2b", "predicted_answer": "1. 30m utterances", "predicted_evidence": []}
{"question_id": "50c8b821191339043306fd28e6cda2db400704f9", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "dee7383a92c78ea49859a2d5ff2a9d0a794c1f0f", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "a458c649a793588911cef4c421f95117d0b9c472", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "04cab3325e20c61f19846674bf9a2c46ea60c449", "predicted_answer": "wav2vec 2.0", "predicted_evidence": []}
{"question_id": "76c8aac84152fc4bbc0d5faa7b46e40438353e77", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "6916596253d67f74dba9222f48b9e8799581bad9", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "7ccf2392422b44ede35a3fbd85bbb1da25adf795", "predicted_answer": "i couldn't find a specific comparison model for the blending game. therefore, i'll choose:\n\n1. unanswerable", "predicted_evidence": []}
{"question_id": "4d60e9494a412d581bd5e85f4e78881914085afc", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "cf63a4f9fe0f71779cf5a014807ae4528279c25a", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "8829f738bcdf05b615072724223dbd82463e5de6", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "4b624064332072102ea674254d7098038edad572", "predicted_answer": "1. no", "predicted_evidence": []}
{"question_id": "65ba7304838eb960e3b3de7c8a367d2c2cd64c54", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "a60030cfd95d0c10b1f5116c594d50cb96c87ae6", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "efe49829725cfe54de01405c76149a4fe4d18747", "predicted_answer": "for example, in quasart, it improves 16.8% in em score and 20.4% in f1 score.", "predicted_evidence": []}
{"question_id": "3d49b678ff6b125ffe7fb614af3e187da65c6f65", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "b686e10a725254695821e330a277c900792db69f", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "40f87db3a8d1ac49b888ce3358200f7d52903ce7", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "36383971a852d1542e720d3ea1f5adeae0dbff18", "predicted_answer": "1. holistic, traatt, regatt, conatt, ibowimg , vqa, wtl , nmn , san , ama , fda , d-nmn, dmn+", "predicted_evidence": []}
{"question_id": "1d941d390c0ee365aa7d7c58963e646eea74cbd6", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "3ee976add83e37339715d4ae9d8aa328dd54d052", "predicted_answer": "1. queensland flood which provided 96% accuracy, alberta flood with the same configuration of train-test split which provided 95% accuracy", "predicted_evidence": []}
{"question_id": "ef04182b6ae73a83d52cb694cdf4d414c81bf1dc", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "decb07f9be715de024236e50dc7011a132363480", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "63eb31f613a41a3ddd86f599e743ed10e1cd07ba", "predicted_answer": "hindi-english", "predicted_evidence": []}
{"question_id": "d2804ac0f068e9c498e33582af9c66906b26cac3", "predicted_answer": "the provided text does not directly answer how they compress the model. however, based on the given options and context, i would make an educated guess that the correct answer is:\n\n1", "predicted_evidence": []}
{"question_id": "e24fbcc8be922c43f6b6037cdf2bfd4c0a926c08", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "e8c0fabae0d29491471e37dec34f652910302928", "predicted_answer": "1. beyond localized features and have access to the entire sequence", "predicted_evidence": []}
{"question_id": "cafa6103e609acaf08274a2f6d8686475c6b8723", "predicted_answer": "1. improves the dar accuracy over bi-lstm-crf by 2.1% and 0.8% on swda and mrda respectively", "predicted_evidence": []}
{"question_id": "7f2fd7ab968de720082133c42c2052d351589a67", "predicted_answer": "1. word2vec, 200 as the dimension of the obtained word vectors", "predicted_evidence": []}
{"question_id": "369b0a481a4b75439ade0ec4f12b44414c4e5164", "predicted_answer": "1. turkish news-web corpus, ts tweets by sezer-2013 and 20m turkish tweets by bolat and amasyal\u0131", "predicted_evidence": []}
{"question_id": "e97545f4a5e7bc96515e60f2f9b23d8023d1eed9", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "aaed6e30cf16727df0075b364873df2a4ec7605b", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "66f0dee89f084fe0565539a73f5bbe65f3677814", "predicted_answer": "i'm happy to help! however, i don't see a specific context or reference to a particular model or research in your question. could you please provide more information or clarify which neural network models you are referring to?\n\nif not, i'll do my best to provide a general answer based on common practices in the field of natural language processing.\n\nin that case, my answer would be:\n\nno", "predicted_evidence": []}
{"question_id": "8f882f414d7ea12077930451ae77c6e5f093adbc", "predicted_answer": "1. incorporating nnglm and nnjm both independently and jointly into a baseline system", "predicted_evidence": []}
{"question_id": "a49832c89a2d7f95c1fe6132902d74e4e7a3f2d0", "predicted_answer": "1. conll 2014", "predicted_evidence": []}
{"question_id": "a33ab5ce8497ff63ca575a80b03e0ed9c6acd273", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "8fcbae7c3bd85034ae074fa58a35e773936edb5b", "predicted_answer": "1. support vector machine (svm), logistic regression (lr), random forest (rf)", "predicted_evidence": []}
{"question_id": "cbbcafffda7107358fa5bf02409a01e17ee56bfd", "predicted_answer": "1. it is observed some variability - but not significant. bert does not seem to gain much more syntax information than with type level information.", "predicted_evidence": []}
{"question_id": "1e59263f7aa7dd5acb53c8749f627cf68683adee", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "eac042734f76e787cb98ba3d0c13a916a49bdfb3", "predicted_answer": "1. genia corpus", "predicted_evidence": []}
{"question_id": "9595bf228c9e859b0dc745e6c74070be2468d2cf", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "94c5f5b1eb8414ad924c3568cedd81dc35f29c48", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "ba05a53f5563b9dd51cc2db241c6e9418bc00031", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "7bf3a7d19f17cf01f2c9fa16401ef04a3bef65d8", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "20f7b359f09c37e6aaaa15c2cdbb52b031ab4809", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "3efc0981e7f959d916aa8bb32ab1c347b8474ff8", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "10f560fe8e1c0c7dea5e308ee4cec16d07874f1d", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "07580f78b04554eea9bb6d3a1fc7ca0d37d5c612", "predicted_answer": "1. there is no reason to think that this approach wouldn't also be successful for other technical domains. technical terms are replaced with tokens, therefore so as long as there is a corresponding process for identifying and replacing technical terms in the new domain this approach could be viable.", "predicted_evidence": []}
{"question_id": "dc28ac845602904c2522f5349374153f378c42d3", "predicted_answer": "1. 44,000 tweets", "predicted_evidence": []}
{"question_id": "ac148fb921cce9c8e7b559bba36e54b63ef86350", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "094ce2f912aa3ced9eb97b171745d38f58f946dd", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "b5bfa6effdeae8ee864d7d11bc5f3e1766171c2d", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "bf00808353eec22b4801c922cce7b1ec0ff3b777", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "ec62c4cdbeaafc875c695f2d4415bce285015763", "predicted_answer": "1. bert, roberta, distilbert, gpt, gpt2, transformer-xl, xlnet, xlm", "predicted_evidence": []}
{"question_id": "405964517f372629cda4326d8efadde0206b7751", "predicted_answer": "1. they use roc curves and cross-validation", "predicted_evidence": []}
{"question_id": "ae95a7d286cb7a0d5bc1a8283ecbf803e9305951", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "0be0c8106df5fde4b544af766ec3d4a3d7a6c8a2", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "959490ba72bd02f742db1e7b19525d4b6c419772", "predicted_answer": "unfortunately, i don't have a specific answer to this question as it's too broad and depends on various factors such as the type of dataset, its purpose, and the source.\n\nso, my response would be:\n\n1. unanswerable", "predicted_evidence": []}
{"question_id": "504a069ccda21580ccbf18c34f5eefc0088fa105", "predicted_answer": "1. hundreds of thousands of legal agreements", "predicted_evidence": []}
{"question_id": "d76ecdc0743893a895bc9dc3772af47d325e6d07", "predicted_answer": "unfortunately, i couldn't find specific information on the dataset size for the 2019 amazon alexa competition. therefore, my response is:\n\n1. unanswerable", "predicted_evidence": []}
{"question_id": "2a6469f8f6bf16577b590732d30266fd2486a72e", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "a02696d4ab728ddd591f84a352df9375faf7d1b4", "predicted_answer": "1. 1,618 training dialogs, 500 validation dialogs, and 1,117 test dialogs", "predicted_evidence": []}
{"question_id": "78577fd1c09c0766f6e7d625196adcc72ddc8438", "predicted_answer": "1. training datasets: tts system dataset and embedding selection dataset. evaluation datasets: common prosody errors dataset and lfr dataset.", "predicted_evidence": []}
{"question_id": "1f63ccc379f01ecdccaa02ed0912970610c84b72", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "736c74d2f61ac8d3ac31c45c6510a36c767a5d6d", "predicted_answer": "multi-instance learning is a type of machine learning approach that deals with data where each example is represented by multiple instances or bags of features, rather than a single feature vector.\n\nsince there's only one option available which says \"unanswerable\", i'll choose that as the best answer. however, please note that multi-instance learning is indeed an answerable topic in machine learning.", "predicted_evidence": []}
{"question_id": "b2254f9dd0e416ee37b577cef75ffa36cbcb8293", "predicted_answer": "1. 5 domains: software, stuff, african wildlife, healthcare, datatypes", "predicted_evidence": []}
{"question_id": "cb1126992a39555e154bedec388465b249a02ded", "predicted_answer": "1. using a mixture of manual and semi-automatic techniques", "predicted_evidence": []}
{"question_id": "d5256d684b5f1b1ec648d996c358e66fe51f4904", "predicted_answer": "3. measure impact of word normalization tools.", "predicted_evidence": []}
{"question_id": "2a1069ae3629ae8ecc19d2305f23445c0231dc39", "predicted_answer": "i'm happy to help! however, i don't see a specific task or context mentioned in your question. could you please provide more information about the task you are referring to? that way, i can give you a more accurate answer.\n\nif not, my best guess would be:\n\n1. no", "predicted_evidence": []}
{"question_id": "0b411f942c6e2e34e3d81cc855332f815b6bc123", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "01123a39574bdc4684aafa59c52d956b532d2e53", "predicted_answer": "1. ae-hcn outperforms by 17%, ae-hcn-cnn outperforms by 20% on average", "predicted_evidence": []}
{"question_id": "954c4756e293fd5c26dc50dc74f505cc94b3f8cc", "predicted_answer": "1.", "predicted_evidence": []}
{"question_id": "ee279ace5bc69d15e640da967bd4214fe264aa1a", "predicted_answer": "1. mean rank (mr), mean reciprocal rank (mrr), as well as hits@1, hits@3, and hits@10", "predicted_evidence": []}
{"question_id": "beda007307c76b8ce7ffcd159a8280d2e8c7c356", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "dac2591f19f5bbac3d4a7fa038ff7aa09f6f0d96", "predicted_answer": "1. optimized tf-idf, iterated tf-idf, bert re-ranking.", "predicted_evidence": []}
{"question_id": "f62c78be58983ef1d77049738785ec7ab9f2a3ee", "predicted_answer": "1. kaggle", "predicted_evidence": []}
{"question_id": "639c145f0bcb1dd12d08108bc7a02f9ec181552e", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "ab3737fbf17b7a0e790e1315fffe46f615ebde64", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "0b8d64d6cdcfc2ba66efa41a52e09241729a697c", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "891c4af5bb77d6b8635ec4109572de3401b60631", "predicted_answer": "1. unanswerable", "predicted_evidence": []}
{"question_id": "39a450ac15688199575798e72a2cc016ef4316b5", "predicted_answer": "1.096% on em and 0.689% f1", "predicted_evidence": []}
{"question_id": "de015276dcde4e7d1d648c6e31100ec80f61960f", "predicted_answer": "yes", "predicted_evidence": []}
{"question_id": "56836afc57cae60210fa1e5294c88e40bb10cc0e", "predicted_answer": "1. language identification, part-of-speech tagging, word segmentation, and preordering for statistical machine translation", "predicted_evidence": []}
{"question_id": "6147846520a3dc05b230241f2ad6d411d614e24c", "predicted_answer": "paper acceptance prediction, named entity recognition (ner), author stance prediction", "predicted_evidence": []}
{"question_id": "99cf494714c67723692ad1279132212db29295f3", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "85e45b37408bb353c6068ba62c18e516d4f67fe9", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "f4e1d2276d3fc781b686d2bb44eead73e06fbf3f", "predicted_answer": "1. language modeling", "predicted_evidence": []}
{"question_id": "bf2ebc9bbd4cbdf8922c051f406effc97fd16e54", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "c13fe4064df0cfebd0538f29cb13e917fc5c3be0", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "6adde6bc3e27a32eac5daa57d30ab373f77690be", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "90ad8d7ee27192b89ffcfa4a68302f370e6333a8", "predicted_answer": "unanswerable", "predicted_evidence": []}
{"question_id": "ba1da61db264599963e340010b777a1723ffeb4c", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "ff814793387c8f3b61f09b88c73c00360a22a60e", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "059acc270062921ad27ee40a77fd50de6f02840a", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "6a9eb407be6a459dc976ffeae17bdd8f71c8791c", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "cacb83e15e160d700db93c3f67c79a11281d20c5", "predicted_answer": "1", "predicted_evidence": []}
{"question_id": "33957fde72f9082a5c11844e7c47c58f8029c4ae", "predicted_answer": "1. freebase", "predicted_evidence": []}
{"question_id": "1c4cd22d6eaefffd47b93c2124f6779a06d2d9e1", "predicted_answer": "1. 3 million webpages processed with a ccg parser for training, 220 queries for development, and 307 queries for testing", "predicted_evidence": []}
{"question_id": "2122bd05c03dde098aa17e36773e1ac7b6011969", "predicted_answer": "1. fill-in-the-blank natural language questions", "predicted_evidence": []}
{"question_id": "1d6c42e3f545d55daa86bea6fabf0b1c52a93bbb", "predicted_answer": "1. yes", "predicted_evidence": []}
{"question_id": "480e10e5a1b9c0ae9f7763b7611eeae9e925096b", "predicted_answer": "no", "predicted_evidence": []}
{"question_id": "056fc821d1ec1e8ca5dc958d14ea389857b1a299", "predicted_answer": "3", "predicted_evidence": []}
{"question_id": "974868e4e22f14766bcc76dc4927a7f2795dcd5e", "predicted_answer": "unanswerable", "predicted_evidence": []}
